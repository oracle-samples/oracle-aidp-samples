{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# media: Iceberg and Liquid Clustering Demo\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "This notebook demonstrates the power of **Iceberg and Liquid Clustering** in Oracle AI Data Platform (AIDP) Workbench using a media and entertainment analytics use case. Liquid clustering automatically optimizes data layout for query performance without requiring manual partitioning or Z-Ordering.\n",
    "\n",
    "### What is Iceberg?\n",
    "\n",
    "Apache Iceberg is an open table format for huge analytic datasets that provides:\n",
    "\n",
    "- **Schema evolution**: Add, drop, rename, update columns without rewriting data\n",
    "- **Partition evolution**: Change partitioning without disrupting queries\n",
    "- **Time travel**: Query historical data snapshots for auditing and rollback\n",
    "- **ACID transactions**: Reliable concurrent read/write operations\n",
    "- **Cross-engine compatibility**: Works with Spark, Flink, Presto, Hive, and more\n",
    "- **Open ecosystem**: Apache 2.0 licensed, community-driven development\n",
    "\n",
    "### Delta Universal Format with Iceberg\n",
    "\n",
    "Delta Universal Format enables Iceberg compatibility while maintaining Delta's advanced features like liquid clustering. This combination provides:\n",
    "\n",
    "- **Best of both worlds**: Delta's performance optimizations with Iceberg's openness\n",
    "- **Multi-engine access**: Query the same data from different analytics engines\n",
    "- **Future-proof architecture**: Standards-based approach for long-term data investments\n",
    "- **Enhanced governance**: Rich metadata and catalog integration\n",
    "\n",
    "### What is Liquid Clustering?\n",
    "\n",
    "Liquid clustering automatically identifies and groups similar data together based on clustering columns you define. This optimization happens automatically during data ingestion and maintenance operations, providing:\n",
    "\n",
    "- **Automatic optimization**: No manual tuning required\n",
    "- **Improved query performance**: Faster queries on clustered columns\n",
    "- **Reduced maintenance**: No need for manual repartitioning\n",
    "- **Adaptive clustering**: Adjusts as data patterns change\n",
    "\n",
    "### Use Case: Content Performance and User Engagement Analytics\n",
    "\n",
    "We'll analyze media content consumption and user engagement data. Our clustering strategy will optimize for:\n",
    "\n",
    "- **User-specific queries**: Fast lookups by user ID\n",
    "- **Time-based analysis**: Efficient filtering by viewing and engagement dates\n",
    "- **Content performance patterns**: Quick aggregation by content type and engagement metrics\n",
    "\n",
    "### AIDP Environment Setup\n",
    "\n",
    "This notebook leverages the existing Spark session in your AIDP environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T19:16:55.002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Media catalog and analytics schema created successfully!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create media catalog and analytics schema\n",
    "\n",
    "# In AIDP, catalogs provide data isolation and governance\n",
    "\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS media\")\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS media.analytics\")\n",
    "\n",
    "print(\"Media catalog and analytics schema created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Delta Table with Liquid Clustering\n",
    "\n",
    "### Table Design\n",
    "\n",
    "Our `content_engagement_uf` table will store:\n",
    "\n",
    "- **user_id**: Unique user identifier\n",
    "- **engagement_date**: Date and time of engagement\n",
    "- **content_type**: Type (Video, Article, Podcast, Live Stream)\n",
    "- **watch_time**: Time spent consuming content (minutes)\n",
    "- **content_id**: Specific content identifier\n",
    "- **engagement_score**: User engagement metric (0-100)\n",
    "- **device_type**: Device used (Mobile, Desktop, TV, etc.)\n",
    "\n",
    "### Clustering Strategy\n",
    "\n",
    "We'll cluster by `user_id` and `engagement_date` because:\n",
    "\n",
    "- **user_id**: Users consume multiple pieces of content, grouping their viewing history together\n",
    "- **engagement_date**: Time-based queries are critical for content performance analysis, recommendation systems, and user behavior trends\n",
    "- This combination optimizes for both personalized content recommendations and temporal engagement analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T19:17:53.796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delta table with Iceberg compatibility and liquid clustering created successfully!\n",
       "Universal format enables Iceberg features while CLUSTER BY (columns) optimizes data layout.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Delta table with liquid clustering\n",
    "\n",
    "# CLUSTER BY defines the columns for automatic optimization\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "data_schema = StructType([\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"engagement_date\", TimestampType(), True),\n",
    "    StructField(\"content_type\", StringType(), True),\n",
    "    StructField(\"watch_time\", DoubleType(), True),\n",
    "    StructField(\"content_id\", StringType(), True),\n",
    "    StructField(\"engagement_score\", IntegerType(), True),\n",
    "    StructField(\"device_type\", StringType(), True)\n",
    "])\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS media.analytics.content_engagement_uf (\n",
    "    user_id STRING,\n",
    "    engagement_date TIMESTAMP,\n",
    "    content_type STRING,\n",
    "    watch_time DECIMAL(8,2),\n",
    "    content_id STRING,\n",
    "    engagement_score INT,\n",
    "    device_type STRING\n",
    ")\n",
    "\n",
    "USING DELTA\n",
    "\n",
    "TBLPROPERTIES('delta.universalFormat.enabledFormats' = 'iceberg') CLUSTER BY (user_id, engagement_date)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"Delta table with Iceberg compatibility and liquid clustering created successfully!\")\n",
    "\n",
    "print(\"Universal format enables Iceberg features while CLUSTER BY (columns) optimizes data layout.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Media Sample Data\n",
    "\n",
    "### Data Generation Strategy\n",
    "\n",
    "We'll create realistic media engagement data including:\n",
    "\n",
    "- **12,000 users** with multiple content interactions over time\n",
    "- **Content types**: Video, Article, Podcast, Live Stream\n",
    "- **Realistic engagement patterns**: Peak viewing times, content preferences, device usage\n",
    "- **Engagement metrics**: Watch time, completion rates, interaction scores\n",
    "\n",
    "### Why This Data Pattern?\n",
    "\n",
    "This data simulates real media scenarios where:\n",
    "\n",
    "- User preferences drive content recommendations\n",
    "- Engagement metrics determine content success\n",
    "- Device usage affects viewing experience\n",
    "- Time-based patterns influence programming decisions\n",
    "- Personalization requires historical user behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T19:18:01.184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generated 300771 content engagement records\n",
       "Sample record: {'user_id': 'USER000001', 'engagement_date': datetime.datetime(2024, 11, 25, 9, 29), 'content_type': 'Video', 'watch_time': 25.22, 'content_id': 'VID16142', 'engagement_score': 77, 'device_type': 'Smart TV'}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample media engagement data\n",
    "\n",
    "# Using fully qualified imports to avoid conflicts\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define media data constants\n",
    "\n",
    "CONTENT_TYPES = ['Video', 'Article', 'Podcast', 'Live Stream']\n",
    "\n",
    "DEVICE_TYPES = ['Mobile', 'Desktop', 'Tablet', 'Smart TV', 'Gaming Console']\n",
    "\n",
    "# Base engagement parameters by content type\n",
    "\n",
    "ENGAGEMENT_PARAMS = {\n",
    "\n",
    "    'Video': {'avg_watch_time': 15, 'engagement_base': 75, 'frequency': 12},\n",
    "\n",
    "    'Article': {'avg_watch_time': 8, 'engagement_base': 65, 'frequency': 8},\n",
    "\n",
    "    'Podcast': {'avg_watch_time': 25, 'engagement_base': 70, 'frequency': 6},\n",
    "\n",
    "    'Live Stream': {'avg_watch_time': 45, 'engagement_base': 80, 'frequency': 4}\n",
    "\n",
    "}\n",
    "\n",
    "# Device engagement multipliers\n",
    "\n",
    "DEVICE_MULTIPLIERS = {\n",
    "\n",
    "    'Mobile': 0.9, 'Desktop': 1.0, 'Tablet': 0.95, 'Smart TV': 1.1, 'Gaming Console': 1.05\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Generate content engagement records\n",
    "\n",
    "engagement_data = []\n",
    "\n",
    "base_date = datetime(2024, 1, 1)\n",
    "\n",
    "\n",
    "# Create 12,000 users with 10-40 engagement events each\n",
    "\n",
    "for user_num in range(1, 12001):\n",
    "\n",
    "    user_id = f\"USER{user_num:06d}\"\n",
    "    \n",
    "    # Each user gets 10-40 engagement events over 12 months\n",
    "\n",
    "    num_engagements = random.randint(10, 40)\n",
    "    \n",
    "    for i in range(num_engagements):\n",
    "\n",
    "        # Spread engagements over 12 months\n",
    "\n",
    "        days_offset = random.randint(0, 365)\n",
    "\n",
    "        engagement_date = base_date + timedelta(days=days_offset)\n",
    "        \n",
    "        # Add realistic timing (more engagement during certain hours)\n",
    "\n",
    "        hour_weights = [2, 1, 1, 1, 1, 1, 3, 6, 8, 7, 6, 7, 8, 9, 10, 9, 8, 10, 12, 9, 7, 5, 4, 3]\n",
    "\n",
    "        hours_offset = random.choices(range(24), weights=hour_weights)[0]\n",
    "\n",
    "        engagement_date = engagement_date.replace(hour=hours_offset, minute=random.randint(0, 59), second=0, microsecond=0)\n",
    "        \n",
    "        # Select content type\n",
    "\n",
    "        content_type = random.choice(CONTENT_TYPES)\n",
    "\n",
    "        params = ENGAGEMENT_PARAMS[content_type]\n",
    "        \n",
    "        # Select device type\n",
    "\n",
    "        device_type = random.choice(DEVICE_TYPES)\n",
    "\n",
    "        device_multiplier = DEVICE_MULTIPLIERS[device_type]\n",
    "        \n",
    "        # Calculate watch time with variations\n",
    "\n",
    "        time_variation = random.uniform(0.3, 2.5)\n",
    "\n",
    "        watch_time = round(params['avg_watch_time'] * time_variation * device_multiplier, 2)\n",
    "        \n",
    "        # Content ID\n",
    "\n",
    "        content_id = f\"{content_type[:3].upper()}{random.randint(10000, 99999)}\"\n",
    "        \n",
    "        # Engagement score (based on content type, device, and some randomness)\n",
    "\n",
    "        engagement_variation = random.randint(-15, 15)\n",
    "\n",
    "        engagement_score = max(0, min(100, int(params['engagement_base'] * device_multiplier) + engagement_variation))\n",
    "        \n",
    "        engagement_data.append({\n",
    "\n",
    "            \"user_id\": user_id,\n",
    "\n",
    "            \"engagement_date\": engagement_date,\n",
    "\n",
    "            \"content_type\": content_type,\n",
    "\n",
    "            \"watch_time\": watch_time,\n",
    "\n",
    "            \"content_id\": content_id,\n",
    "\n",
    "            \"engagement_score\": engagement_score,\n",
    "\n",
    "            \"device_type\": device_type\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Generated {len(engagement_data)} content engagement records\")\n",
    "\n",
    "print(\"Sample record:\", engagement_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Insert Data Using PySpark\n",
    "\n",
    "### Data Insertion Strategy\n",
    "\n",
    "We'll use PySpark to:\n",
    "\n",
    "1. **Create DataFrame** from our generated data\n",
    "2. **Insert into Delta table** with liquid clustering\n",
    "3. **Verify the insertion** with a sample query\n",
    "\n",
    "### Why PySpark for Insertion?\n",
    "\n",
    "- **Distributed processing**: Handles large datasets efficiently\n",
    "- **Type safety**: Ensures data integrity\n",
    "- **Optimization**: Leverages Spark's query optimization\n",
    "- **Liquid clustering**: Automatically applies clustering during insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T19:18:17.628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame Schema:\n",
       "root\n",
       " |-- user_id: string (nullable = true)\n",
       " |-- engagement_date: timestamp (nullable = true)\n",
       " |-- content_type: string (nullable = true)\n",
       " |-- watch_time: double (nullable = true)\n",
       " |-- content_id: string (nullable = true)\n",
       " |-- engagement_score: integer (nullable = true)\n",
       " |-- device_type: string (nullable = true)\n",
       "\n",
       "\n",
       "Sample Data:\n",
       "+----------+-------------------+------------+----------+----------+----------------+--------------+\n",
       "|   user_id|    engagement_date|content_type|watch_time|content_id|engagement_score|   device_type|\n",
       "+----------+-------------------+------------+----------+----------+----------------+--------------+\n",
       "|USER000001|2024-11-25 09:29:00|       Video|     25.22|  VID16142|              77|      Smart TV|\n",
       "|USER000001|2024-06-25 22:51:00|     Podcast|     19.84|  POD74343|              80|Gaming Console|\n",
       "|USER000001|2024-05-19 17:06:00| Live Stream|     89.71|  LIV77628|              79|Gaming Console|\n",
       "|USER000001|2024-07-28 21:15:00|     Podcast|     23.12|  POD90271|              58|        Mobile|\n",
       "|USER000001|2024-02-16 19:07:00|       Video|     29.09|  VID33249|              84|      Smart TV|\n",
       "+----------+-------------------+------------+----------+----------+----------------+--------------+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Successfully inserted 300771 records into media.analytics.content_engagement_uf\n",
       "Liquid clustering automatically optimized the data layout during insertion!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert data using PySpark DataFrame operations\n",
    "\n",
    "# Using fully qualified function references to avoid conflicts\n",
    "\n",
    "\n",
    "# Create DataFrame from generated data\n",
    "\n",
    "df_engagement = spark.createDataFrame(engagement_data, schema=data_schema)\n",
    "\n",
    "\n",
    "# Display schema and sample data\n",
    "\n",
    "print(\"DataFrame Schema:\")\n",
    "\n",
    "df_engagement.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "\n",
    "df_engagement.show(5)\n",
    "\n",
    "\n",
    "# Insert data into Delta table with liquid clustering\n",
    "\n",
    "# The TBLPROPERTIES('delta.universalFormat.enabledFormats' = 'iceberg') CLUSTER BY (user_id, engagement_date) will automatically optimize the data layout\n",
    "\n",
    "df_engagement.write.mode(\"overwrite\").insertInto(\"media.analytics.content_engagement_uf\")\n",
    "\n",
    "\n",
    "print(f\"\\nSuccessfully inserted {df_engagement.count()} records into media.analytics.content_engagement_uf\")\n",
    "\n",
    "print(\"Liquid clustering automatically optimized the data layout during insertion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate Liquid Clustering Benefits\n",
    "\n",
    "### Query Performance Analysis\n",
    "\n",
    "Now let's see how liquid clustering improves query performance. We'll run queries that benefit from our clustering strategy:\n",
    "\n",
    "1. **User engagement history** (clustered by user_id)\n",
    "2. **Time-based content analysis** (clustered by engagement_date)\n",
    "3. **Combined user + time queries** (optimal for our clustering)\n",
    "\n",
    "### Expected Performance Benefits\n",
    "\n",
    "With liquid clustering, these queries should be significantly faster because:\n",
    "\n",
    "- **Data locality**: Related records are physically grouped together\n",
    "- **Reduced I/O**: Less data needs to be read from disk\n",
    "- **Automatic optimization**: No manual tuning required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T19:18:37.061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Query 1: User Engagement History ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+------------+----------+----------------+\n",
       "|   user_id|    engagement_date|content_type|watch_time|engagement_score|\n",
       "+----------+-------------------+------------+----------+----------------+\n",
       "|USER000001|2024-12-11 13:14:00| Live Stream|     37.69|              84|\n",
       "|USER000001|2024-12-01 11:34:00|     Podcast|     23.76|              71|\n",
       "|USER000001|2024-11-25 09:29:00|       Video|     25.22|              77|\n",
       "|USER000001|2024-10-31 11:12:00|     Podcast|     44.24|              78|\n",
       "|USER000001|2024-09-30 20:12:00|     Article|      9.16|              60|\n",
       "|USER000001|2024-07-28 21:15:00|     Podcast|     23.12|              58|\n",
       "|USER000001|2024-07-04 08:19:00|     Article|     17.52|              57|\n",
       "|USER000001|2024-06-25 22:51:00|     Podcast|     19.84|              80|\n",
       "|USER000001|2024-06-24 00:50:00| Live Stream|     39.48|              88|\n",
       "|USER000001|2024-05-19 17:06:00| Live Stream|     89.71|              79|\n",
       "+----------+-------------------+------------+----------+----------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Records found: 10\n",
       "\n",
       "=== Query 2: Recent High-Engagement Content ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------------+----------+----------+------------+----------------+----------+\n",
       "|    engagement_date|   user_id|content_id|content_type|engagement_score|watch_time|\n",
       "+-------------------+----------+----------+------------+----------------+----------+\n",
       "|2024-02-15 13:16:00|USER001757|  LIV68728| Live Stream|             100|    116.08|\n",
       "|2024-02-15 11:23:00|USER007306|  LIV28859| Live Stream|             100|    105.36|\n",
       "|2024-02-15 18:32:00|USER005814|  LIV85937| Live Stream|             100|    101.34|\n",
       "|2024-02-15 13:01:00|USER008486|  LIV35187| Live Stream|             100|     97.15|\n",
       "|2024-02-15 08:01:00|USER002750|  LIV83892| Live Stream|             100|     84.93|\n",
       "|2024-02-15 14:44:00|USER008331|  LIV76007| Live Stream|             100|     77.00|\n",
       "|2024-02-15 22:57:00|USER007024|  LIV86996| Live Stream|             100|     20.17|\n",
       "|2024-02-15 20:56:00|USER001844|  LIV34873| Live Stream|              99|     67.04|\n",
       "|2024-02-15 13:02:00|USER003599|  LIV99017| Live Stream|              99|     34.64|\n",
       "|2024-02-15 14:47:00|USER008129|  LIV61687| Live Stream|              97|    105.07|\n",
       "|2024-02-15 14:52:00|USER010286|  LIV74366| Live Stream|              97|     61.80|\n",
       "|2024-02-15 22:43:00|USER010619|  VID52526|       Video|              97|     20.06|\n",
       "|2024-02-15 18:03:00|USER002165|  VID37576|       Video|              97|     13.51|\n",
       "|2024-02-15 15:27:00|USER003734|  LIV32304| Live Stream|              95|    102.77|\n",
       "|2024-02-15 09:56:00|USER003084|  LIV69097| Live Stream|              95|     94.12|\n",
       "|2024-02-15 19:35:00|USER010276|  LIV87646| Live Stream|              95|     86.49|\n",
       "|2024-02-15 10:42:00|USER006212|  LIV47336| Live Stream|              95|     71.07|\n",
       "|2024-02-15 09:48:00|USER003981|  LIV78863| Live Stream|              95|     55.65|\n",
       "|2024-02-15 17:27:00|USER011107|  LIV69583| Live Stream|              95|     43.39|\n",
       "|2024-02-15 17:24:00|USER005234|  VID64239|       Video|              95|     24.42|\n",
       "+-------------------+----------+----------+------------+----------------+----------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "High-engagement records found: 110\n",
       "\n",
       "=== Query 3: User Content Preferences ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+------------+----------+--------------+\n",
       "|   user_id|    engagement_date|content_type|watch_time|   device_type|\n",
       "+----------+-------------------+------------+----------+--------------+\n",
       "|USER000001|2024-02-16 19:07:00|       Video|     29.09|      Smart TV|\n",
       "|USER000001|2024-03-23 10:43:00|     Podcast|     40.37|        Mobile|\n",
       "|USER000001|2024-03-26 04:24:00|     Article|     13.69|Gaming Console|\n",
       "|USER000001|2024-04-06 20:43:00|     Article|      3.23|        Mobile|\n",
       "|USER000001|2024-05-19 17:06:00| Live Stream|     89.71|Gaming Console|\n",
       "|USER000001|2024-06-24 00:50:00| Live Stream|     39.48|      Smart TV|\n",
       "|USER000001|2024-06-25 22:51:00|     Podcast|     19.84|Gaming Console|\n",
       "|USER000001|2024-07-04 08:19:00|     Article|     17.52|       Desktop|\n",
       "|USER000001|2024-07-28 21:15:00|     Podcast|     23.12|        Mobile|\n",
       "|USER000001|2024-09-30 20:12:00|     Article|      9.16|        Tablet|\n",
       "|USER000001|2024-10-31 11:12:00|     Podcast|     44.24|        Tablet|\n",
       "|USER000001|2024-11-25 09:29:00|       Video|     25.22|      Smart TV|\n",
       "|USER000001|2024-12-01 11:34:00|     Podcast|     23.76|        Mobile|\n",
       "|USER000001|2024-12-11 13:14:00| Live Stream|     37.69|      Smart TV|\n",
       "|USER000002|2024-04-11 08:51:00|     Article|     15.52|      Smart TV|\n",
       "|USER000002|2024-04-24 09:03:00|     Article|      4.47|       Desktop|\n",
       "|USER000002|2024-05-07 23:59:00| Live Stream|     93.05|      Smart TV|\n",
       "|USER000002|2024-05-14 19:58:00| Live Stream|     18.33|Gaming Console|\n",
       "|USER000002|2024-06-24 15:17:00|     Podcast|     22.50|Gaming Console|\n",
       "|USER000002|2024-07-11 15:07:00| Live Stream|     88.84|        Mobile|\n",
       "+----------+-------------------+------------+----------+--------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "User preference records found: 25\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate liquid clustering benefits with optimized queries\n",
    "\n",
    "\n",
    "# Query 1: User engagement history - benefits from user_id clustering\n",
    "\n",
    "print(\"=== Query 1: User Engagement History ===\")\n",
    "\n",
    "user_history = spark.sql(\"\"\"\n",
    "\n",
    "SELECT user_id, engagement_date, content_type, watch_time, engagement_score\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "WHERE user_id = 'USER000001'\n",
    "\n",
    "ORDER BY engagement_date DESC\n",
    "\n",
    "LIMIT 10\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "user_history.show()\n",
    "\n",
    "print(f\"Records found: {user_history.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 2: Time-based high-engagement content analysis - benefits from engagement_date clustering\n",
    "\n",
    "print(\"\\n=== Query 2: Recent High-Engagement Content ===\")\n",
    "\n",
    "high_engagement = spark.sql(\"\"\"\n",
    "\n",
    "SELECT engagement_date, user_id, content_id, content_type, engagement_score, watch_time\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "WHERE DATE(engagement_date) = '2024-02-15' AND engagement_score > 85\n",
    "\n",
    "ORDER BY engagement_score DESC, watch_time DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "high_engagement.show()\n",
    "\n",
    "print(f\"High-engagement records found: {high_engagement.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 3: Combined user + time query - optimal for our clustering strategy\n",
    "\n",
    "print(\"\\n=== Query 3: User Content Preferences ===\")\n",
    "\n",
    "user_preferences = spark.sql(\"\"\"\n",
    "\n",
    "SELECT user_id, engagement_date, content_type, watch_time, device_type\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "WHERE user_id LIKE 'USER000%' AND engagement_date >= '2024-02-01'\n",
    "\n",
    "ORDER BY user_id, engagement_date\n",
    "\n",
    "LIMIT 25\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "user_preferences.show()\n",
    "\n",
    "print(f\"User preference records found: {user_preferences.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Clustering Effectiveness\n",
    "\n",
    "### Understanding the Impact\n",
    "\n",
    "Let's examine how liquid clustering has organized our data and analyze some aggregate statistics to demonstrate the media insights possible with this optimized structure.\n",
    "\n",
    "### Key Analytics\n",
    "\n",
    "- **User engagement patterns** and content preferences\n",
    "- **Content performance** by type and popularity metrics\n",
    "- **Device usage trends** and platform optimization\n",
    "- **Time-based consumption patterns** and programming insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T19:18:59.651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== User Engagement Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------+----------------+----------------+--------------+------------------+\n",
       "|   user_id|total_sessions|total_watch_time|avg_session_time|avg_engagement|content_types_used|\n",
       "+----------+--------------+----------------+----------------+--------------+------------------+\n",
       "|USER007757|            40|         1786.04|           44.65|         71.45|                 4|\n",
       "|USER006953|            38|         1779.15|           46.82|         71.37|                 4|\n",
       "|USER009153|            32|         1766.97|           55.22|         76.38|                 4|\n",
       "|USER004023|            38|         1765.27|           46.45|         72.34|                 4|\n",
       "|USER011324|            40|         1751.78|           43.79|          73.4|                 4|\n",
       "|USER007714|            38|         1746.63|           45.96|         71.61|                 4|\n",
       "|USER005489|            38|         1731.22|           45.56|         73.16|                 4|\n",
       "|USER006643|            40|         1729.31|           43.23|          74.3|                 4|\n",
       "|USER000106|            36|         1728.68|           48.02|         73.94|                 4|\n",
       "|USER011924|            40|         1719.03|           42.98|         74.43|                 4|\n",
       "+----------+--------------+----------------+----------------+--------------+------------------+\n",
       "\n",
       "\n",
       "=== Content Type Performance ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+------------+-----------------+----------------+--------------+--------------+------------+--------------+\n",
       "|content_type|total_engagements|total_watch_time|avg_watch_time|avg_engagement|unique_users|unique_content|\n",
       "+------------+-----------------+----------------+--------------+--------------+------------+--------------+\n",
       "| Live Stream|            75343|      4760788.06|         63.19|         79.91|       11906|         50968|\n",
       "|     Podcast|            75155|      2630926.58|         35.01|         69.74|       11915|         50896|\n",
       "|       Video|            75314|      1584940.33|         21.04|         74.64|       11910|         50942|\n",
       "|     Article|            74959|       838960.65|         11.19|         64.61|       11909|         51014|\n",
       "+------------+-----------------+----------------+--------------+--------------+------------+--------------+\n",
       "\n",
       "\n",
       "=== Device Usage Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+--------------+--------------+----------------+----------------+--------------+------------+\n",
       "|   device_type|total_sessions|total_watch_time|avg_session_time|avg_engagement|unique_users|\n",
       "+--------------+--------------+----------------+----------------+--------------+------------+\n",
       "|      Smart TV|         60479|      2167853.26|           35.84|         79.49|       11789|\n",
       "|Gaming Console|         60124|      2064190.85|           34.33|          75.7|       11813|\n",
       "|       Desktop|         59997|      1950615.35|           32.51|         72.44|       11789|\n",
       "|        Tablet|         59849|      1862777.95|           31.12|         68.52|       11771|\n",
       "|        Mobile|         60322|      1770178.21|           29.35|          65.0|       11790|\n",
       "+--------------+--------------+----------------+----------------+--------------+------------+\n",
       "\n",
       "\n",
       "=== Hourly Engagement Patterns ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-----------+-----------------+----------------+--------------+------------+\n",
       "|hour_of_day|engagement_events|total_watch_time|avg_engagement|active_users|\n",
       "+-----------+-----------------+----------------+--------------+------------+\n",
       "|          0|               13|          361.49|          67.0|          13|\n",
       "|          1|                2|           60.02|          65.5|           2|\n",
       "|          2|               12|          237.20|          71.0|          12|\n",
       "|          3|                3|           33.81|          64.0|           3|\n",
       "|          4|                3|           65.32|         72.67|           3|\n",
       "|          5|                1|           28.42|          73.0|           1|\n",
       "|          6|               19|          557.21|         68.79|          19|\n",
       "|          7|               39|         1311.27|         74.69|          39|\n",
       "|          8|               50|         1492.66|          71.4|          50|\n",
       "|          9|               40|         1211.88|          72.4|          40|\n",
       "|         10|               26|          949.73|         71.08|          26|\n",
       "|         11|               41|         1283.62|          72.0|          41|\n",
       "|         12|               31|         1046.42|         71.48|          31|\n",
       "|         13|               44|         1374.62|         72.93|          43|\n",
       "|         14|               62|         2031.39|         73.21|          62|\n",
       "|         15|               51|         1869.34|         71.65|          51|\n",
       "|         16|               46|         1363.29|         70.61|          46|\n",
       "|         17|               65|         2307.75|         72.38|          64|\n",
       "|         18|               71|         2052.38|         70.89|          71|\n",
       "|         19|               43|         1270.01|         70.74|          43|\n",
       "+-----------+-----------------+----------------+--------------+------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "\n",
       "=== Monthly Engagement Trends ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------+-----------------+------------------+----------------+--------------+------------+\n",
       "|  month|total_engagements|monthly_watch_time|avg_session_time|avg_engagement|active_users|\n",
       "+-------+-----------------+------------------+----------------+--------------+------------+\n",
       "|2024-01|            25469|         835801.11|           32.82|          72.3|       10295|\n",
       "|2024-02|            23976|         784023.26|           32.70|         72.17|       10071|\n",
       "|2024-03|            25635|         838410.60|           32.71|         72.21|       10238|\n",
       "|2024-04|            24772|         802608.23|           32.40|         72.08|       10116|\n",
       "|2024-05|            25101|         811778.86|           32.34|         72.31|       10201|\n",
       "|2024-06|            24789|         804955.18|           32.47|         72.25|       10191|\n",
       "|2024-07|            25280|         830363.38|           32.85|         72.27|       10212|\n",
       "|2024-08|            25586|         831211.87|           32.49|         72.25|       10244|\n",
       "|2024-09|            24572|         802709.35|           32.67|         72.28|       10149|\n",
       "|2024-10|            25312|         832915.73|           32.91|         72.19|       10199|\n",
       "|2024-11|            24678|         809446.28|           32.80|         72.33|       10073|\n",
       "|2024-12|            25601|         831391.77|           32.47|         72.21|       10251|\n",
       "+-------+-----------------+------------------+----------------+--------------+------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze clustering effectiveness and media insights\n",
    "\n",
    "\n",
    "# User engagement analysis\n",
    "\n",
    "print(\"=== User Engagement Analysis ===\")\n",
    "\n",
    "user_engagement = spark.sql(\"\"\"\n",
    "\n",
    "SELECT user_id, COUNT(*) as total_sessions,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_session_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT content_type) as content_types_used\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "GROUP BY user_id\n",
    "\n",
    "ORDER BY total_watch_time DESC\n",
    "\n",
    "LIMIT 10\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "user_engagement.show()\n",
    "\n",
    "\n",
    "# Content type performance\n",
    "\n",
    "print(\"\\n=== Content Type Performance ===\")\n",
    "\n",
    "content_performance = spark.sql(\"\"\"\n",
    "\n",
    "SELECT content_type, COUNT(*) as total_engagements,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_watch_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as unique_users,\n",
    "\n",
    "       COUNT(DISTINCT content_id) as unique_content\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "GROUP BY content_type\n",
    "\n",
    "ORDER BY total_watch_time DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "content_performance.show()\n",
    "\n",
    "\n",
    "# Device usage analysis\n",
    "\n",
    "print(\"\\n=== Device Usage Analysis ===\")\n",
    "\n",
    "device_analysis = spark.sql(\"\"\"\n",
    "\n",
    "SELECT device_type, COUNT(*) as total_sessions,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_session_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as unique_users\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "GROUP BY device_type\n",
    "\n",
    "ORDER BY total_watch_time DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "device_analysis.show()\n",
    "\n",
    "\n",
    "# Hourly engagement patterns\n",
    "\n",
    "print(\"\\n=== Hourly Engagement Patterns ===\")\n",
    "\n",
    "hourly_patterns = spark.sql(\"\"\"\n",
    "\n",
    "SELECT HOUR(engagement_date) as hour_of_day, COUNT(*) as engagement_events,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as active_users\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "WHERE DATE(engagement_date) = '2024-02-01'\n",
    "\n",
    "GROUP BY HOUR(engagement_date)\n",
    "\n",
    "ORDER BY hour_of_day\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "hourly_patterns.show()\n",
    "\n",
    "\n",
    "# Monthly engagement trends\n",
    "\n",
    "print(\"\\n=== Monthly Engagement Trends ===\")\n",
    "\n",
    "monthly_trends = spark.sql(\"\"\"\n",
    "\n",
    "SELECT DATE_FORMAT(engagement_date, 'yyyy-MM') as month,\n",
    "\n",
    "       COUNT(*) as total_engagements,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as monthly_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_session_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as active_users\n",
    "\n",
    "FROM media.analytics.content_engagement_uf\n",
    "\n",
    "GROUP BY DATE_FORMAT(engagement_date, 'yyyy-MM')\n",
    "\n",
    "ORDER BY month\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "monthly_trends.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: Iceberg and Liquid Clustering in AIDP\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Automatic Optimization**: Created a table with `TBLPROPERTIES('delta.universalFormat.enabledFormats' = 'iceberg') CLUSTER BY (user_id, engagement_date)` and let Delta automatically optimize data layout\n",
    "\n",
    "2. **Performance Benefits**: Queries on clustered columns (user_id, engagement_date) are significantly faster due to data locality\n",
    "\n",
    "3. **Zero Maintenance**: No manual partitioning, bucketing, or Z-Ordering required - Delta handles it automatically\n",
    "\n",
    "4. **Real-World Use Case**: Media analytics where content engagement and user behavior analysis are critical\n",
    "\n",
    "### AIDP Advantages\n",
    "\n",
    "- **Unified Analytics**: Seamlessly integrates with other AIDP services\n",
    "- **Governance**: Catalog and schema isolation for media data\n",
    "- **Performance**: Optimized for both OLAP and OLTP workloads\n",
    "- **Scalability**: Handles media-scale data volumes effortlessly\n",
    "\n",
    "### Best Practices for Iceberg and Liquid Clustering\n",
    "\n",
    "1. **Choose clustering columns** based on your most common query patterns\n",
    "2. **Start with 1-4 columns** - too many can reduce effectiveness\n",
    "3. **Consider cardinality** - high-cardinality columns work best\n",
    "4. **Monitor and adjust** as query patterns evolve\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore other AIDP features like AI/ML integration\n",
    "- Try liquid clustering with different column combinations\n",
    "- Scale up to larger media datasets\n",
    "- Integrate with real content management and streaming platforms\n",
    "\n",
    "This notebook demonstrates how Oracle AI Data Platform combines Delta's advanced liquid clustering with Iceberg's open, future-proof architecture to deliver enterprise-grade analytics that are both high-performance and standards-compliant."
   ]
  }
 ],
 "metadata": {
  "Last_Active_Cell_Index": 3,
  "kernelspec": {
   "name": "notebook"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
