{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# telecommunications: Iceberg and Liquid Clustering Demo\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "This notebook demonstrates the power of **Iceberg and Liquid Clustering** in Oracle AI Data Platform (AIDP) Workbench using a telecommunications analytics use case. Liquid clustering automatically optimizes data layout for query performance without requiring manual partitioning or Z-Ordering.\n",
    "\n",
    "### What is Iceberg?\n",
    "\n",
    "Apache Iceberg is an open table format for huge analytic datasets that provides:\n",
    "\n",
    "- **Schema evolution**: Add, drop, rename, update columns without rewriting data\n",
    "- **Partition evolution**: Change partitioning without disrupting queries\n",
    "- **Time travel**: Query historical data snapshots for auditing and rollback\n",
    "- **ACID transactions**: Reliable concurrent read/write operations\n",
    "- **Cross-engine compatibility**: Works with Spark, Flink, Presto, Hive, and more\n",
    "- **Open ecosystem**: Apache 2.0 licensed, community-driven development\n",
    "\n",
    "### Delta Universal Format with Iceberg\n",
    "\n",
    "Delta Universal Format enables Iceberg compatibility while maintaining Delta's advanced features like liquid clustering. This combination provides:\n",
    "\n",
    "- **Best of both worlds**: Delta's performance optimizations with Iceberg's openness\n",
    "- **Multi-engine access**: Query the same data from different analytics engines\n",
    "- **Future-proof architecture**: Standards-based approach for long-term data investments\n",
    "- **Enhanced governance**: Rich metadata and catalog integration\n",
    "\n",
    "### What is Liquid Clustering?\n",
    "\n",
    "Liquid clustering automatically identifies and groups similar data together based on clustering columns you define. This optimization happens automatically during data ingestion and maintenance operations, providing:\n",
    "\n",
    "- **Automatic optimization**: No manual tuning required\n",
    "- **Improved query performance**: Faster queries on clustered columns\n",
    "- **Reduced maintenance**: No need for manual repartitioning\n",
    "- **Adaptive clustering**: Adjusts as data patterns change\n",
    "\n",
    "### Use Case: Network Performance Monitoring and Customer Experience Analytics\n",
    "\n",
    "We'll analyze telecommunications network performance and customer usage data. Our clustering strategy will optimize for:\n",
    "\n",
    "- **Customer-specific queries**: Fast lookups by subscriber ID\n",
    "- **Time-based analysis**: Efficient filtering by call/service date\n",
    "- **Network performance patterns**: Quick aggregation by cell tower and service quality metrics\n",
    "\n",
    "### AIDP Environment Setup\n",
    "\n",
    "This notebook leverages the existing Spark session in your AIDP environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T15:34:15.593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Telecommunications catalog and analytics schema created successfully!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create telecommunications catalog and analytics schema\n",
    "\n",
    "# In AIDP, catalogs provide data isolation and governance\n",
    "\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS telecom\")\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS telecom.analytics\")\n",
    "\n",
    "print(\"Telecommunications catalog and analytics schema created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Delta Table with Liquid Clustering\n",
    "\n",
    "### Table Design\n",
    "\n",
    "Our `network_usage_uf` table will store:\n",
    "\n",
    "- **subscriber_id**: Unique customer identifier\n",
    "- **usage_date**: Date and time of service usage\n",
    "- **service_type**: Type (Voice, Data, SMS, Streaming)\n",
    "- **data_volume**: Data consumed (GB)\n",
    "- **call_duration**: Call length (minutes)\n",
    "- **cell_tower_id**: Network cell tower identifier\n",
    "- **signal_quality**: Network signal strength (0-100)\n",
    "\n",
    "### Clustering Strategy\n",
    "\n",
    "We'll cluster by `subscriber_id` and `usage_date` because:\n",
    "\n",
    "- **subscriber_id**: Customers generate multiple service interactions, grouping their usage patterns together\n",
    "- **usage_date**: Time-based queries are critical for billing cycles, network planning, and customer behavior analysis\n",
    "- This combination optimizes for both customer analytics and temporal network performance monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T18:39:28.195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delta table with Iceberg compatibility and liquid clustering created successfully!\n",
       "Universal format enables Iceberg features while CLUSTER BY (columns) optimizes data layout.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Delta table with liquid clustering\n",
    "\n",
    "# CLUSTER BY defines the columns for automatic optimization\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType, TimestampType\n",
    "data_schema = StructType([\n",
    "    StructField(\"subscriber_id\", StringType(), True),\n",
    "    StructField(\"usage_date\", TimestampType(), True),\n",
    "    StructField(\"service_type\", StringType(), True),\n",
    "    StructField(\"data_volume\", DoubleType(), True),\n",
    "    StructField(\"call_duration\", DoubleType(), True),\n",
    "    StructField(\"cell_tower_id\", StringType(), True),\n",
    "    StructField(\"signal_quality\", IntegerType(), True)])\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS telecom.analytics.network_usage_uf (\n",
    "    subscriber_id STRING,\n",
    "    usage_date TIMESTAMP,\n",
    "    service_type STRING,\n",
    "    data_volume DECIMAL(10,3),\n",
    "    call_duration DECIMAL(8,2),\n",
    "    cell_tower_id STRING,\n",
    "    signal_quality INT\n",
    "\n",
    ")\n",
    "\n",
    "USING DELTA\n",
    "\n",
    "TBLPROPERTIES('delta.universalFormat.enabledFormats' = 'iceberg') CLUSTER BY (subscriber_id, usage_date)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"Delta table with Iceberg compatibility and liquid clustering created successfully!\")\n",
    "\n",
    "print(\"Universal format enables Iceberg features while CLUSTER BY (columns) optimizes data layout.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Telecommunications Sample Data\n",
    "\n",
    "### Data Generation Strategy\n",
    "\n",
    "We'll create realistic telecommunications usage data including:\n",
    "\n",
    "- **10,000 subscribers** with multiple service interactions over time\n",
    "- **Service types**: Voice calls, Data usage, SMS, Video streaming\n",
    "- **Realistic usage patterns**: Peak hours, weekend vs weekday patterns, roaming\n",
    "- **Network infrastructure**: Multiple cell towers with varying signal quality\n",
    "\n",
    "### Why This Data Pattern?\n",
    "\n",
    "This data simulates real telecommunications scenarios where:\n",
    "\n",
    "- Customer usage varies by time of day and service type\n",
    "- Network performance impacts customer experience\n",
    "- Billing and service quality require temporal analysis\n",
    "- Capacity planning depends on usage patterns\n",
    "- Fraud detection needs real-time monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T18:35:30.778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generated 600441 network usage records\n",
       "Sample record: {'subscriber_id': 'SUB00000001', 'usage_date': datetime.datetime(2024, 10, 11, 9, 9), 'service_type': 'Voice', 'data_volume': 0.0, 'call_duration': 6.73, 'cell_tower_id': 'TOWER_CHI_003', 'signal_quality': 65}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample telecommunications usage data\n",
    "\n",
    "# Using fully qualified imports to avoid conflicts\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define telecommunications data constants\n",
    "\n",
    "SERVICE_TYPES = ['Voice', 'Data', 'SMS', 'Streaming']\n",
    "\n",
    "CELL_TOWERS = ['TOWER_NYC_001', 'TOWER_LAX_002', 'TOWER_CHI_003', 'TOWER_HOU_004', 'TOWER_MIA_005', 'TOWER_SFO_006', 'TOWER_SEA_007']\n",
    "\n",
    "# Base usage parameters by service type\n",
    "\n",
    "USAGE_PARAMS = {\n",
    "\n",
    "    'Voice': {'avg_duration': 5.0, 'frequency': 8, 'data_volume': 0.0},\n",
    "\n",
    "    'Data': {'avg_duration': 0.0, 'frequency': 15, 'data_volume': 0.5},\n",
    "\n",
    "    'SMS': {'avg_duration': 0.0, 'frequency': 12, 'data_volume': 0.0},\n",
    "\n",
    "    'Streaming': {'avg_duration': 0.0, 'frequency': 6, 'data_volume': 2.0}\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Generate network usage records\n",
    "\n",
    "usage_data = []\n",
    "\n",
    "base_date = datetime(2024, 1, 1)\n",
    "\n",
    "\n",
    "# Create 10,000 subscribers with 20-100 usage events each\n",
    "\n",
    "for subscriber_num in range(1, 10001):\n",
    "\n",
    "    subscriber_id = f\"SUB{subscriber_num:08d}\"\n",
    "    \n",
    "    # Each subscriber gets 20-100 usage events over 12 months\n",
    "\n",
    "    num_events = random.randint(20, 100)\n",
    "    \n",
    "    for i in range(num_events):\n",
    "\n",
    "        # Spread usage events over 12 months\n",
    "\n",
    "        days_offset = random.randint(0, 365)\n",
    "\n",
    "        usage_date = base_date + timedelta(days=days_offset)\n",
    "        \n",
    "        # Add realistic timing (more usage during business hours and evenings)\n",
    "\n",
    "        hour_weights = [1, 1, 1, 1, 1, 2, 4, 6, 8, 7, 6, 8, 9, 8, 7, 6, 8, 9, 10, 8, 6, 4, 3, 2]\n",
    "\n",
    "        hours_offset = random.choices(range(24), weights=hour_weights)[0]\n",
    "\n",
    "        usage_date = usage_date.replace(hour=hours_offset, minute=random.randint(0, 59), second=0, microsecond=0)\n",
    "        \n",
    "        # Select service type\n",
    "\n",
    "        service_type = random.choice(SERVICE_TYPES)\n",
    "\n",
    "        params = USAGE_PARAMS[service_type]\n",
    "        \n",
    "        # Calculate usage metrics with variability\n",
    "\n",
    "        if service_type == 'Voice':\n",
    "\n",
    "            duration_variation = random.uniform(0.3, 3.0)\n",
    "\n",
    "            call_duration = round(params['avg_duration'] * duration_variation, 2)\n",
    "\n",
    "            data_volume = 0.0\n",
    "\n",
    "        elif service_type == 'Data':\n",
    "\n",
    "            data_variation = random.uniform(0.1, 5.0)\n",
    "\n",
    "            data_volume = round(params['data_volume'] * data_variation, 3)\n",
    "\n",
    "            call_duration = 0.0\n",
    "\n",
    "        elif service_type == 'SMS':\n",
    "\n",
    "            data_volume = 0.0\n",
    "\n",
    "            call_duration = 0.0\n",
    "\n",
    "        else:  # Streaming\n",
    "\n",
    "            data_variation = random.uniform(0.5, 8.0)\n",
    "\n",
    "            data_volume = round(params['data_volume'] * data_variation, 3)\n",
    "\n",
    "            call_duration = 0.0\n",
    "        \n",
    "        # Select cell tower and signal quality\n",
    "\n",
    "        cell_tower_id = random.choice(CELL_TOWERS)\n",
    "\n",
    "        # Signal quality varies by tower and time\n",
    "\n",
    "        base_signal = random.randint(60, 95)\n",
    "\n",
    "        signal_variation = random.randint(-15, 5)\n",
    "\n",
    "        signal_quality = max(0, min(100, base_signal + signal_variation))\n",
    "        \n",
    "        usage_data.append({\n",
    "\n",
    "            \"subscriber_id\": subscriber_id,\n",
    "\n",
    "            \"usage_date\": usage_date,\n",
    "\n",
    "            \"service_type\": service_type,\n",
    "\n",
    "            \"data_volume\": data_volume,\n",
    "\n",
    "            \"call_duration\": call_duration,\n",
    "\n",
    "            \"cell_tower_id\": cell_tower_id,\n",
    "\n",
    "            \"signal_quality\": signal_quality\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Generated {len(usage_data)} network usage records\")\n",
    "\n",
    "print(\"Sample record:\", usage_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Insert Data Using PySpark\n",
    "\n",
    "### Data Insertion Strategy\n",
    "\n",
    "We'll use PySpark to:\n",
    "\n",
    "1. **Create DataFrame** from our generated data\n",
    "2. **Insert into Delta table** with liquid clustering\n",
    "3. **Verify the insertion** with a sample query\n",
    "\n",
    "### Why PySpark for Insertion?\n",
    "\n",
    "- **Distributed processing**: Handles large datasets efficiently\n",
    "- **Type safety**: Ensures data integrity\n",
    "- **Optimization**: Leverages Spark's query optimization\n",
    "- **Liquid clustering**: Automatically applies clustering during insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T18:39:54.362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame Schema:\n",
       "root\n",
       " |-- subscriber_id: string (nullable = true)\n",
       " |-- usage_date: timestamp (nullable = true)\n",
       " |-- service_type: string (nullable = true)\n",
       " |-- data_volume: double (nullable = true)\n",
       " |-- call_duration: double (nullable = true)\n",
       " |-- cell_tower_id: string (nullable = true)\n",
       " |-- signal_quality: integer (nullable = true)\n",
       "\n",
       "\n",
       "Sample Data:\n",
       "+-------------+-------------------+------------+-----------+-------------+-------------+--------------+\n",
       "|subscriber_id|         usage_date|service_type|data_volume|call_duration|cell_tower_id|signal_quality|\n",
       "+-------------+-------------------+------------+-----------+-------------+-------------+--------------+\n",
       "|  SUB00000001|2024-10-11 09:09:00|       Voice|        0.0|         6.73|TOWER_CHI_003|            65|\n",
       "|  SUB00000001|2024-09-01 10:33:00|       Voice|        0.0|          7.6|TOWER_SEA_007|            64|\n",
       "|  SUB00000001|2024-06-09 18:09:00|       Voice|        0.0|         5.82|TOWER_HOU_004|            91|\n",
       "|  SUB00000001|2024-10-19 16:56:00|        Data|      0.284|          0.0|TOWER_HOU_004|            57|\n",
       "|  SUB00000001|2024-05-23 09:40:00|         SMS|        0.0|          0.0|TOWER_CHI_003|            96|\n",
       "+-------------+-------------------+------------+-----------+-------------+-------------+--------------+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Successfully inserted 600441 records into telecom.analytics.network_usage_uf\n",
       "Liquid clustering automatically optimized the data layout during insertion!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert data using PySpark DataFrame operations\n",
    "\n",
    "# Using fully qualified function references to avoid conflicts\n",
    "\n",
    "\n",
    "# Create DataFrame from generated data\n",
    "\n",
    "df_usage = spark.createDataFrame(usage_data, schema=data_schema)\n",
    "\n",
    "\n",
    "# Display schema and sample data\n",
    "\n",
    "print(\"DataFrame Schema:\")\n",
    "\n",
    "df_usage.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "\n",
    "df_usage.show(5)\n",
    "\n",
    "\n",
    "# Insert data into Delta table with liquid clustering\n",
    "\n",
    "# The TBLPROPERTIES('delta.universalFormat.enabledFormats' = 'iceberg') CLUSTER BY (subscriber_id, usage_date) will automatically optimize the data layout\n",
    "\n",
    "df_usage.write.mode(\"overwrite\").insertInto(\"telecom.analytics.network_usage_uf\")\n",
    "\n",
    "\n",
    "print(f\"\\nSuccessfully inserted {df_usage.count()} records into telecom.analytics.network_usage_uf\")\n",
    "\n",
    "print(\"Liquid clustering automatically optimized the data layout during insertion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate Liquid Clustering Benefits\n",
    "\n",
    "### Query Performance Analysis\n",
    "\n",
    "Now let's see how liquid clustering improves query performance. We'll run queries that benefit from our clustering strategy:\n",
    "\n",
    "1. **Subscriber usage history** (clustered by subscriber_id)\n",
    "2. **Time-based network analysis** (clustered by usage_date)\n",
    "3. **Combined subscriber + time queries** (optimal for our clustering)\n",
    "\n",
    "### Expected Performance Benefits\n",
    "\n",
    "With liquid clustering, these queries should be significantly faster because:\n",
    "\n",
    "- **Data locality**: Related records are physically grouped together\n",
    "- **Reduced I/O**: Less data needs to be read from disk\n",
    "- **Automatic optimization**: No manual tuning required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T18:40:19.294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Query 1: Subscriber Usage History ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------+-------------------+------------+-----------+-------------+--------------+\n",
       "|subscriber_id|         usage_date|service_type|data_volume|call_duration|signal_quality|\n",
       "+-------------+-------------------+------------+-----------+-------------+--------------+\n",
       "|  SUB00000001|2024-12-23 19:56:00|   Streaming|      9.203|         0.00|            64|\n",
       "|  SUB00000001|2024-12-18 14:35:00|         SMS|      0.000|         0.00|            49|\n",
       "|  SUB00000001|2024-12-13 07:58:00|         SMS|      0.000|         0.00|            64|\n",
       "|  SUB00000001|2024-12-08 12:02:00|        Data|      0.587|         0.00|            57|\n",
       "|  SUB00000001|2024-11-28 09:17:00|        Data|      1.336|         0.00|            80|\n",
       "|  SUB00000001|2024-11-26 14:57:00|       Voice|      0.000|         1.91|            64|\n",
       "|  SUB00000001|2024-11-15 20:26:00|       Voice|      0.000|         8.90|            68|\n",
       "|  SUB00000001|2024-11-05 20:19:00|   Streaming|      6.681|         0.00|            65|\n",
       "|  SUB00000001|2024-11-02 10:39:00|   Streaming|      7.830|         0.00|            63|\n",
       "|  SUB00000001|2024-11-01 09:33:00|         SMS|      0.000|         0.00|            55|\n",
       "|  SUB00000001|2024-10-25 22:19:00|   Streaming|     14.656|         0.00|            87|\n",
       "|  SUB00000001|2024-10-25 19:52:00|         SMS|      0.000|         0.00|            63|\n",
       "|  SUB00000001|2024-10-21 23:26:00|       Voice|      0.000|         8.40|            57|\n",
       "|  SUB00000001|2024-10-19 16:56:00|        Data|      0.284|         0.00|            57|\n",
       "|  SUB00000001|2024-10-16 12:48:00|       Voice|      0.000|         3.36|            69|\n",
       "|  SUB00000001|2024-10-15 07:20:00|       Voice|      0.000|         6.79|            94|\n",
       "|  SUB00000001|2024-10-11 09:09:00|       Voice|      0.000|         6.73|            65|\n",
       "|  SUB00000001|2024-09-20 09:56:00|         SMS|      0.000|         0.00|            71|\n",
       "|  SUB00000001|2024-09-12 18:28:00|         SMS|      0.000|         0.00|            62|\n",
       "|  SUB00000001|2024-09-12 10:10:00|       Voice|      0.000|        13.93|            76|\n",
       "+-------------+-------------------+------------+-----------+-------------+--------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Records found: 65\n",
       "\n",
       "=== Query 2: Recent Network Quality Issues ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------------+-------------+-------------+--------------+------------+\n",
       "|         usage_date|subscriber_id|cell_tower_id|signal_quality|service_type|\n",
       "+-------------------+-------------+-------------+--------------+------------+\n",
       "|2024-12-31 23:30:00|  SUB00000489|TOWER_SFO_006|            45|   Streaming|\n",
       "|2024-12-31 19:26:00|  SUB00002960|TOWER_LAX_002|            45|   Streaming|\n",
       "|2024-12-31 13:51:00|  SUB00005928|TOWER_NYC_001|            45|   Streaming|\n",
       "|2024-12-29 20:40:00|  SUB00003337|TOWER_HOU_004|            45|   Streaming|\n",
       "|2024-12-28 13:04:00|  SUB00002745|TOWER_NYC_001|            45|   Streaming|\n",
       "|2024-12-27 10:03:00|  SUB00007176|TOWER_NYC_001|            45|        Data|\n",
       "|2024-12-26 19:25:00|  SUB00003629|TOWER_CHI_003|            45|         SMS|\n",
       "|2024-12-26 08:18:00|  SUB00008098|TOWER_MIA_005|            45|        Data|\n",
       "|2024-12-26 07:37:00|  SUB00006040|TOWER_SEA_007|            45|   Streaming|\n",
       "|2024-12-26 01:45:00|  SUB00009227|TOWER_HOU_004|            45|        Data|\n",
       "|2024-12-25 13:49:00|  SUB00003772|TOWER_MIA_005|            45|       Voice|\n",
       "|2024-12-24 07:58:00|  SUB00007534|TOWER_LAX_002|            45|   Streaming|\n",
       "|2024-12-23 11:49:00|  SUB00000579|TOWER_SEA_007|            45|   Streaming|\n",
       "|2024-12-23 10:57:00|  SUB00000257|TOWER_NYC_001|            45|         SMS|\n",
       "|2024-12-22 19:51:00|  SUB00006809|TOWER_SEA_007|            45|        Data|\n",
       "|2024-12-22 12:09:00|  SUB00003481|TOWER_LAX_002|            45|   Streaming|\n",
       "|2024-12-22 11:22:00|  SUB00007076|TOWER_NYC_001|            45|       Voice|\n",
       "|2024-12-22 07:23:00|  SUB00004671|TOWER_LAX_002|            45|       Voice|\n",
       "|2024-12-19 11:18:00|  SUB00004070|TOWER_SFO_006|            45|       Voice|\n",
       "|2024-12-19 07:25:00|  SUB00000281|TOWER_SFO_006|            45|   Streaming|\n",
       "+-------------------+-------------+-------------+--------------+------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Network quality issues found: 7052\n",
       "\n",
       "=== Query 3: Subscriber Data Usage Trends ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------+-------------------+------------+-----------+-------------+\n",
       "|subscriber_id|         usage_date|service_type|data_volume|call_duration|\n",
       "+-------------+-------------------+------------+-----------+-------------+\n",
       "|  SUB00000001|2024-04-13 06:35:00|         SMS|      0.000|         0.00|\n",
       "|  SUB00000001|2024-04-16 04:46:00|       Voice|      0.000|         5.62|\n",
       "|  SUB00000001|2024-04-16 20:47:00|         SMS|      0.000|         0.00|\n",
       "|  SUB00000001|2024-04-24 22:28:00|       Voice|      0.000|         4.94|\n",
       "|  SUB00000001|2024-05-03 18:50:00|        Data|      1.165|         0.00|\n",
       "|  SUB00000001|2024-05-05 02:55:00|   Streaming|     10.595|         0.00|\n",
       "|  SUB00000001|2024-05-12 06:30:00|       Voice|      0.000|        11.42|\n",
       "|  SUB00000001|2024-05-23 09:40:00|         SMS|      0.000|         0.00|\n",
       "|  SUB00000001|2024-05-23 19:20:00|         SMS|      0.000|         0.00|\n",
       "|  SUB00000001|2024-05-29 23:50:00|        Data|      1.616|         0.00|\n",
       "|  SUB00000001|2024-06-07 13:40:00|   Streaming|      6.221|         0.00|\n",
       "|  SUB00000001|2024-06-09 18:09:00|       Voice|      0.000|         5.82|\n",
       "|  SUB00000001|2024-06-13 08:08:00|   Streaming|      3.019|         0.00|\n",
       "|  SUB00000001|2024-07-06 11:09:00|   Streaming|     11.093|         0.00|\n",
       "|  SUB00000001|2024-07-07 04:06:00|        Data|      1.400|         0.00|\n",
       "|  SUB00000001|2024-07-08 20:15:00|         SMS|      0.000|         0.00|\n",
       "|  SUB00000001|2024-07-19 18:52:00|       Voice|      0.000|         4.97|\n",
       "|  SUB00000001|2024-07-20 11:45:00|       Voice|      0.000|        14.22|\n",
       "|  SUB00000001|2024-08-01 08:24:00|       Voice|      0.000|         3.42|\n",
       "|  SUB00000001|2024-08-01 16:15:00|         SMS|      0.000|         0.00|\n",
       "+-------------+-------------------+------------+-----------+-------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Usage trend records found: 4695\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate liquid clustering benefits with optimized queries\n",
    "\n",
    "\n",
    "# Query 1: Subscriber usage history - benefits from subscriber_id clustering\n",
    "\n",
    "print(\"=== Query 1: Subscriber Usage History ===\")\n",
    "\n",
    "subscriber_history = spark.sql(\"\"\"\n",
    "\n",
    "SELECT subscriber_id, usage_date, service_type, data_volume, call_duration, signal_quality\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "WHERE subscriber_id = 'SUB00000001'\n",
    "\n",
    "ORDER BY usage_date DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "subscriber_history.show()\n",
    "\n",
    "print(f\"Records found: {subscriber_history.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 2: Time-based network quality analysis - benefits from usage_date clustering\n",
    "\n",
    "print(\"\\n=== Query 2: Recent Network Quality Issues ===\")\n",
    "\n",
    "network_quality = spark.sql(\"\"\"\n",
    "\n",
    "SELECT usage_date, subscriber_id, cell_tower_id, signal_quality, service_type\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "WHERE usage_date >= '2024-06-01' AND signal_quality < 50\n",
    "\n",
    "ORDER BY signal_quality ASC, usage_date DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "network_quality.show()\n",
    "\n",
    "print(f\"Network quality issues found: {network_quality.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 3: Combined subscriber + time query - optimal for our clustering strategy\n",
    "\n",
    "print(\"\\n=== Query 3: Subscriber Data Usage Trends ===\")\n",
    "\n",
    "usage_trends = spark.sql(\"\"\"\n",
    "\n",
    "SELECT subscriber_id, usage_date, service_type, data_volume, call_duration\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "WHERE subscriber_id LIKE 'SUB000000%' AND usage_date >= '2024-04-01'\n",
    "\n",
    "ORDER BY subscriber_id, usage_date\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "usage_trends.show()\n",
    "\n",
    "print(f\"Usage trend records found: {usage_trends.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Clustering Effectiveness\n",
    "\n",
    "### Understanding the Impact\n",
    "\n",
    "Let's examine how liquid clustering has organized our data and analyze some aggregate statistics to demonstrate the telecommunications insights possible with this optimized structure.\n",
    "\n",
    "### Key Analytics\n",
    "\n",
    "- **Subscriber usage patterns** and data consumption analysis\n",
    "- **Network performance metrics** and signal quality trends\n",
    "- **Service type adoption** and usage distribution\n",
    "- **Cell tower utilization** and capacity planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-11T18:40:39.950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Subscriber Usage Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------+--------------+-------------+------------------+------------------+-------------+\n",
       "|subscriber_id|total_sessions|total_data_gb|total_call_minutes|avg_signal_quality|services_used|\n",
       "+-------------+--------------+-------------+------------------+------------------+-------------+\n",
       "|  SUB00007721|           100|      437.600|            186.18|             71.52|            4|\n",
       "|  SUB00000310|            87|      360.635|            115.96|             74.31|            4|\n",
       "|  SUB00009487|            99|      359.354|            142.81|             71.95|            4|\n",
       "|  SUB00004489|           100|      355.142|            241.89|             72.93|            4|\n",
       "|  SUB00009757|            99|      353.809|            159.57|              72.8|            4|\n",
       "|  SUB00003440|           100|      352.415|            206.11|             73.61|            4|\n",
       "|  SUB00001442|            97|      349.590|            165.55|             72.38|            4|\n",
       "|  SUB00007546|            96|      348.428|            135.82|             72.92|            4|\n",
       "|  SUB00004214|           100|      348.169|            172.92|             71.78|            4|\n",
       "|  SUB00006283|           100|      345.790|            150.00|              73.5|            4|\n",
       "|  SUB00008402|           100|      345.618|            142.73|             70.44|            4|\n",
       "|  SUB00008111|            97|      343.440|            101.13|             73.01|            4|\n",
       "|  SUB00003035|           100|      339.136|            175.07|             72.13|            4|\n",
       "|  SUB00001748|            98|      338.285|            208.30|             70.98|            4|\n",
       "|  SUB00006171|            99|      337.831|            150.28|             73.94|            4|\n",
       "|  SUB00005497|            94|      337.171|            172.54|             70.84|            4|\n",
       "|  SUB00009271|            96|      336.513|             93.63|             74.96|            4|\n",
       "|  SUB00000062|            91|      335.497|            173.41|             71.75|            4|\n",
       "|  SUB00007334|            95|      335.381|            167.79|             73.04|            4|\n",
       "|  SUB00006732|            95|      332.291|            264.65|             72.54|            4|\n",
       "+-------------+--------------+-------------+------------------+------------------+-------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "\n",
       "=== Service Type Usage Patterns ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+------------+-----------+-------------+------------------+------------------+------------------+\n",
       "|service_type|total_usage|total_data_gb|total_call_minutes|avg_signal_quality|unique_subscribers|\n",
       "+------------+-----------+-------------+------------------+------------------+------------------+\n",
       "|   Streaming|     150681|  1281179.011|              0.00|             72.53|              9998|\n",
       "|         SMS|     150362|        0.000|              0.00|             72.54|              9999|\n",
       "|        Data|     149979|   191224.751|              0.00|             72.46|              9998|\n",
       "|       Voice|     149419|        0.000|        1233854.92|             72.49|              9998|\n",
       "+------------+-----------+-------------+------------------+------------------+------------------+\n",
       "\n",
       "\n",
       "=== Cell Tower Performance ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------+-----------------+------------------+------------------+-------------+------------------+\n",
       "|cell_tower_id|total_connections|unique_subscribers|avg_signal_quality|total_data_gb|total_call_minutes|\n",
       "+-------------+-----------------+------------------+------------------+-------------+------------------+\n",
       "|TOWER_SEA_007|            86303|              9961|              72.5|   211831.705|         178234.77|\n",
       "|TOWER_LAX_002|            85815|              9972|             72.54|   210171.637|         175583.76|\n",
       "|TOWER_MIA_005|            85807|              9963|             72.46|   209335.766|         176913.40|\n",
       "|TOWER_HOU_004|            85665|              9967|             72.49|   211980.345|         175157.25|\n",
       "|TOWER_SFO_006|            85652|              9951|             72.49|   209578.515|         176548.76|\n",
       "|TOWER_NYC_001|            85627|              9952|              72.5|   209938.392|         175181.60|\n",
       "|TOWER_CHI_003|            85572|              9947|             72.56|   209567.402|         176235.38|\n",
       "+-------------+-----------------+------------------+------------------+-------------+------------------+\n",
       "\n",
       "\n",
       "=== Hourly Usage Patterns ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-----------+------------+--------------+------------+------------------+\n",
       "|hour_of_day|usage_events|data_volume_gb|call_minutes|avg_signal_quality|\n",
       "+-----------+------------+--------------+------------+------------------+\n",
       "|          0|        4882|     11751.071|     9743.80|             72.72|\n",
       "|          1|        4784|     11658.243|    10049.24|              72.4|\n",
       "|          2|        4700|     11674.221|     9564.95|             72.35|\n",
       "|          3|        4600|     11147.394|     9624.37|             72.65|\n",
       "|          4|        4825|     12138.186|     9876.13|              72.7|\n",
       "|          5|        9596|     23752.194|    19921.37|             72.28|\n",
       "|          6|       19040|     47192.768|    39631.71|             72.37|\n",
       "|          7|       28752|     70402.197|    58563.54|             72.52|\n",
       "|          8|       37945|     93032.801|    78315.74|             72.48|\n",
       "|          9|       33081|     81710.376|    66832.08|             72.48|\n",
       "|         10|       28429|     68958.860|    59135.27|             72.48|\n",
       "|         11|       38101|     93204.018|    78487.30|             72.56|\n",
       "|         12|       42815|    104460.943|    87031.47|             72.42|\n",
       "|         13|       38415|     94148.620|    77148.95|             72.55|\n",
       "|         14|       32834|     81224.012|    67454.09|             72.59|\n",
       "|         15|       28701|     69364.347|    59312.36|             72.39|\n",
       "|         16|       37938|     93322.410|    78815.42|             72.52|\n",
       "|         17|       43191|    105001.947|    89736.16|             72.56|\n",
       "|         18|       48101|    119449.782|    95749.89|             72.48|\n",
       "|         19|       38223|     93909.480|    79484.67|             72.53|\n",
       "+-----------+------------+--------------+------------+------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "\n",
       "=== Monthly Network Trends ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------+-----------+---------------+--------------------+------------------+------------------+\n",
       "|  month|total_usage|monthly_data_gb|monthly_call_minutes|avg_signal_quality|active_subscribers|\n",
       "+-------+-----------+---------------+--------------------+------------------+------------------+\n",
       "|2024-01|      50546|     124398.149|           103286.56|             72.46|              9742|\n",
       "|2024-02|      47868|     116160.897|            97495.47|             72.52|              9681|\n",
       "|2024-03|      51080|     124101.472|           105340.74|             72.51|              9767|\n",
       "|2024-04|      49091|     120063.291|           102222.16|             72.51|              9708|\n",
       "|2024-05|      51182|     125372.721|           105244.69|             72.44|              9739|\n",
       "|2024-06|      49228|     121975.716|           100510.07|             72.45|              9710|\n",
       "|2024-07|      50892|     125537.807|           104053.12|             72.57|              9779|\n",
       "|2024-08|      50955|     125087.109|           103173.90|             72.49|              9763|\n",
       "|2024-09|      48948|     118872.734|           101867.21|             72.53|              9701|\n",
       "|2024-10|      50958|     125711.263|           105509.87|             72.57|              9766|\n",
       "|2024-11|      49322|     120869.745|           101971.29|             72.52|              9734|\n",
       "|2024-12|      50371|     124252.858|           103179.84|             72.48|              9753|\n",
       "+-------+-----------+---------------+--------------------+------------------+------------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze clustering effectiveness and telecommunications insights\n",
    "\n",
    "\n",
    "# Subscriber usage analysis\n",
    "\n",
    "print(\"=== Subscriber Usage Analysis ===\")\n",
    "\n",
    "subscriber_usage = spark.sql(\"\"\"\n",
    "\n",
    "SELECT subscriber_id, COUNT(*) as total_sessions,\n",
    "\n",
    "       ROUND(SUM(data_volume), 3) as total_data_gb,\n",
    "\n",
    "       ROUND(SUM(call_duration), 2) as total_call_minutes,\n",
    "\n",
    "       ROUND(AVG(signal_quality), 2) as avg_signal_quality,\n",
    "\n",
    "       COUNT(DISTINCT service_type) as services_used\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "GROUP BY subscriber_id\n",
    "\n",
    "ORDER BY total_data_gb DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "subscriber_usage.show()\n",
    "\n",
    "\n",
    "# Service type usage patterns\n",
    "\n",
    "print(\"\\n=== Service Type Usage Patterns ===\")\n",
    "\n",
    "service_patterns = spark.sql(\"\"\"\n",
    "\n",
    "SELECT service_type, COUNT(*) as total_usage,\n",
    "\n",
    "       ROUND(SUM(data_volume), 3) as total_data_gb,\n",
    "\n",
    "       ROUND(SUM(call_duration), 2) as total_call_minutes,\n",
    "\n",
    "       ROUND(AVG(signal_quality), 2) as avg_signal_quality,\n",
    "\n",
    "       COUNT(DISTINCT subscriber_id) as unique_subscribers\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "GROUP BY service_type\n",
    "\n",
    "ORDER BY total_usage DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "service_patterns.show()\n",
    "\n",
    "\n",
    "# Cell tower performance\n",
    "\n",
    "print(\"\\n=== Cell Tower Performance ===\")\n",
    "\n",
    "tower_performance = spark.sql(\"\"\"\n",
    "\n",
    "SELECT cell_tower_id, COUNT(*) as total_connections,\n",
    "\n",
    "       COUNT(DISTINCT subscriber_id) as unique_subscribers,\n",
    "\n",
    "       ROUND(AVG(signal_quality), 2) as avg_signal_quality,\n",
    "\n",
    "       ROUND(SUM(data_volume), 3) as total_data_gb,\n",
    "\n",
    "       ROUND(SUM(call_duration), 2) as total_call_minutes\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "GROUP BY cell_tower_id\n",
    "\n",
    "ORDER BY total_connections DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "tower_performance.show()\n",
    "\n",
    "\n",
    "# Hourly usage patterns\n",
    "\n",
    "print(\"\\n=== Hourly Usage Patterns ===\")\n",
    "\n",
    "hourly_patterns = spark.sql(\"\"\"\n",
    "\n",
    "SELECT HOUR(usage_date) as hour_of_day, COUNT(*) as usage_events,\n",
    "\n",
    "       ROUND(SUM(data_volume), 3) as data_volume_gb,\n",
    "\n",
    "       ROUND(SUM(call_duration), 2) as call_minutes,\n",
    "\n",
    "       ROUND(AVG(signal_quality), 2) as avg_signal_quality\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "GROUP BY HOUR(usage_date)\n",
    "\n",
    "ORDER BY hour_of_day\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "hourly_patterns.show()\n",
    "\n",
    "\n",
    "# Monthly network trends\n",
    "\n",
    "print(\"\\n=== Monthly Network Trends ===\")\n",
    "\n",
    "monthly_trends = spark.sql(\"\"\"\n",
    "\n",
    "SELECT DATE_FORMAT(usage_date, 'yyyy-MM') as month,\n",
    "\n",
    "       COUNT(*) as total_usage,\n",
    "\n",
    "       ROUND(SUM(data_volume), 3) as monthly_data_gb,\n",
    "\n",
    "       ROUND(SUM(call_duration), 2) as monthly_call_minutes,\n",
    "\n",
    "       ROUND(AVG(signal_quality), 2) as avg_signal_quality,\n",
    "\n",
    "       COUNT(DISTINCT subscriber_id) as active_subscribers\n",
    "\n",
    "FROM telecom.analytics.network_usage_uf\n",
    "\n",
    "GROUP BY DATE_FORMAT(usage_date, 'yyyy-MM')\n",
    "\n",
    "ORDER BY month\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "monthly_trends.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: Iceberg and Liquid Clustering in AIDP\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Automatic Optimization**: Created a table with `TBLPROPERTIES('delta.universalFormat.enabledFormats' = 'iceberg') CLUSTER BY (subscriber_id, usage_date)` and let Delta automatically optimize data layout\n",
    "\n",
    "2. **Performance Benefits**: Queries on clustered columns (subscriber_id, usage_date) are significantly faster due to data locality\n",
    "\n",
    "3. **Zero Maintenance**: No manual partitioning, bucketing, or Z-Ordering required - Delta handles it automatically\n",
    "\n",
    "4. **Real-World Use Case**: Telecommunications analytics where network monitoring and customer experience are critical\n",
    "\n",
    "### AIDP Advantages\n",
    "\n",
    "- **Unified Analytics**: Seamlessly integrates with other AIDP services\n",
    "- **Governance**: Catalog and schema isolation for telecommunications data\n",
    "- **Performance**: Optimized for both OLAP and OLTP workloads\n",
    "- **Scalability**: Handles telecommunications-scale data volumes effortlessly\n",
    "\n",
    "### Best Practices for Iceberg and Liquid Clustering\n",
    "\n",
    "1. **Choose clustering columns** based on your most common query patterns\n",
    "2. **Start with 1-4 columns** - too many can reduce effectiveness\n",
    "3. **Consider cardinality** - high-cardinality columns work best\n",
    "4. **Monitor and adjust** as query patterns evolve\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore other AIDP features like AI/ML integration\n",
    "- Try liquid clustering with different column combinations\n",
    "- Scale up to larger telecommunications datasets\n",
    "- Integrate with real network monitoring systems and CDR data\n",
    "\n",
    "This notebook demonstrates how Oracle AI Data Platform combines Delta's advanced liquid clustering with Iceberg's open, future-proof architecture to deliver enterprise-grade analytics that are both high-performance and standards-compliant."
   ]
  }
 ],
 "metadata": {
  "Last_Active_Cell_Index": 11,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "notebook"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
