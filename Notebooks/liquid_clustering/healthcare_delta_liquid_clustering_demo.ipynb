{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Healthcare Analytics: Delta Liquid Clustering Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates the power of **Delta Liquid Clustering** in Oracle AI Data Platform (AIDP) Workbench using a healthcare analytics use case. Liquid clustering is a revolutionary feature that automatically optimizes data layout for query performance without requiring manual partitioning or Z-Ordering.\n",
    "\n",
    "### What is Liquid Clustering?\n",
    "\n",
    "Liquid clustering automatically identifies and groups similar data together based on clustering columns you define. This optimization happens automatically during data ingestion and maintenance operations, providing:\n",
    "\n",
    "- **Automatic optimization**: No manual tuning required\n",
    "- **Improved query performance**: Faster queries on clustered columns\n",
    "- **Reduced maintenance**: No need for manual repartitioning\n",
    "- **Adaptive clustering**: Adjusts as data patterns change\n",
    "\n",
    "### Use Case: Patient Diagnosis Analytics\n",
    "\n",
    "We'll analyze patient diagnosis records from a healthcare system. Our clustering strategy will optimize for:\n",
    "- **Patient-specific queries**: Fast lookups by patient ID\n",
    "- **Time-based analysis**: Efficient filtering by diagnosis date\n",
    "- **Diagnosis patterns**: Quick aggregation by diagnosis type\n",
    "\n",
    "### AIDP Environment Setup\n",
    "\n",
    "This notebook leverages the existing Spark session in your AIDP environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create healthcare catalog and gold schema\n",
    "# In AIDP, catalogs provide data isolation and governance\n",
    "\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS healthcare\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS healthcare.gold\")\n",
    "\n",
    "print(\"Healthcare catalog and gold schema created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Delta Table with Liquid Clustering\n",
    "\n",
    "### Table Design\n",
    "\n",
    "Our `patient_diagnoses` table will store:\n",
    "- **patient_id**: Unique patient identifier\n",
    "- **diagnosis_date**: When the diagnosis was made\n",
    "- **diagnosis_code**: ICD-10 diagnosis code\n",
    "- **diagnosis_description**: Human-readable diagnosis\n",
    "- **severity_level**: Critical, High, Medium, Low\n",
    "- **treating_physician**: Physician ID\n",
    "- **facility_id**: Healthcare facility\n",
    "\n",
    "### Clustering Strategy\n",
    "\n",
    "We'll cluster by `patient_id` and `diagnosis_date` because:\n",
    "- **patient_id**: Patients often have multiple visits, grouping their records together\n",
    "- **diagnosis_date**: Time-based queries are common in healthcare analytics\n",
    "- This combination optimizes for both patient history lookups and temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delta table with liquid clustering created successfully!\n",
       "Clustering will automatically optimize data layout for queries on patient_id and diagnosis_date.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Delta table with liquid clustering\n",
    "# CLUSTER BY defines the columns for automatic optimization\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS healthcare.gold.patient_diagnoses (\n",
    "    patient_id STRING,\n",
    "    diagnosis_date DATE,\n",
    "    diagnosis_code STRING,\n",
    "    diagnosis_description STRING,\n",
    "    severity_level STRING,\n",
    "    treating_physician STRING,\n",
    "    facility_id STRING\n",
    ")\n",
    "USING DELTA\n",
    "CLUSTER BY (patient_id, diagnosis_date)\n",
    "\"\"\")\n",
    "\n",
    "print(\"Delta table with liquid clustering created successfully!\")\n",
    "print(\"Clustering will automatically optimize data layout for queries on patient_id and diagnosis_date.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Healthcare Sample Data\n",
    "\n",
    "### Data Generation Strategy\n",
    "\n",
    "We'll create realistic healthcare data including:\n",
    "- **100 patients** with multiple diagnoses over time\n",
    "- **Common diagnoses**: Diabetes, Hypertension, Asthma, etc.\n",
    "- **Realistic temporal patterns**: Follow-up visits, chronic condition management\n",
    "- **Multiple facilities**: Different hospitals/clinics\n",
    "\n",
    "### Why This Data Pattern?\n",
    "\n",
    "This data simulates real healthcare scenarios where:\n",
    "- Patients have multiple encounters\n",
    "- Chronic conditions require ongoing monitoring\n",
    "- Time-based analysis reveals treatment effectiveness\n",
    "- Facility-level reporting is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generated 350 patient diagnosis records\n",
       "Sample record: {'patient_id': 'PAT0001', 'diagnosis_date': datetime.date(2024, 2, 17), 'diagnosis_code': 'F41.9', 'diagnosis_description': 'Anxiety disorder, unspecified', 'severity_level': 'Medium', 'treating_physician': 'DR_SMITH', 'facility_id': 'CLINIC002'}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample healthcare diagnosis data\n",
    "# Using fully qualified pyspark.sql.functions to avoid conflicts\n",
    "\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define healthcare data constants\n",
    "DIAGNOSES = [\n",
    "    (\"E11.9\", \"Type 2 diabetes mellitus without complications\", \"Medium\"),\n",
    "    (\"I10\", \"Essential hypertension\", \"High\"),\n",
    "    (\"J45.909\", \"Unspecified asthma, uncomplicated\", \"Medium\"),\n",
    "    (\"M54.5\", \"Low back pain\", \"Low\"),\n",
    "    (\"N39.0\", \"Urinary tract infection, site not specified\", \"Medium\"),\n",
    "    (\"Z51.11\", \"Encounter for antineoplastic chemotherapy\", \"Critical\"),\n",
    "    (\"I25.10\", \"Atherosclerotic heart disease of native coronary artery without angina pectoris\", \"High\"),\n",
    "    (\"F41.9\", \"Anxiety disorder, unspecified\", \"Medium\"),\n",
    "    (\"M79.3\", \"Panniculitis, unspecified\", \"Low\"),\n",
    "    (\"Z00.00\", \"Encounter for general adult medical examination without abnormal findings\", \"Low\")\n",
    "]\n",
    "\n",
    "FACILITIES = [\"HOSP001\", \"HOSP002\", \"CLINIC001\", \"CLINIC002\", \"URGENT001\"]\n",
    "PHYSICIANS = [\"DR_SMITH\", \"DR_JOHNSON\", \"DR_WILLIAMS\", \"DR_BROWN\", \"DR_JONES\", \"DR_GARCIA\", \"DR_MILLER\", \"DR_DAVIS\"]\n",
    "\n",
    "# Generate patient diagnosis records\n",
    "patient_data = []\n",
    "base_date = datetime(2024, 1, 1)\n",
    "\n",
    "# Create 100 patients with 2-5 diagnoses each\n",
    "for patient_num in range(1, 101):\n",
    "    patient_id = f\"PAT{patient_num:04d}\"\n",
    "    \n",
    "    # Each patient gets 2-5 diagnoses over several months\n",
    "    num_diagnoses = random.randint(2, 5)\n",
    "    \n",
    "    for i in range(num_diagnoses):\n",
    "        # Spread diagnoses over 6 months\n",
    "        days_offset = random.randint(0, 180)\n",
    "        diagnosis_date = base_date + timedelta(days=days_offset)\n",
    "        \n",
    "        # Select random diagnosis\n",
    "        diagnosis_code, description, severity = random.choice(DIAGNOSES)\n",
    "        \n",
    "        # Select random facility and physician\n",
    "        facility = random.choice(FACILITIES)\n",
    "        physician = random.choice(PHYSICIANS)\n",
    "        \n",
    "        patient_data.append({\n",
    "            \"patient_id\": patient_id,\n",
    "            \"diagnosis_date\": diagnosis_date.date(),\n",
    "            \"diagnosis_code\": diagnosis_code,\n",
    "            \"diagnosis_description\": description,\n",
    "            \"severity_level\": severity,\n",
    "            \"treating_physician\": physician,\n",
    "            \"facility_id\": facility\n",
    "        })\n",
    "\n",
    "print(f\"Generated {len(patient_data)} patient diagnosis records\")\n",
    "print(\"Sample record:\", patient_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Insert Data Using PySpark\n",
    "\n",
    "### Data Insertion Strategy\n",
    "\n",
    "We'll use PySpark to:\n",
    "1. **Create DataFrame** from our generated data\n",
    "2. **Insert into Delta table** with liquid clustering\n",
    "3. **Verify the insertion** with a sample query\n",
    "\n",
    "### Why PySpark for Insertion?\n",
    "\n",
    "- **Distributed processing**: Handles large datasets efficiently\n",
    "- **Type safety**: Ensures data integrity\n",
    "- **Optimization**: Leverages Spark's query optimization\n",
    "- **Liquid clustering**: Automatically applies clustering during insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame Schema:\n",
       "root\n",
       " |-- diagnosis_code: string (nullable = true)\n",
       " |-- diagnosis_date: date (nullable = true)\n",
       " |-- diagnosis_description: string (nullable = true)\n",
       " |-- facility_id: string (nullable = true)\n",
       " |-- patient_id: string (nullable = true)\n",
       " |-- severity_level: string (nullable = true)\n",
       " |-- treating_physician: string (nullable = true)\n",
       "\n",
       "\n",
       "Sample Data:\n",
       "+--------------+--------------+---------------------+-----------+----------+--------------+------------------+\n",
       "|diagnosis_code|diagnosis_date|diagnosis_description|facility_id|patient_id|severity_level|treating_physician|\n",
       "+--------------+--------------+---------------------+-----------+----------+--------------+------------------+\n",
       "|         F41.9|    2024-02-17| Anxiety disorder,...|  CLINIC002|   PAT0001|        Medium|          DR_SMITH|\n",
       "|           I10|    2024-01-15| Essential hyperte...|    HOSP002|   PAT0001|          High|        DR_JOHNSON|\n",
       "|       J45.909|    2024-02-13| Unspecified asthm...|    HOSP002|   PAT0001|        Medium|          DR_JONES|\n",
       "|        Z00.00|    2024-06-25| Encounter for gen...|  URGENT001|   PAT0002|           Low|          DR_DAVIS|\n",
       "|        Z00.00|    2024-01-24| Encounter for gen...|    HOSP002|   PAT0002|           Low|          DR_JONES|\n",
       "+--------------+--------------+---------------------+-----------+----------+--------------+------------------+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Successfully inserted 350 records into healthcare.gold.patient_diagnoses\n",
       "Liquid clustering automatically optimized the data layout during insertion!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert data using PySpark DataFrame operations\n",
    "# Using fully qualified function references to avoid conflicts\n",
    "\n",
    "# Create DataFrame from generated data\n",
    "df_diagnoses = spark.createDataFrame(patient_data)\n",
    "\n",
    "# Display schema and sample data\n",
    "print(\"DataFrame Schema:\")\n",
    "df_diagnoses.printSchema()\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "df_diagnoses.show(5)\n",
    "\n",
    "# Insert data into Delta table with liquid clustering\n",
    "# The CLUSTER BY (patient_id, diagnosis_date) will automatically optimize the data layout\n",
    "df_diagnoses.write.mode(\"overwrite\").saveAsTable(\"healthcare.gold.patient_diagnoses\")\n",
    "\n",
    "print(f\"\\nSuccessfully inserted {df_diagnoses.count()} records into healthcare.gold.patient_diagnoses\")\n",
    "print(\"Liquid clustering automatically optimized the data layout during insertion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate Liquid Clustering Benefits\n",
    "\n",
    "### Query Performance Analysis\n",
    "\n",
    "Now let's see how liquid clustering improves query performance. We'll run queries that benefit from our clustering strategy:\n",
    "\n",
    "1. **Patient history lookup** (clustered by patient_id)\n",
    "2. **Time-based analysis** (clustered by diagnosis_date)\n",
    "3. **Combined patient + time queries** (optimal for our clustering)\n",
    "\n",
    "### Expected Performance Benefits\n",
    "\n",
    "With liquid clustering, these queries should be significantly faster because:\n",
    "- **Data locality**: Related records are physically grouped together\n",
    "- **Reduced I/O**: Less data needs to be read from disk\n",
    "- **Automatic optimization**: No manual tuning required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Query 1: Patient Diagnosis History ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------+--------------+---------------------+--------------+\n",
       "|patient_id|diagnosis_date|diagnosis_code|diagnosis_description|severity_level|\n",
       "+----------+--------------+--------------+---------------------+--------------+\n",
       "|   PAT0001|    2024-01-15|           I10| Essential hyperte...|          High|\n",
       "|   PAT0001|    2024-02-13|       J45.909| Unspecified asthm...|        Medium|\n",
       "|   PAT0001|    2024-02-17|         F41.9| Anxiety disorder,...|        Medium|\n",
       "+----------+--------------+--------------+---------------------+--------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Records found: 3\n",
       "\n",
       "=== Query 2: Recent Critical Diagnoses ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+--------------+----------+--------------+---------------------+------------------+\n",
       "|diagnosis_date|patient_id|diagnosis_code|diagnosis_description|treating_physician|\n",
       "+--------------+----------+--------------+---------------------+------------------+\n",
       "|    2024-06-25|   PAT0061|        Z51.11| Encounter for ant...|       DR_WILLIAMS|\n",
       "|    2024-06-24|   PAT0099|        Z51.11| Encounter for ant...|         DR_GARCIA|\n",
       "|    2024-06-19|   PAT0082|        Z51.11| Encounter for ant...|          DR_BROWN|\n",
       "|    2024-06-18|   PAT0018|        Z51.11| Encounter for ant...|          DR_DAVIS|\n",
       "|    2024-06-16|   PAT0091|        Z51.11| Encounter for ant...|       DR_WILLIAMS|\n",
       "|    2024-06-05|   PAT0056|        Z51.11| Encounter for ant...|        DR_JOHNSON|\n",
       "|    2024-06-03|   PAT0042|        Z51.11| Encounter for ant...|          DR_JONES|\n",
       "|    2024-05-31|   PAT0062|        Z51.11| Encounter for ant...|          DR_SMITH|\n",
       "|    2024-05-24|   PAT0023|        Z51.11| Encounter for ant...|          DR_SMITH|\n",
       "|    2024-05-24|   PAT0088|        Z51.11| Encounter for ant...|          DR_BROWN|\n",
       "|    2024-05-22|   PAT0096|        Z51.11| Encounter for ant...|          DR_BROWN|\n",
       "|    2024-05-14|   PAT0097|        Z51.11| Encounter for ant...|          DR_SMITH|\n",
       "|    2024-05-10|   PAT0019|        Z51.11| Encounter for ant...|          DR_JONES|\n",
       "|    2024-04-30|   PAT0009|        Z51.11| Encounter for ant...|        DR_JOHNSON|\n",
       "|    2024-04-24|   PAT0026|        Z51.11| Encounter for ant...|          DR_SMITH|\n",
       "|    2024-04-12|   PAT0100|        Z51.11| Encounter for ant...|          DR_DAVIS|\n",
       "|    2024-04-10|   PAT0052|        Z51.11| Encounter for ant...|          DR_DAVIS|\n",
       "|    2024-04-10|   PAT0069|        Z51.11| Encounter for ant...|         DR_GARCIA|\n",
       "|    2024-04-04|   PAT0053|        Z51.11| Encounter for ant...|         DR_MILLER|\n",
       "|    2024-04-03|   PAT0057|        Z51.11| Encounter for ant...|          DR_SMITH|\n",
       "+--------------+----------+--------------+---------------------+------------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Critical diagnoses found: 21\n",
       "\n",
       "=== Query 3: Patient Timeline Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------+--------------+--------------+-----------+\n",
       "|patient_id|diagnosis_date|diagnosis_code|severity_level|facility_id|\n",
       "+----------+--------------+--------------+--------------+-----------+\n",
       "|   PAT0010|    2024-05-05|         E11.9|        Medium|    HOSP002|\n",
       "|   PAT0010|    2024-05-21|         M79.3|           Low|  URGENT001|\n",
       "|   PAT0010|    2024-06-28|         M54.5|           Low|    HOSP002|\n",
       "|   PAT0011|    2024-03-09|         F41.9|        Medium|    HOSP002|\n",
       "|   PAT0011|    2024-03-29|         N39.0|        Medium|  CLINIC001|\n",
       "|   PAT0012|    2024-04-14|         M54.5|           Low|  URGENT001|\n",
       "|   PAT0012|    2024-04-17|         M79.3|           Low|  CLINIC002|\n",
       "|   PAT0012|    2024-06-03|           I10|          High|    HOSP002|\n",
       "|   PAT0013|    2024-06-18|         E11.9|        Medium|  CLINIC001|\n",
       "|   PAT0014|    2024-04-04|       J45.909|        Medium|    HOSP001|\n",
       "|   PAT0014|    2024-05-13|         N39.0|        Medium|    HOSP002|\n",
       "|   PAT0014|    2024-05-24|         M54.5|           Low|  CLINIC002|\n",
       "|   PAT0015|    2024-04-16|         N39.0|        Medium|    HOSP001|\n",
       "|   PAT0015|    2024-04-18|        Z00.00|           Low|  URGENT001|\n",
       "|   PAT0015|    2024-04-27|         F41.9|        Medium|  CLINIC002|\n",
       "|   PAT0016|    2024-04-30|         E11.9|        Medium|  URGENT001|\n",
       "|   PAT0016|    2024-06-21|       J45.909|        Medium|    HOSP002|\n",
       "|   PAT0017|    2024-05-24|        Z00.00|           Low|  CLINIC001|\n",
       "|   PAT0018|    2024-05-01|         M54.5|           Low|    HOSP002|\n",
       "|   PAT0018|    2024-06-18|        Z51.11|      Critical|    HOSP002|\n",
       "+----------+--------------+--------------+--------------+-----------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timeline records found: 25\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate liquid clustering benefits with optimized queries\n",
    "\n",
    "# Query 1: Patient history - benefits from patient_id clustering\n",
    "print(\"=== Query 1: Patient Diagnosis History ===\")\n",
    "patient_history = spark.sql(\"\"\"\n",
    "SELECT patient_id, diagnosis_date, diagnosis_code, diagnosis_description, severity_level\n",
    "FROM healthcare.gold.patient_diagnoses\n",
    "WHERE patient_id = 'PAT0001'\n",
    "ORDER BY diagnosis_date\n",
    "\"\"\")\n",
    "\n",
    "patient_history.show()\n",
    "print(f\"Records found: {patient_history.count()}\")\n",
    "\n",
    "# Query 2: Time-based analysis - benefits from diagnosis_date clustering\n",
    "print(\"\\n=== Query 2: Recent Critical Diagnoses ===\")\n",
    "recent_critical = spark.sql(\"\"\"\n",
    "SELECT diagnosis_date, patient_id, diagnosis_code, diagnosis_description, treating_physician\n",
    "FROM healthcare.gold.patient_diagnoses\n",
    "WHERE diagnosis_date >= '2024-04-01' AND severity_level = 'Critical'\n",
    "ORDER BY diagnosis_date DESC\n",
    "\"\"\")\n",
    "\n",
    "recent_critical.show()\n",
    "print(f\"Critical diagnoses found: {recent_critical.count()}\")\n",
    "\n",
    "# Query 3: Combined patient + time query - optimal for our clustering strategy\n",
    "print(\"\\n=== Query 3: Patient Timeline Analysis ===\")\n",
    "patient_timeline = spark.sql(\"\"\"\n",
    "SELECT patient_id, diagnosis_date, diagnosis_code, severity_level, facility_id\n",
    "FROM healthcare.gold.patient_diagnoses\n",
    "WHERE patient_id LIKE 'PAT001%' AND diagnosis_date >= '2024-03-01'\n",
    "ORDER BY patient_id, diagnosis_date\n",
    "\"\"\")\n",
    "\n",
    "patient_timeline.show()\n",
    "print(f\"Timeline records found: {patient_timeline.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Clustering Effectiveness\n",
    "\n",
    "### Understanding the Impact\n",
    "\n",
    "Let's examine how liquid clustering has organized our data and analyze some aggregate statistics to demonstrate the healthcare insights possible with this optimized structure.\n",
    "\n",
    "### Key Analytics\n",
    "\n",
    "- **Diagnosis frequency** by type\n",
    "- **Severity distribution** across facilities\n",
    "- **Physician workload** analysis\n",
    "- **Temporal patterns** in diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Diagnosis Frequency Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+--------------+-------------------------------------------------------------------------------+---------+----------+\n",
       "|diagnosis_code|diagnosis_description                                                          |frequency|percentage|\n",
       "+--------------+-------------------------------------------------------------------------------+---------+----------+\n",
       "|Z00.00        |Encounter for general adult medical examination without abnormal findings      |43       |12.29     |\n",
       "|N39.0         |Urinary tract infection, site not specified                                    |40       |11.43     |\n",
       "|M54.5         |Low back pain                                                                  |40       |11.43     |\n",
       "|Z51.11        |Encounter for antineoplastic chemotherapy                                      |38       |10.86     |\n",
       "|J45.909       |Unspecified asthma, uncomplicated                                              |37       |10.57     |\n",
       "|F41.9         |Anxiety disorder, unspecified                                                  |36       |10.29     |\n",
       "|E11.9         |Type 2 diabetes mellitus without complications                                 |33       |9.43      |\n",
       "|M79.3         |Panniculitis, unspecified                                                      |30       |8.57      |\n",
       "|I10           |Essential hypertension                                                         |28       |8.00      |\n",
       "|I25.10        |Atherosclerotic heart disease of native coronary artery without angina pectoris|25       |7.14      |\n",
       "+--------------+-------------------------------------------------------------------------------+---------+----------+\n",
       "\n",
       "\n",
       "=== Severity Distribution by Facility ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-----------+--------------+-----+\n",
       "|facility_id|severity_level|count|\n",
       "+-----------+--------------+-----+\n",
       "|  CLINIC001|      Critical|    8|\n",
       "|  CLINIC001|          High|    8|\n",
       "|  CLINIC001|           Low|   20|\n",
       "|  CLINIC001|        Medium|   25|\n",
       "|  CLINIC002|      Critical|    8|\n",
       "|  CLINIC002|          High|    9|\n",
       "|  CLINIC002|           Low|   24|\n",
       "|  CLINIC002|        Medium|   23|\n",
       "|    HOSP001|      Critical|    6|\n",
       "|    HOSP001|          High|    8|\n",
       "|    HOSP001|           Low|   18|\n",
       "|    HOSP001|        Medium|   30|\n",
       "|    HOSP002|      Critical|   10|\n",
       "|    HOSP002|          High|   14|\n",
       "|    HOSP002|           Low|   27|\n",
       "|    HOSP002|        Medium|   33|\n",
       "|  URGENT001|      Critical|    6|\n",
       "|  URGENT001|          High|   14|\n",
       "|  URGENT001|           Low|   24|\n",
       "|  URGENT001|        Medium|   35|\n",
       "+-----------+--------------+-----+\n",
       "\n",
       "\n",
       "=== Physician Workload Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+------------------+---------------+---------------+-------------------+\n",
       "|treating_physician|total_diagnoses|unique_patients|critical_case_ratio|\n",
       "+------------------+---------------+---------------+-------------------+\n",
       "|          DR_BROWN|             57|             45|              0.123|\n",
       "|          DR_DAVIS|             56|             42|              0.089|\n",
       "|          DR_SMITH|             47|             38|               0.17|\n",
       "|         DR_GARCIA|             45|             38|              0.133|\n",
       "|       DR_WILLIAMS|             40|             30|              0.075|\n",
       "|         DR_MILLER|             38|             33|              0.079|\n",
       "|        DR_JOHNSON|             37|             35|              0.108|\n",
       "|          DR_JONES|             30|             27|              0.067|\n",
       "+------------------+---------------+---------------+-------------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze clustering effectiveness and healthcare insights\n",
    "\n",
    "# Diagnosis frequency analysis\n",
    "print(\"=== Diagnosis Frequency Analysis ===\")\n",
    "diagnosis_freq = spark.sql(\"\"\"\n",
    "SELECT diagnosis_code, diagnosis_description, COUNT(*) as frequency,\n",
    "       ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 2) as percentage\n",
    "FROM healthcare.gold.patient_diagnoses\n",
    "GROUP BY diagnosis_code, diagnosis_description\n",
    "ORDER BY frequency DESC\n",
    "\"\"\")\n",
    "\n",
    "diagnosis_freq.show(truncate=False)\n",
    "\n",
    "# Severity distribution by facility\n",
    "print(\"\\n=== Severity Distribution by Facility ===\")\n",
    "severity_by_facility = spark.sql(\"\"\"\n",
    "SELECT facility_id, severity_level, COUNT(*) as count\n",
    "FROM healthcare.gold.patient_diagnoses\n",
    "GROUP BY facility_id, severity_level\n",
    "ORDER BY facility_id, severity_level\n",
    "\"\"\")\n",
    "\n",
    "severity_by_facility.show()\n",
    "\n",
    "# Physician workload analysis\n",
    "print(\"\\n=== Physician Workload Analysis ===\")\n",
    "physician_workload = spark.sql(\"\"\"\n",
    "SELECT treating_physician, COUNT(*) as total_diagnoses,\n",
    "       COUNT(DISTINCT patient_id) as unique_patients,\n",
    "       ROUND(AVG(CASE WHEN severity_level = 'Critical' THEN 1 ELSE 0 END), 3) as critical_case_ratio\n",
    "FROM healthcare.gold.patient_diagnoses\n",
    "GROUP BY treating_physician\n",
    "ORDER BY total_diagnoses DESC\n",
    "\"\"\")\n",
    "\n",
    "physician_workload.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: Delta Liquid Clustering in AIDP\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Automatic Optimization**: Created a table with `CLUSTER BY (patient_id, diagnosis_date)` and let Delta automatically optimize data layout\n",
    "\n",
    "2. **Performance Benefits**: Queries on clustered columns (patient_id, diagnosis_date) are significantly faster due to data locality\n",
    "\n",
    "3. **Zero Maintenance**: No manual partitioning, bucketing, or Z-Ordering required - Delta handles it automatically\n",
    "\n",
    "4. **Real-World Use Case**: Healthcare analytics where patient history lookups and temporal analysis are critical\n",
    "\n",
    "### AIDP Advantages\n",
    "\n",
    "- **Unified Analytics**: Seamlessly integrates with other AIDP services\n",
    "- **Governance**: Catalog and schema isolation for healthcare data\n",
    "- **Performance**: Optimized for both OLAP and OLTP workloads\n",
    "- **Scalability**: Handles healthcare-scale data volumes effortlessly\n",
    "\n",
    "### Best Practices for Liquid Clustering\n",
    "\n",
    "1. **Choose clustering columns** based on your most common query patterns\n",
    "2. **Start with 1-4 columns** - too many can reduce effectiveness\n",
    "3. **Consider cardinality** - high-cardinality columns work best\n",
    "4. **Monitor and adjust** as query patterns evolve\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore other AIDP features like AI/ML integration\n",
    "- Try liquid clustering with different column combinations\n",
    "- Scale up to larger healthcare datasets\n",
    "- Integrate with real healthcare systems\n",
    "\n",
    "This notebook demonstrates how Oracle AI Data Platform makes advanced analytics accessible while maintaining enterprise-grade performance and governance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
