{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Media: Delta Liquid Clustering Demo\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "This notebook demonstrates the power of **Delta Liquid Clustering** in Oracle AI Data Platform (AIDP) Workbench using a media and entertainment analytics use case. Liquid clustering automatically optimizes data layout for query performance without requiring manual partitioning or Z-Ordering.\n",
    "\n",
    "### What is Liquid Clustering?\n",
    "\n",
    "Liquid clustering automatically identifies and groups similar data together based on clustering columns you define. This optimization happens automatically during data ingestion and maintenance operations, providing:\n",
    "\n",
    "- **Automatic optimization**: No manual tuning required\n",
    "- **Improved query performance**: Faster queries on clustered columns\n",
    "- **Reduced maintenance**: No need for manual repartitioning\n",
    "- **Adaptive clustering**: Adjusts as data patterns change\n",
    "\n",
    "### Use Case: Content Performance and User Engagement Analytics\n",
    "\n",
    "We'll analyze media content consumption and user engagement data. Our clustering strategy will optimize for:\n",
    "\n",
    "- **User-specific queries**: Fast lookups by user ID\n",
    "- **Time-based analysis**: Efficient filtering by viewing and engagement dates\n",
    "- **Content performance patterns**: Quick aggregation by content type and engagement metrics\n",
    "\n",
    "### AIDP Environment Setup\n",
    "\n",
    "This notebook leverages the existing Spark session in your AIDP environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Media catalog and analytics schema created successfully!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create media catalog and analytics schema\n",
    "\n",
    "# In AIDP, catalogs provide data isolation and governance\n",
    "\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS media\")\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS media.analytics\")\n",
    "\n",
    "print(\"Media catalog and analytics schema created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Delta Table with Liquid Clustering\n",
    "\n",
    "### Table Design\n",
    "\n",
    "Our `content_engagement` table will store:\n",
    "\n",
    "- **user_id**: Unique user identifier\n",
    "- **engagement_date**: Date and time of engagement\n",
    "- **content_type**: Type (Video, Article, Podcast, Live Stream)\n",
    "- **watch_time**: Time spent consuming content (minutes)\n",
    "- **content_id**: Specific content identifier\n",
    "- **engagement_score**: User engagement metric (0-100)\n",
    "- **device_type**: Device used (Mobile, Desktop, TV, etc.)\n",
    "\n",
    "### Clustering Strategy\n",
    "\n",
    "We'll cluster by `user_id` and `engagement_date` because:\n",
    "\n",
    "- **user_id**: Users consume multiple pieces of content, grouping their viewing history together\n",
    "- **engagement_date**: Time-based queries are critical for content performance analysis, recommendation systems, and user behavior trends\n",
    "- This combination optimizes for both personalized content recommendations and temporal engagement analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delta table with liquid clustering created successfully!\n",
       "Clustering will automatically optimize data layout for queries on user_id and engagement_date.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Delta table with liquid clustering\n",
    "\n",
    "# CLUSTER BY defines the columns for automatic optimization\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS media.analytics.content_engagement (\n",
    "\n",
    "    user_id STRING,\n",
    "\n",
    "    engagement_date TIMESTAMP,\n",
    "\n",
    "    content_type STRING,\n",
    "\n",
    "    watch_time DECIMAL(8,2),\n",
    "\n",
    "    content_id STRING,\n",
    "\n",
    "    engagement_score INT,\n",
    "\n",
    "    device_type STRING\n",
    "\n",
    ")\n",
    "\n",
    "USING DELTA\n",
    "\n",
    "CLUSTER BY (user_id, engagement_date)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"Delta table with liquid clustering created successfully!\")\n",
    "\n",
    "print(\"Clustering will automatically optimize data layout for queries on user_id and engagement_date.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Media Sample Data\n",
    "\n",
    "### Data Generation Strategy\n",
    "\n",
    "We'll create realistic media engagement data including:\n",
    "\n",
    "- **12,000 users** with multiple content interactions over time\n",
    "- **Content types**: Video, Article, Podcast, Live Stream\n",
    "- **Realistic engagement patterns**: Peak viewing times, content preferences, device usage\n",
    "- **Engagement metrics**: Watch time, completion rates, interaction scores\n",
    "\n",
    "### Why This Data Pattern?\n",
    "\n",
    "This data simulates real media scenarios where:\n",
    "\n",
    "- User preferences drive content recommendations\n",
    "- Engagement metrics determine content success\n",
    "- Device usage affects viewing experience\n",
    "- Time-based patterns influence programming decisions\n",
    "- Personalization requires historical user behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generated 299540 content engagement records\n",
       "Sample record: {'user_id': 'USER000001', 'engagement_date': datetime.datetime(2024, 8, 13, 17, 29), 'content_type': 'Podcast', 'watch_time': 34.22, 'content_id': 'POD96528', 'engagement_score': 74, 'device_type': 'Desktop'}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample media engagement data\n",
    "\n",
    "# Using fully qualified imports to avoid conflicts\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define media data constants\n",
    "\n",
    "CONTENT_TYPES = ['Video', 'Article', 'Podcast', 'Live Stream']\n",
    "\n",
    "DEVICE_TYPES = ['Mobile', 'Desktop', 'Tablet', 'Smart TV', 'Gaming Console']\n",
    "\n",
    "# Base engagement parameters by content type\n",
    "\n",
    "ENGAGEMENT_PARAMS = {\n",
    "\n",
    "    'Video': {'avg_watch_time': 15, 'engagement_base': 75, 'frequency': 12},\n",
    "\n",
    "    'Article': {'avg_watch_time': 8, 'engagement_base': 65, 'frequency': 8},\n",
    "\n",
    "    'Podcast': {'avg_watch_time': 25, 'engagement_base': 70, 'frequency': 6},\n",
    "\n",
    "    'Live Stream': {'avg_watch_time': 45, 'engagement_base': 80, 'frequency': 4}\n",
    "\n",
    "}\n",
    "\n",
    "# Device engagement multipliers\n",
    "\n",
    "DEVICE_MULTIPLIERS = {\n",
    "\n",
    "    'Mobile': 0.9, 'Desktop': 1.0, 'Tablet': 0.95, 'Smart TV': 1.1, 'Gaming Console': 1.05\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Generate content engagement records\n",
    "\n",
    "engagement_data = []\n",
    "\n",
    "base_date = datetime(2024, 1, 1)\n",
    "\n",
    "\n",
    "# Create 12,000 users with 10-40 engagement events each\n",
    "\n",
    "for user_num in range(1, 12001):\n",
    "\n",
    "    user_id = f\"USER{user_num:06d}\"\n",
    "    \n",
    "    # Each user gets 10-40 engagement events over 12 months\n",
    "\n",
    "    num_engagements = random.randint(10, 40)\n",
    "    \n",
    "    for i in range(num_engagements):\n",
    "\n",
    "        # Spread engagements over 12 months\n",
    "\n",
    "        days_offset = random.randint(0, 365)\n",
    "\n",
    "        engagement_date = base_date + timedelta(days=days_offset)\n",
    "        \n",
    "        # Add realistic timing (more engagement during certain hours)\n",
    "\n",
    "        hour_weights = [2, 1, 1, 1, 1, 1, 3, 6, 8, 7, 6, 7, 8, 9, 10, 9, 8, 10, 12, 9, 7, 5, 4, 3]\n",
    "\n",
    "        hours_offset = random.choices(range(24), weights=hour_weights)[0]\n",
    "\n",
    "        engagement_date = engagement_date.replace(hour=hours_offset, minute=random.randint(0, 59), second=0, microsecond=0)\n",
    "        \n",
    "        # Select content type\n",
    "\n",
    "        content_type = random.choice(CONTENT_TYPES)\n",
    "\n",
    "        params = ENGAGEMENT_PARAMS[content_type]\n",
    "        \n",
    "        # Select device type\n",
    "\n",
    "        device_type = random.choice(DEVICE_TYPES)\n",
    "\n",
    "        device_multiplier = DEVICE_MULTIPLIERS[device_type]\n",
    "        \n",
    "        # Calculate watch time with variations\n",
    "\n",
    "        time_variation = random.uniform(0.3, 2.5)\n",
    "\n",
    "        watch_time = round(params['avg_watch_time'] * time_variation * device_multiplier, 2)\n",
    "        \n",
    "        # Content ID\n",
    "\n",
    "        content_id = f\"{content_type[:3].upper()}{random.randint(10000, 99999)}\"\n",
    "        \n",
    "        # Engagement score (based on content type, device, and some randomness)\n",
    "\n",
    "        engagement_variation = random.randint(-15, 15)\n",
    "\n",
    "        engagement_score = max(0, min(100, int(params['engagement_base'] * device_multiplier) + engagement_variation))\n",
    "        \n",
    "        engagement_data.append({\n",
    "\n",
    "            \"user_id\": user_id,\n",
    "\n",
    "            \"engagement_date\": engagement_date,\n",
    "\n",
    "            \"content_type\": content_type,\n",
    "\n",
    "            \"watch_time\": watch_time,\n",
    "\n",
    "            \"content_id\": content_id,\n",
    "\n",
    "            \"engagement_score\": engagement_score,\n",
    "\n",
    "            \"device_type\": device_type\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Generated {len(engagement_data)} content engagement records\")\n",
    "\n",
    "print(\"Sample record:\", engagement_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Insert Data Using PySpark\n",
    "\n",
    "### Data Insertion Strategy\n",
    "\n",
    "We'll use PySpark to:\n",
    "\n",
    "1. **Create DataFrame** from our generated data\n",
    "2. **Insert into Delta table** with liquid clustering\n",
    "3. **Verify the insertion** with a sample query\n",
    "\n",
    "### Why PySpark for Insertion?\n",
    "\n",
    "- **Distributed processing**: Handles large datasets efficiently\n",
    "- **Type safety**: Ensures data integrity\n",
    "- **Optimization**: Leverages Spark's query optimization\n",
    "- **Liquid clustering**: Automatically applies clustering during insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame Schema:\n",
       "root\n",
       " |-- content_id: string (nullable = true)\n",
       " |-- content_type: string (nullable = true)\n",
       " |-- device_type: string (nullable = true)\n",
       " |-- engagement_date: timestamp (nullable = true)\n",
       " |-- engagement_score: long (nullable = true)\n",
       " |-- user_id: string (nullable = true)\n",
       " |-- watch_time: double (nullable = true)\n",
       "\n",
       "\n",
       "Sample Data:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+------------+--------------+-------------------+----------------+----------+----------+\n",
       "|content_id|content_type|   device_type|    engagement_date|engagement_score|   user_id|watch_time|\n",
       "+----------+------------+--------------+-------------------+----------------+----------+----------+\n",
       "|  POD96528|     Podcast|       Desktop|2024-08-13 17:29:00|              74|USER000001|     34.22|\n",
       "|  VID98484|       Video|        Mobile|2024-09-04 00:59:00|              81|USER000001|     13.27|\n",
       "|  VID15293|       Video|        Tablet|2024-01-01 10:39:00|              84|USER000001|      9.75|\n",
       "|  POD83689|     Podcast|        Mobile|2024-06-04 20:33:00|              76|USER000001|     41.79|\n",
       "|  POD56644|     Podcast|Gaming Console|2024-02-19 13:31:00|              63|USER000001|      27.7|\n",
       "+----------+------------+--------------+-------------------+----------------+----------+----------+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Successfully inserted 299540 records into media.analytics.content_engagement\n",
       "Liquid clustering automatically optimized the data layout during insertion!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert data using PySpark DataFrame operations\n",
    "\n",
    "# Using fully qualified function references to avoid conflicts\n",
    "\n",
    "\n",
    "# Create DataFrame from generated data\n",
    "\n",
    "df_engagement = spark.createDataFrame(engagement_data)\n",
    "\n",
    "\n",
    "# Display schema and sample data\n",
    "\n",
    "print(\"DataFrame Schema:\")\n",
    "\n",
    "df_engagement.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "\n",
    "df_engagement.show(5)\n",
    "\n",
    "\n",
    "# Insert data into Delta table with liquid clustering\n",
    "\n",
    "# The CLUSTER BY (user_id, engagement_date) will automatically optimize the data layout\n",
    "\n",
    "df_engagement.write.mode(\"overwrite\").saveAsTable(\"media.analytics.content_engagement\")\n",
    "\n",
    "\n",
    "print(f\"\\nSuccessfully inserted {df_engagement.count()} records into media.analytics.content_engagement\")\n",
    "\n",
    "print(\"Liquid clustering automatically optimized the data layout during insertion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate Liquid Clustering Benefits\n",
    "\n",
    "### Query Performance Analysis\n",
    "\n",
    "Now let's see how liquid clustering improves query performance. We'll run queries that benefit from our clustering strategy:\n",
    "\n",
    "1. **User engagement history** (clustered by user_id)\n",
    "2. **Time-based content analysis** (clustered by engagement_date)\n",
    "3. **Combined user + time queries** (optimal for our clustering)\n",
    "\n",
    "### Expected Performance Benefits\n",
    "\n",
    "With liquid clustering, these queries should be significantly faster because:\n",
    "\n",
    "- **Data locality**: Related records are physically grouped together\n",
    "- **Reduced I/O**: Less data needs to be read from disk\n",
    "- **Automatic optimization**: No manual tuning required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Query 1: User Engagement History ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+------------+----------+----------------+\n",
       "|   user_id|    engagement_date|content_type|watch_time|engagement_score|\n",
       "+----------+-------------------+------------+----------+----------------+\n",
       "|USER000001|2024-12-30 07:16:00|     Podcast|     41.06|              83|\n",
       "|USER000001|2024-12-08 17:18:00|     Podcast|     13.61|              75|\n",
       "|USER000001|2024-11-27 07:56:00|     Article|     18.44|              63|\n",
       "|USER000001|2024-10-15 15:23:00| Live Stream|     111.8|              80|\n",
       "|USER000001|2024-09-04 00:59:00|       Video|     13.27|              81|\n",
       "|USER000001|2024-09-03 23:01:00| Live Stream|      65.6|              88|\n",
       "|USER000001|2024-09-03 14:35:00| Live Stream|     44.77|              91|\n",
       "|USER000001|2024-08-20 19:50:00|     Podcast|     40.36|              67|\n",
       "|USER000001|2024-08-13 17:29:00|     Podcast|     34.22|              74|\n",
       "|USER000001|2024-07-17 23:14:00| Live Stream|     113.5|              74|\n",
       "+----------+-------------------+------------+----------+----------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Records found: 10\n",
       "\n",
       "=== Query 2: Recent High-Engagement Content ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------------+----------+----------+------------+----------------+----------+\n",
       "|    engagement_date|   user_id|content_id|content_type|engagement_score|watch_time|\n",
       "+-------------------+----------+----------+------------+----------------+----------+\n",
       "|2024-02-15 16:33:00|USER004701|  LIV23443| Live Stream|             100|     111.0|\n",
       "|2024-02-15 15:56:00|USER009133|  LIV37632| Live Stream|             100|    107.46|\n",
       "|2024-02-15 06:56:00|USER005956|  LIV52538| Live Stream|             100|    102.42|\n",
       "|2024-02-15 15:32:00|USER002011|  LIV53566| Live Stream|             100|     57.66|\n",
       "|2024-02-15 10:38:00|USER004131|  LIV78476| Live Stream|             100|     21.97|\n",
       "|2024-02-15 07:53:00|USER001098|  LIV42709| Live Stream|             100|     21.52|\n",
       "|2024-02-15 15:50:00|USER011262|  LIV59439| Live Stream|              99|     74.89|\n",
       "|2024-02-15 13:38:00|USER006084|  LIV42623| Live Stream|              98|    110.39|\n",
       "|2024-02-15 02:57:00|USER010226|  LIV65581| Live Stream|              98|     21.21|\n",
       "|2024-02-15 18:31:00|USER010806|  LIV22812| Live Stream|              97|    104.68|\n",
       "|2024-02-15 15:57:00|USER011843|  LIV75072| Live Stream|              97|     85.95|\n",
       "|2024-02-15 19:05:00|USER001313|  LIV27251| Live Stream|              97|     80.72|\n",
       "|2024-02-15 13:35:00|USER002206|  LIV20408| Live Stream|              97|      26.6|\n",
       "|2024-02-15 21:38:00|USER010468|  LIV75912| Live Stream|              96|    111.89|\n",
       "|2024-02-15 15:08:00|USER010862|  LIV57131| Live Stream|              96|     85.56|\n",
       "|2024-02-15 13:46:00|USER007068|  LIV56576| Live Stream|              96|     73.59|\n",
       "|2024-02-15 14:03:00|USER002667|  LIV60308| Live Stream|              96|     43.27|\n",
       "|2024-02-15 11:15:00|USER003909|  VID86057|       Video|              96|     26.42|\n",
       "|2024-02-15 08:09:00|USER009458|  LIV92626| Live Stream|              95|    107.98|\n",
       "|2024-02-15 14:27:00|USER006756|  LIV23306| Live Stream|              95|    105.01|\n",
       "+-------------------+----------+----------+------------+----------------+----------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "High-engagement records found: 106\n",
       "\n",
       "=== Query 3: User Content Preferences ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+------------+----------+--------------+\n",
       "|   user_id|    engagement_date|content_type|watch_time|   device_type|\n",
       "+----------+-------------------+------------+----------+--------------+\n",
       "|USER000001|2024-02-19 13:31:00|     Podcast|      27.7|Gaming Console|\n",
       "|USER000001|2024-03-06 18:48:00| Live Stream|     93.56|        Mobile|\n",
       "|USER000001|2024-03-19 21:42:00|       Video|     32.25|       Desktop|\n",
       "|USER000001|2024-03-26 07:32:00|     Podcast|      17.3|      Smart TV|\n",
       "|USER000001|2024-04-02 12:00:00|     Podcast|     40.56|      Smart TV|\n",
       "|USER000001|2024-04-02 13:07:00|     Podcast|     24.74|       Desktop|\n",
       "|USER000001|2024-04-27 14:31:00|     Podcast|     32.07|        Tablet|\n",
       "|USER000001|2024-05-05 23:26:00|       Video|     11.33|        Tablet|\n",
       "|USER000001|2024-05-06 18:32:00|     Podcast|      17.0|        Tablet|\n",
       "|USER000001|2024-06-04 20:33:00|     Podcast|     41.79|        Mobile|\n",
       "|USER000001|2024-06-06 13:12:00|       Video|     30.08|      Smart TV|\n",
       "|USER000001|2024-06-08 10:16:00| Live Stream|      95.7|        Mobile|\n",
       "|USER000001|2024-06-21 09:42:00| Live Stream|     54.65|        Mobile|\n",
       "|USER000001|2024-07-17 23:14:00| Live Stream|     113.5|      Smart TV|\n",
       "|USER000001|2024-08-13 17:29:00|     Podcast|     34.22|       Desktop|\n",
       "|USER000001|2024-08-20 19:50:00|     Podcast|     40.36|       Desktop|\n",
       "|USER000001|2024-09-03 14:35:00| Live Stream|     44.77|       Desktop|\n",
       "|USER000001|2024-09-03 23:01:00| Live Stream|      65.6|        Tablet|\n",
       "|USER000001|2024-09-04 00:59:00|       Video|     13.27|        Mobile|\n",
       "|USER000001|2024-10-15 15:23:00| Live Stream|     111.8|      Smart TV|\n",
       "+----------+-------------------+------------+----------+--------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "User preference records found: 25\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate liquid clustering benefits with optimized queries\n",
    "\n",
    "\n",
    "# Query 1: User engagement history - benefits from user_id clustering\n",
    "\n",
    "print(\"=== Query 1: User Engagement History ===\")\n",
    "\n",
    "user_history = spark.sql(\"\"\"\n",
    "\n",
    "SELECT user_id, engagement_date, content_type, watch_time, engagement_score\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "WHERE user_id = 'USER000001'\n",
    "\n",
    "ORDER BY engagement_date DESC\n",
    "\n",
    "LIMIT 10\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "user_history.show()\n",
    "\n",
    "print(f\"Records found: {user_history.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 2: Time-based high-engagement content analysis - benefits from engagement_date clustering\n",
    "\n",
    "print(\"\\n=== Query 2: Recent High-Engagement Content ===\")\n",
    "\n",
    "high_engagement = spark.sql(\"\"\"\n",
    "\n",
    "SELECT engagement_date, user_id, content_id, content_type, engagement_score, watch_time\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "WHERE DATE(engagement_date) = '2024-02-15' AND engagement_score > 85\n",
    "\n",
    "ORDER BY engagement_score DESC, watch_time DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "high_engagement.show()\n",
    "\n",
    "print(f\"High-engagement records found: {high_engagement.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 3: Combined user + time query - optimal for our clustering strategy\n",
    "\n",
    "print(\"\\n=== Query 3: User Content Preferences ===\")\n",
    "\n",
    "user_preferences = spark.sql(\"\"\"\n",
    "\n",
    "SELECT user_id, engagement_date, content_type, watch_time, device_type\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "WHERE user_id LIKE 'USER000%' AND engagement_date >= '2024-02-01'\n",
    "\n",
    "ORDER BY user_id, engagement_date\n",
    "\n",
    "LIMIT 25\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "user_preferences.show()\n",
    "\n",
    "print(f\"User preference records found: {user_preferences.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Clustering Effectiveness\n",
    "\n",
    "### Understanding the Impact\n",
    "\n",
    "Let's examine how liquid clustering has organized our data and analyze some aggregate statistics to demonstrate the media insights possible with this optimized structure.\n",
    "\n",
    "### Key Analytics\n",
    "\n",
    "- **User engagement patterns** and content preferences\n",
    "- **Content performance** by type and popularity metrics\n",
    "- **Device usage trends** and platform optimization\n",
    "- **Time-based consumption patterns** and programming insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== User Engagement Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------+----------------+----------------+--------------+------------------+\n",
       "|   user_id|total_sessions|total_watch_time|avg_session_time|avg_engagement|content_types_used|\n",
       "+----------+--------------+----------------+----------------+--------------+------------------+\n",
       "|USER007579|            40|         1877.93|           46.95|         75.13|                 4|\n",
       "|USER005840|            37|         1833.53|           49.55|         74.32|                 4|\n",
       "|USER001865|            38|         1811.01|           47.66|         74.92|                 4|\n",
       "|USER004356|            38|         1750.62|           46.07|         72.79|                 4|\n",
       "|USER007922|            36|         1738.63|            48.3|         75.08|                 4|\n",
       "|USER002936|            35|         1729.81|           49.42|         69.69|                 4|\n",
       "|USER002713|            40|         1712.54|           42.81|         71.73|                 4|\n",
       "|USER007310|            40|         1705.58|           42.64|          74.9|                 4|\n",
       "|USER001554|            39|         1680.15|           43.08|         72.31|                 4|\n",
       "|USER008670|            40|         1678.74|           41.97|          75.5|                 4|\n",
       "+----------+--------------+----------------+----------------+--------------+------------------+\n",
       "\n",
       "\n",
       "=== Content Type Performance ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+------------+-----------------+----------------+--------------+--------------+------------+--------------+\n",
       "|content_type|total_engagements|total_watch_time|avg_watch_time|avg_engagement|unique_users|unique_content|\n",
       "+------------+-----------------+----------------+--------------+--------------+------------+--------------+\n",
       "| Live Stream|            75054|      4737522.68|         63.12|         79.97|       11912|         50853|\n",
       "|     Podcast|            75096|      2632220.72|         35.05|         69.87|       11904|         51028|\n",
       "|       Video|            74449|      1568878.01|         21.07|         74.64|       11906|         50616|\n",
       "|     Article|            74941|       839239.02|          11.2|         64.59|       11923|         50708|\n",
       "+------------+-----------------+----------------+--------------+--------------+------------+--------------+\n",
       "\n",
       "\n",
       "=== Device Usage Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+--------------+--------------+----------------+----------------+--------------+------------+\n",
       "|   device_type|total_sessions|total_watch_time|avg_session_time|avg_engagement|unique_users|\n",
       "+--------------+--------------+----------------+----------------+--------------+------------+\n",
       "|      Smart TV|         60108|      2160351.14|           35.94|         79.43|       11778|\n",
       "|Gaming Console|         59734|      2028688.05|           33.96|         75.74|       11802|\n",
       "|       Desktop|         59949|      1969632.73|           32.86|          72.5|       11783|\n",
       "|        Tablet|         60175|      1869267.79|           31.06|         68.54|       11804|\n",
       "|        Mobile|         59574|      1749920.72|           29.37|         65.08|       11784|\n",
       "+--------------+--------------+----------------+----------------+--------------+------------+\n",
       "\n",
       "\n",
       "=== Hourly Engagement Patterns ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-----------+-----------------+----------------+--------------+------------+\n",
       "|hour_of_day|engagement_events|total_watch_time|avg_engagement|active_users|\n",
       "+-----------+-----------------+----------------+--------------+------------+\n",
       "|          0|               15|           472.0|         71.47|          15|\n",
       "|          1|                7|          158.18|         73.71|           7|\n",
       "|          2|                8|           322.8|         68.25|           8|\n",
       "|          3|                6|          199.68|          68.0|           6|\n",
       "|          4|                8|          219.29|         68.88|           8|\n",
       "|          5|                3|          116.65|         76.33|           3|\n",
       "|          6|               18|           568.5|         72.56|          18|\n",
       "|          7|               42|         1211.49|         71.38|          42|\n",
       "|          8|               43|         1407.64|         73.84|          43|\n",
       "|          9|               47|          1604.9|         70.06|          47|\n",
       "|         10|               39|         1341.92|         71.82|          39|\n",
       "|         11|               48|         1707.31|         75.85|          48|\n",
       "|         12|               49|         1723.38|         72.92|          49|\n",
       "|         13|               70|          2297.3|         72.96|          70|\n",
       "|         14|               47|         1873.51|         73.87|          47|\n",
       "|         15|               51|         1556.71|         72.69|          51|\n",
       "|         16|               42|         1095.14|         70.02|          42|\n",
       "|         17|               63|         2550.92|         72.48|          63|\n",
       "|         18|               72|         2541.56|         72.81|          72|\n",
       "|         19|               40|         1289.31|          73.4|          40|\n",
       "+-----------+-----------------+----------------+--------------+------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "\n",
       "=== Monthly Engagement Trends ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------+-----------------+------------------+----------------+--------------+------------+\n",
       "|  month|total_engagements|monthly_watch_time|avg_session_time|avg_engagement|active_users|\n",
       "+-------+-----------------+------------------+----------------+--------------+------------+\n",
       "|2024-01|            25159|         827121.13|           32.88|         72.26|       10203|\n",
       "|2024-02|            23872|         772994.45|           32.38|         72.24|       10000|\n",
       "|2024-03|            25510|         827291.65|           32.43|         72.29|       10244|\n",
       "|2024-04|            24519|          798865.9|           32.58|         72.23|       10145|\n",
       "|2024-05|            25288|         829255.26|           32.79|         72.26|       10225|\n",
       "|2024-06|            24308|         794100.99|           32.67|         72.17|       10062|\n",
       "|2024-07|            25428|         832311.23|           32.73|         72.25|       10260|\n",
       "|2024-08|            25603|         833486.22|           32.55|         72.34|       10257|\n",
       "|2024-09|            24588|         808066.62|           32.86|         72.33|       10097|\n",
       "|2024-10|            25287|         820795.48|           32.46|         72.26|       10214|\n",
       "|2024-11|            24695|         804246.35|           32.57|         72.18|       10137|\n",
       "|2024-12|            25283|         829325.15|            32.8|         72.37|       10259|\n",
       "+-------+-----------------+------------------+----------------+--------------+------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze clustering effectiveness and media insights\n",
    "\n",
    "\n",
    "# User engagement analysis\n",
    "\n",
    "print(\"=== User Engagement Analysis ===\")\n",
    "\n",
    "user_engagement = spark.sql(\"\"\"\n",
    "\n",
    "SELECT user_id, COUNT(*) as total_sessions,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_session_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT content_type) as content_types_used\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "GROUP BY user_id\n",
    "\n",
    "ORDER BY total_watch_time DESC\n",
    "\n",
    "LIMIT 10\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "user_engagement.show()\n",
    "\n",
    "\n",
    "# Content type performance\n",
    "\n",
    "print(\"\\n=== Content Type Performance ===\")\n",
    "\n",
    "content_performance = spark.sql(\"\"\"\n",
    "\n",
    "SELECT content_type, COUNT(*) as total_engagements,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_watch_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as unique_users,\n",
    "\n",
    "       COUNT(DISTINCT content_id) as unique_content\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "GROUP BY content_type\n",
    "\n",
    "ORDER BY total_watch_time DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "content_performance.show()\n",
    "\n",
    "\n",
    "# Device usage analysis\n",
    "\n",
    "print(\"\\n=== Device Usage Analysis ===\")\n",
    "\n",
    "device_analysis = spark.sql(\"\"\"\n",
    "\n",
    "SELECT device_type, COUNT(*) as total_sessions,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_session_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as unique_users\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "GROUP BY device_type\n",
    "\n",
    "ORDER BY total_watch_time DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "device_analysis.show()\n",
    "\n",
    "\n",
    "# Hourly engagement patterns\n",
    "\n",
    "print(\"\\n=== Hourly Engagement Patterns ===\")\n",
    "\n",
    "hourly_patterns = spark.sql(\"\"\"\n",
    "\n",
    "SELECT HOUR(engagement_date) as hour_of_day, COUNT(*) as engagement_events,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as total_watch_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as active_users\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "WHERE DATE(engagement_date) = '2024-02-01'\n",
    "\n",
    "GROUP BY HOUR(engagement_date)\n",
    "\n",
    "ORDER BY hour_of_day\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "hourly_patterns.show()\n",
    "\n",
    "\n",
    "# Monthly engagement trends\n",
    "\n",
    "print(\"\\n=== Monthly Engagement Trends ===\")\n",
    "\n",
    "monthly_trends = spark.sql(\"\"\"\n",
    "\n",
    "SELECT DATE_FORMAT(engagement_date, 'yyyy-MM') as month,\n",
    "\n",
    "       COUNT(*) as total_engagements,\n",
    "\n",
    "       ROUND(SUM(watch_time), 2) as monthly_watch_time,\n",
    "\n",
    "       ROUND(AVG(watch_time), 2) as avg_session_time,\n",
    "\n",
    "       ROUND(AVG(engagement_score), 2) as avg_engagement,\n",
    "\n",
    "       COUNT(DISTINCT user_id) as active_users\n",
    "\n",
    "FROM media.analytics.content_engagement\n",
    "\n",
    "GROUP BY DATE_FORMAT(engagement_date, 'yyyy-MM')\n",
    "\n",
    "ORDER BY month\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "monthly_trends.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: Delta Liquid Clustering in AIDP\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Automatic Optimization**: Created a table with `CLUSTER BY (user_id, engagement_date)` and let Delta automatically optimize data layout\n",
    "\n",
    "2. **Performance Benefits**: Queries on clustered columns (user_id, engagement_date) are significantly faster due to data locality\n",
    "\n",
    "3. **Zero Maintenance**: No manual partitioning, bucketing, or Z-Ordering required - Delta handles it automatically\n",
    "\n",
    "4. **Real-World Use Case**: Media analytics where content engagement and user behavior analysis are critical\n",
    "\n",
    "### AIDP Advantages\n",
    "\n",
    "- **Unified Analytics**: Seamlessly integrates with other AIDP services\n",
    "- **Governance**: Catalog and schema isolation for media data\n",
    "- **Performance**: Optimized for both OLAP and OLTP workloads\n",
    "- **Scalability**: Handles media-scale data volumes effortlessly\n",
    "\n",
    "### Best Practices for Liquid Clustering\n",
    "\n",
    "1. **Choose clustering columns** based on your most common query patterns\n",
    "2. **Start with 1-4 columns** - too many can reduce effectiveness\n",
    "3. **Consider cardinality** - high-cardinality columns work best\n",
    "4. **Monitor and adjust** as query patterns evolve\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore other AIDP features like AI/ML integration\n",
    "- Try liquid clustering with different column combinations\n",
    "- Scale up to larger media datasets\n",
    "- Integrate with real content management and streaming platforms\n",
    "\n",
    "This notebook demonstrates how Oracle AI Data Platform makes advanced media analytics accessible while maintaining enterprise-grade performance and governance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
