{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cc9fe-f3d4-41a2-9294-40090d11d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oracle AI Data Platform v1.0\n",
    "\n",
    "Copyright Â© 2025, Oracle and/or its affiliates.\n",
    "\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec3db1-c1fc-43ba-a160-9ff0fc1ea0f6",
   "metadata": {
    "type": "python"
   },
   "source": [
    "### Sample Code: Read and Write Data from Hive\n",
    "\n",
    "AI Data Platform supports connectivity to Hive-based data sources, allowing you to read from and write to Hive tables directly using the `HIVE` connector type. Below is a sample code demonstrating how to connect to Hive, read from a source table, and write to a target table.\n",
    "\n",
    "Replace the placeholders such as `<username>`, `<password>`, `<schema>`, and `<table>` with your actual configuration details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e3826-768f-4c1d-832e-f4e89a6a53a5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-08T17:09:53.240Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Hive Sample code for READ\n",
    "hive_df = spark.read.format(\"aidataplatform\") \\\n",
    "    .option(\"type\", \"HIVE\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"authentication.method\", \"basic\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<table>\") \\\n",
    "    .load()\n",
    "\n",
    "hive_df.show()\n",
    "\n",
    "# Hive Sample code for WRITE\n",
    "hive_df.write.format(\"aidataplatform\") \\\n",
    "    .option(\"type\", \"HIVE\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"authentication.method\", \"basic\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<target_table>\") \\\n",
    "    .option(\"write.mode\", \"CREATE\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d14320-2765-4201-92d4-7ea44103761e",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "### Sample Code: Read and Write Data from Microsoft SQL Server (MSSQL)\n",
    "\n",
    "AI Data Platform supports reading from and writing to Microsoft SQL Server (MSSQL) using the `SQLSERVER` connector type. Below is a sample demonstrating how to read a table from MSSQL and write it back to a different table.\n",
    "\n",
    "Make sure to replace placeholders like `<host>`, `<port>`, `<username>`, `<password>`, `<schema>`, and `<table>` with your actual configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c233d02-dfdc-4b54-a5e0-dc3860f5293e",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# MSSQL - Read\n",
    "mssql_df = spark.read.format(\"aidataplatform\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"type\", \"SQLSERVER\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<table>\") \\\n",
    "    .load()\n",
    "\n",
    "mssql_df.show()\n",
    "\n",
    "# MSSQL - Write\n",
    "mssql_df.write.format(\"aidataplatform\") \\\n",
    "    .option(\"type\", \"SQLSERVER\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"database.name\", \"<database_name>\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<target_table>\") \\\n",
    "    .option(\"write.mode\", \"CREATE\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8329a9a-ea85-4301-948d-308eb3732105",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "### Sample Code: Read and Write Data from PostgreSQL\n",
    "\n",
    "AI Data Platform supports reading from and writing to PostgreSQL using the `POSTGRESQL` connector. Below is a sample demonstrating how to read data from a PostgreSQL source and write it to a different target table.\n",
    "\n",
    "Replace placeholders like `<host>`, `<port>`, `<username>`, `<password>`, `<schema>`, and `<table>` with your actual configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99f3bb-4cd1-4a9e-8dc9-f58edf943ff8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-08T17:13:47.110Z"
    },
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# POSTGRES - Read\n",
    "postgres_df = spark.read.format(\"aidataplatform\") \\\n",
    "    .option(\"type\", \"POSTGRESQL\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<table>\") \\\n",
    "    .load()\n",
    "\n",
    "postgres_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166408a2-afc5-41a2-9381-ef845d81e4e5",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# POSTGRES - Write\n",
    "postgres_df.write.format(\"aidataplatform\") \\\n",
    "    .option(\"type\", \"POSTGRESQL\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<target_table>\") \\\n",
    "    .option(\"write.mode\", \"CREATE\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed32d46-0b76-4964-9c3d-a2249451888a",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "### Sample Code: Read and Write Data from MySQL\n",
    "\n",
    "AI Data Platform supports integration with MySQL for both reading and writing data. You can configure the connection using options such as host, port, user credentials, schema, and table name.\n",
    "\n",
    "Replace placeholders like `<host>`, `<port>`, `<username>`, `<password>`, `<schema>`, and `<table>` with your actual values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067b9f6-782e-498c-9c29-d146838e2ca0",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# MySQL - Read\n",
    "mysql_df = spark.read.format(\"aidataplatform\") \\\n",
    "    .option(\"type\", \"MYSQL\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<table>\") \\\n",
    "    .load()\n",
    "\n",
    "mysql_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419c98c-1e91-4b60-adac-d5a4520de76b",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "mysql_df.write.format(\"aidataplatform\") \\\n",
    "    .option(\"type\", \"MYSQL\") \\\n",
    "    .option(\"host\", \"<host>\") \\\n",
    "    .option(\"port\", \"<port>\") \\\n",
    "    .option(\"user.name\", \"<username>\") \\\n",
    "    .option(\"password\", \"<password>\") \\\n",
    "    .option(\"schema\", \"<schema>\") \\\n",
    "    .option(\"table\", \"<target_table>\") \\\n",
    "    .option(\"write.mode\", \"CREATE\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed647967-509c-4365-a052-e11e0d4ea802",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "title": "Read Write External Ecosystem Connectors"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
