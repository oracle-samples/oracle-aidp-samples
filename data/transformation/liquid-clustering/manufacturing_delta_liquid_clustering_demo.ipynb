{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manufacturing: Delta Liquid Clustering Demo\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "This notebook demonstrates the power of **Delta Liquid Clustering** in Oracle AI Data Platform (AIDP) Workbench using a manufacturing analytics use case. Liquid clustering automatically optimizes data layout for query performance without requiring manual partitioning or Z-Ordering.\n",
    "\n",
    "### What is Liquid Clustering?\n",
    "\n",
    "Liquid clustering automatically identifies and groups similar data together based on clustering columns you define. This optimization happens automatically during data ingestion and maintenance operations, providing:\n",
    "\n",
    "- **Automatic optimization**: No manual tuning required\n",
    "- **Improved query performance**: Faster queries on clustered columns\n",
    "- **Reduced maintenance**: No need for manual repartitioning\n",
    "- **Adaptive clustering**: Adjusts as data patterns change\n",
    "\n",
    "### Use Case: Production Quality Control and Equipment Monitoring\n",
    "\n",
    "We'll analyze manufacturing production records from a factory. Our clustering strategy will optimize for:\n",
    "\n",
    "- **Equipment-specific queries**: Fast lookups by machine ID\n",
    "- **Time-based analysis**: Efficient filtering by production date\n",
    "- **Quality control patterns**: Quick aggregation by product type and defect rates\n",
    "\n",
    "### AIDP Environment Setup\n",
    "\n",
    "This notebook leverages the existing Spark session in your AIDP environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Manufacturing catalog and analytics schema created successfully!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create manufacturing catalog and analytics schema\n",
    "\n",
    "# In AIDP, catalogs provide data isolation and governance\n",
    "\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS manufacturing\")\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS manufacturing.analytics\")\n",
    "\n",
    "print(\"Manufacturing catalog and analytics schema created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Delta Table with Liquid Clustering\n",
    "\n",
    "### Table Design\n",
    "\n",
    "Our `production_records` table will store:\n",
    "\n",
    "- **machine_id**: Unique equipment identifier\n",
    "- **production_date**: Date and time of production\n",
    "- **product_type**: Type of product manufactured\n",
    "- **units_produced**: Number of units produced\n",
    "- **defect_count**: Number of defective units\n",
    "- **production_line**: Assembly line identifier\n",
    "- **cycle_time**: Time to produce one unit (minutes)\n",
    "\n",
    "### Clustering Strategy\n",
    "\n",
    "We'll cluster by `machine_id` and `production_date` because:\n",
    "\n",
    "- **machine_id**: Equipment often produces multiple batches, grouping maintenance and performance data together\n",
    "- **production_date**: Time-based queries are essential for shift analysis, maintenance scheduling, and quality trending\n",
    "- This combination optimizes for both equipment monitoring and temporal production analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delta table with liquid clustering created successfully!\n",
       "Clustering will automatically optimize data layout for queries on machine_id and production_date.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Delta table with liquid clustering\n",
    "\n",
    "# CLUSTER BY defines the columns for automatic optimization\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS manufacturing.analytics.production_records (\n",
    "\n",
    "    machine_id STRING,\n",
    "\n",
    "    production_date TIMESTAMP,\n",
    "\n",
    "    product_type STRING,\n",
    "\n",
    "    units_produced INT,\n",
    "\n",
    "    defect_count INT,\n",
    "\n",
    "    production_line STRING,\n",
    "\n",
    "    cycle_time DECIMAL(5,2)\n",
    "\n",
    ")\n",
    "\n",
    "USING DELTA\n",
    "\n",
    "CLUSTER BY (machine_id, production_date)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"Delta table with liquid clustering created successfully!\")\n",
    "\n",
    "print(\"Clustering will automatically optimize data layout for queries on machine_id and production_date.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Manufacturing Sample Data\n",
    "\n",
    "### Data Generation Strategy\n",
    "\n",
    "We'll create realistic manufacturing production data including:\n",
    "\n",
    "- **200 machines** with multiple production runs over time\n",
    "- **Product types**: Electronics, Automotive Parts, Consumer Goods, Industrial Equipment\n",
    "- **Realistic production patterns**: Shift-based operations, maintenance downtime, quality variations\n",
    "- **Multiple production lines**: Different assembly areas and facilities\n",
    "\n",
    "### Why This Data Pattern?\n",
    "\n",
    "This data simulates real manufacturing scenarios where:\n",
    "\n",
    "- Equipment performance varies over time\n",
    "- Quality control requires tracking defects and yields\n",
    "- Maintenance scheduling depends on usage patterns\n",
    "- Production optimization drives efficiency improvements\n",
    "- Supply chain visibility requires real-time production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generated 12176 production records\n",
       "Sample record: {'machine_id': 'MCH0001', 'production_date': datetime.datetime(2024, 10, 21, 6, 0), 'product_type': 'Automotive Parts', 'units_produced': 255, 'defect_count': 11, 'production_line': 'LINE_B', 'cycle_time': 10.48}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate sample manufacturing production data\n",
    "\n",
    "# Using fully qualified imports to avoid conflicts\n",
    "\n",
    "import random\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Define manufacturing data constants\n",
    "\n",
    "PRODUCT_TYPES = ['Electronics', 'Automotive Parts', 'Consumer Goods', 'Industrial Equipment']\n",
    "\n",
    "PRODUCTION_LINES = ['LINE_A', 'LINE_B', 'LINE_C', 'LINE_D', 'LINE_E']\n",
    "\n",
    "# Base production parameters by product type\n",
    "\n",
    "PRODUCTION_PARAMS = {\n",
    "\n",
    "    'Electronics': {'base_units': 500, 'defect_rate': 0.02, 'cycle_time': 2.5},\n",
    "\n",
    "    'Automotive Parts': {'base_units': 200, 'defect_rate': 0.05, 'cycle_time': 8.0},\n",
    "\n",
    "    'Consumer Goods': {'base_units': 800, 'defect_rate': 0.03, 'cycle_time': 1.8},\n",
    "\n",
    "    'Industrial Equipment': {'base_units': 50, 'defect_rate': 0.08, 'cycle_time': 25.0}\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Generate production records\n",
    "\n",
    "production_data = []\n",
    "\n",
    "base_date = datetime(2024, 1, 1)\n",
    "\n",
    "\n",
    "# Create 200 machines with 30-90 production runs each\n",
    "\n",
    "for machine_num in range(1, 201):\n",
    "\n",
    "    machine_id = f\"MCH{machine_num:04d}\"\n",
    "    \n",
    "    # Each machine gets 30-90 production runs over 12 months\n",
    "\n",
    "    num_runs = random.randint(30, 90)\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "\n",
    "        # Spread production runs over 12 months (weekdays only, during shifts)\n",
    "\n",
    "        days_offset = random.randint(0, 365)\n",
    "\n",
    "        production_date = base_date + timedelta(days=days_offset)\n",
    "        \n",
    "        # Skip weekends\n",
    "\n",
    "        while production_date.weekday() >= 5:\n",
    "\n",
    "            production_date += timedelta(days=1)\n",
    "        \n",
    "        # Add shift timing (6 AM - 6 PM)\n",
    "\n",
    "        hours_offset = random.randint(6, 18)\n",
    "\n",
    "        production_date = production_date.replace(hour=hours_offset, minute=0, second=0, microsecond=0)\n",
    "        \n",
    "        # Select product type\n",
    "\n",
    "        product_type = random.choice(PRODUCT_TYPES)\n",
    "\n",
    "        params = PRODUCTION_PARAMS[product_type]\n",
    "        \n",
    "        # Calculate production with variability\n",
    "\n",
    "        units_variation = random.uniform(0.7, 1.3)\n",
    "\n",
    "        units_produced = int(params['base_units'] * units_variation)\n",
    "        \n",
    "        # Calculate defects\n",
    "\n",
    "        defect_rate_variation = random.uniform(0.5, 2.0)\n",
    "\n",
    "        actual_defect_rate = params['defect_rate'] * defect_rate_variation\n",
    "\n",
    "        defect_count = int(units_produced * actual_defect_rate)\n",
    "        \n",
    "        # Calculate cycle time with variation\n",
    "\n",
    "        cycle_time_variation = random.uniform(0.8, 1.4)\n",
    "\n",
    "        cycle_time = round(params['cycle_time'] * cycle_time_variation, 2)\n",
    "        \n",
    "        # Select production line\n",
    "\n",
    "        production_line = random.choice(PRODUCTION_LINES)\n",
    "        \n",
    "        production_data.append({\n",
    "\n",
    "            \"machine_id\": machine_id,\n",
    "\n",
    "            \"production_date\": production_date,\n",
    "\n",
    "            \"product_type\": product_type,\n",
    "\n",
    "            \"units_produced\": units_produced,\n",
    "\n",
    "            \"defect_count\": defect_count,\n",
    "\n",
    "            \"production_line\": production_line,\n",
    "\n",
    "            \"cycle_time\": cycle_time\n",
    "\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Generated {len(production_data)} production records\")\n",
    "\n",
    "print(\"Sample record:\", production_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Insert Data Using PySpark\n",
    "\n",
    "### Data Insertion Strategy\n",
    "\n",
    "We'll use PySpark to:\n",
    "\n",
    "1. **Create DataFrame** from our generated data\n",
    "2. **Insert into Delta table** with liquid clustering\n",
    "3. **Verify the insertion** with a sample query\n",
    "\n",
    "### Why PySpark for Insertion?\n",
    "\n",
    "- **Distributed processing**: Handles large datasets efficiently\n",
    "- **Type safety**: Ensures data integrity\n",
    "- **Optimization**: Leverages Spark's query optimization\n",
    "- **Liquid clustering**: Automatically applies clustering during insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame Schema:\n",
       "root\n",
       " |-- cycle_time: double (nullable = true)\n",
       " |-- defect_count: long (nullable = true)\n",
       " |-- machine_id: string (nullable = true)\n",
       " |-- product_type: string (nullable = true)\n",
       " |-- production_date: timestamp (nullable = true)\n",
       " |-- production_line: string (nullable = true)\n",
       " |-- units_produced: long (nullable = true)\n",
       "\n",
       "\n",
       "Sample Data:\n",
       "+----------+------------+----------+--------------------+-------------------+---------------+--------------+\n",
       "|cycle_time|defect_count|machine_id|        product_type|    production_date|production_line|units_produced|\n",
       "+----------+------------+----------+--------------------+-------------------+---------------+--------------+\n",
       "|     10.48|          11|   MCH0001|    Automotive Parts|2024-10-21 06:00:00|         LINE_B|           255|\n",
       "|     28.18|           3|   MCH0001|Industrial Equipment|2024-04-29 09:00:00|         LINE_A|            43|\n",
       "|     11.19|           7|   MCH0001|    Automotive Parts|2024-04-15 06:00:00|         LINE_C|           171|\n",
       "|     27.26|           7|   MCH0001|Industrial Equipment|2024-01-23 14:00:00|         LINE_D|            54|\n",
       "|      2.02|          18|   MCH0001|      Consumer Goods|2024-04-18 07:00:00|         LINE_C|           589|\n",
       "+----------+------------+----------+--------------------+-------------------+---------------+--------------+\n",
       "only showing top 5 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Successfully inserted 12176 records into manufacturing.analytics.production_records\n",
       "Liquid clustering automatically optimized the data layout during insertion!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert data using PySpark DataFrame operations\n",
    "\n",
    "# Using fully qualified function references to avoid conflicts\n",
    "\n",
    "\n",
    "# Create DataFrame from generated data\n",
    "\n",
    "df_production = spark.createDataFrame(production_data)\n",
    "\n",
    "\n",
    "# Display schema and sample data\n",
    "\n",
    "print(\"DataFrame Schema:\")\n",
    "\n",
    "df_production.printSchema()\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSample Data:\")\n",
    "\n",
    "df_production.show(5)\n",
    "\n",
    "\n",
    "# Insert data into Delta table with liquid clustering\n",
    "\n",
    "# The CLUSTER BY (machine_id, production_date) will automatically optimize the data layout\n",
    "\n",
    "df_production.write.mode(\"overwrite\").saveAsTable(\"manufacturing.analytics.production_records\")\n",
    "\n",
    "\n",
    "print(f\"\\nSuccessfully inserted {df_production.count()} records into manufacturing.analytics.production_records\")\n",
    "\n",
    "print(\"Liquid clustering automatically optimized the data layout during insertion!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate Liquid Clustering Benefits\n",
    "\n",
    "### Query Performance Analysis\n",
    "\n",
    "Now let's see how liquid clustering improves query performance. We'll run queries that benefit from our clustering strategy:\n",
    "\n",
    "1. **Machine performance history** (clustered by machine_id)\n",
    "2. **Time-based production analysis** (clustered by production_date)\n",
    "3. **Combined machine + time queries** (optimal for our clustering)\n",
    "\n",
    "### Expected Performance Benefits\n",
    "\n",
    "With liquid clustering, these queries should be significantly faster because:\n",
    "\n",
    "- **Data locality**: Related records are physically grouped together\n",
    "- **Reduced I/O**: Less data needs to be read from disk\n",
    "- **Automatic optimization**: No manual tuning required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Query 1: Machine Performance History ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+--------------------+--------------+------------+-------------------+\n",
       "|machine_id|    production_date|        product_type|units_produced|defect_count|defect_rate_percent|\n",
       "+----------+-------------------+--------------------+--------------+------------+-------------------+\n",
       "|   MCH0001|2024-12-16 08:00:00|Industrial Equipment|            64|           3|               4.69|\n",
       "|   MCH0001|2024-12-09 10:00:00|      Consumer Goods|           790|          27|               3.42|\n",
       "|   MCH0001|2024-12-09 08:00:00|         Electronics|           359|           8|               2.23|\n",
       "|   MCH0001|2024-12-09 07:00:00|      Consumer Goods|           982|          55|               5.60|\n",
       "|   MCH0001|2024-12-05 16:00:00|      Consumer Goods|          1030|          40|               3.88|\n",
       "|   MCH0001|2024-12-04 13:00:00|Industrial Equipment|            60|           8|              13.33|\n",
       "|   MCH0001|2024-12-02 13:00:00|      Consumer Goods|           613|          28|               4.57|\n",
       "|   MCH0001|2024-11-25 14:00:00|      Consumer Goods|           613|          35|               5.71|\n",
       "|   MCH0001|2024-11-25 06:00:00|      Consumer Goods|           661|          16|               2.42|\n",
       "|   MCH0001|2024-11-05 07:00:00|      Consumer Goods|           584|          15|               2.57|\n",
       "|   MCH0001|2024-10-28 10:00:00|      Consumer Goods|          1038|          60|               5.78|\n",
       "|   MCH0001|2024-10-21 06:00:00|    Automotive Parts|           255|          11|               4.31|\n",
       "|   MCH0001|2024-10-04 18:00:00|    Automotive Parts|           156|          13|               8.33|\n",
       "|   MCH0001|2024-10-02 18:00:00|    Automotive Parts|           206|          19|               9.22|\n",
       "|   MCH0001|2024-10-01 13:00:00|         Electronics|           454|          12|               2.64|\n",
       "|   MCH0001|2024-10-01 07:00:00|      Consumer Goods|           955|          23|               2.41|\n",
       "|   MCH0001|2024-09-20 13:00:00|    Automotive Parts|           205|          18|               8.78|\n",
       "|   MCH0001|2024-09-20 10:00:00|Industrial Equipment|            39|           6|              15.38|\n",
       "|   MCH0001|2024-09-10 18:00:00|         Electronics|           423|           7|               1.65|\n",
       "|   MCH0001|2024-09-04 18:00:00|    Automotive Parts|           197|          12|               6.09|\n",
       "+----------+-------------------+--------------------+--------------+------------+-------------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Records found: 69\n",
       "\n",
       "=== Query 2: Recent Quality Issues ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------------------+----------+--------------------+--------------+------------+-------------------+\n",
       "|    production_date|machine_id|        product_type|units_produced|defect_count|defect_rate_percent|\n",
       "+-------------------+----------+--------------------+--------------+------------+-------------------+\n",
       "|2024-10-29 09:00:00|   MCH0006|Industrial Equipment|            44|           7|              15.91|\n",
       "|2024-08-01 13:00:00|   MCH0055|Industrial Equipment|            44|           7|              15.91|\n",
       "|2024-11-27 08:00:00|   MCH0175|Industrial Equipment|            57|           9|              15.79|\n",
       "|2024-08-30 11:00:00|   MCH0141|Industrial Equipment|            51|           8|              15.69|\n",
       "|2024-06-21 10:00:00|   MCH0113|Industrial Equipment|            51|           8|              15.69|\n",
       "|2024-12-23 10:00:00|   MCH0157|Industrial Equipment|            64|          10|              15.63|\n",
       "|2024-12-09 09:00:00|   MCH0107|Industrial Equipment|            64|          10|              15.63|\n",
       "|2024-07-29 17:00:00|   MCH0162|Industrial Equipment|            64|          10|              15.63|\n",
       "|2024-06-25 14:00:00|   MCH0064|Industrial Equipment|            64|          10|              15.63|\n",
       "|2024-06-17 18:00:00|   MCH0027|Industrial Equipment|            64|          10|              15.63|\n",
       "|2024-06-27 14:00:00|   MCH0154|Industrial Equipment|            45|           7|              15.56|\n",
       "|2024-12-03 12:00:00|   MCH0182|Industrial Equipment|            58|           9|              15.52|\n",
       "|2024-09-17 17:00:00|   MCH0178|Industrial Equipment|            58|           9|              15.52|\n",
       "|2024-12-20 07:00:00|   MCH0079|Industrial Equipment|            52|           8|              15.38|\n",
       "|2024-09-23 09:00:00|   MCH0083|Industrial Equipment|            39|           6|              15.38|\n",
       "|2024-09-20 10:00:00|   MCH0001|Industrial Equipment|            39|           6|              15.38|\n",
       "|2024-09-10 08:00:00|   MCH0076|Industrial Equipment|            39|           6|              15.38|\n",
       "|2024-08-12 13:00:00|   MCH0053|Industrial Equipment|            39|           6|              15.38|\n",
       "|2024-08-02 15:00:00|   MCH0165|Industrial Equipment|            52|           8|              15.38|\n",
       "|2024-10-22 10:00:00|   MCH0173|Industrial Equipment|            59|           9|              15.25|\n",
       "+-------------------+----------+--------------------+--------------+------------+-------------------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Quality issues found: 3027\n",
       "\n",
       "=== Query 3: Equipment Performance Trends ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+--------------------+--------------+----------+-----------+\n",
       "|machine_id|    production_date|        product_type|units_produced|cycle_time|hourly_rate|\n",
       "+----------+-------------------+--------------------+--------------+----------+-----------+\n",
       "|   MCH0001|2024-04-01 11:00:00|      Consumer Goods|           758|      1.71|   26596.49|\n",
       "|   MCH0001|2024-04-01 15:00:00|      Consumer Goods|           887|      1.67|   31868.26|\n",
       "|   MCH0001|2024-04-03 11:00:00|         Electronics|           523|      3.41|    9202.35|\n",
       "|   MCH0001|2024-04-12 07:00:00|Industrial Equipment|            42|      27.1|      92.99|\n",
       "|   MCH0001|2024-04-15 06:00:00|    Automotive Parts|           171|     11.19|     916.89|\n",
       "|   MCH0001|2024-04-18 07:00:00|      Consumer Goods|           589|      2.02|   17495.05|\n",
       "|   MCH0001|2024-04-22 13:00:00|    Automotive Parts|           179|      7.85|    1368.15|\n",
       "|   MCH0001|2024-04-29 09:00:00|Industrial Equipment|            43|     28.18|      91.55|\n",
       "|   MCH0001|2024-04-29 15:00:00|Industrial Equipment|            53|     23.57|     134.92|\n",
       "|   MCH0001|2024-05-01 14:00:00|      Consumer Goods|           677|      2.42|   16785.12|\n",
       "|   MCH0001|2024-05-02 17:00:00|         Electronics|           449|      2.84|    9485.92|\n",
       "|   MCH0001|2024-05-02 17:00:00|      Consumer Goods|           882|      2.27|   23312.78|\n",
       "|   MCH0001|2024-05-03 09:00:00|         Electronics|           359|      2.26|    9530.97|\n",
       "|   MCH0001|2024-05-07 09:00:00|Industrial Equipment|            46|     30.04|      91.88|\n",
       "|   MCH0001|2024-05-14 06:00:00|Industrial Equipment|            44|     26.21|     100.72|\n",
       "|   MCH0001|2024-05-16 17:00:00|         Electronics|           586|      2.07|   16985.51|\n",
       "|   MCH0001|2024-05-20 06:00:00|         Electronics|           438|      3.25|    8086.15|\n",
       "|   MCH0001|2024-05-21 16:00:00|      Consumer Goods|           934|      2.16|   25944.44|\n",
       "|   MCH0001|2024-05-27 18:00:00|Industrial Equipment|            47|     29.45|      95.76|\n",
       "|   MCH0001|2024-06-03 08:00:00|         Electronics|           472|      2.79|   10150.54|\n",
       "+----------+-------------------+--------------------+--------------+----------+-----------+\n",
       "only showing top 20 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Performance records found: 441\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demonstrate liquid clustering benefits with optimized queries\n",
    "\n",
    "\n",
    "# Query 1: Machine performance history - benefits from machine_id clustering\n",
    "\n",
    "print(\"=== Query 1: Machine Performance History ===\")\n",
    "\n",
    "machine_history = spark.sql(\"\"\"\n",
    "\n",
    "SELECT machine_id, production_date, product_type, units_produced, defect_count,\n",
    "\n",
    "       ROUND(defect_count * 100.0 / units_produced, 2) as defect_rate_percent\n",
    "\n",
    "FROM manufacturing.analytics.production_records\n",
    "\n",
    "WHERE machine_id = 'MCH0001'\n",
    "\n",
    "ORDER BY production_date DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "machine_history.show()\n",
    "\n",
    "print(f\"Records found: {machine_history.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 2: Time-based quality analysis - benefits from production_date clustering\n",
    "\n",
    "print(\"\\n=== Query 2: Recent Quality Issues ===\")\n",
    "\n",
    "quality_issues = spark.sql(\"\"\"\n",
    "\n",
    "SELECT production_date, machine_id, product_type, units_produced, defect_count,\n",
    "\n",
    "       ROUND(defect_count * 100.0 / units_produced, 2) as defect_rate_percent\n",
    "\n",
    "FROM manufacturing.analytics.production_records\n",
    "\n",
    "WHERE production_date >= '2024-06-01' AND (defect_count * 100.0 / units_produced) > 5.0\n",
    "\n",
    "ORDER BY defect_rate_percent DESC, production_date DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "quality_issues.show()\n",
    "\n",
    "print(f\"Quality issues found: {quality_issues.count()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Query 3: Combined machine + time query - optimal for our clustering strategy\n",
    "\n",
    "print(\"\\n=== Query 3: Equipment Performance Trends ===\")\n",
    "\n",
    "performance_trends = spark.sql(\"\"\"\n",
    "\n",
    "SELECT machine_id, production_date, product_type, units_produced, cycle_time,\n",
    "\n",
    "       ROUND(units_produced * 60.0 / cycle_time, 2) as hourly_rate\n",
    "\n",
    "FROM manufacturing.analytics.production_records\n",
    "\n",
    "WHERE machine_id LIKE 'MCH000%' AND production_date >= '2024-04-01'\n",
    "\n",
    "ORDER BY machine_id, production_date\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "performance_trends.show()\n",
    "\n",
    "print(f\"Performance records found: {performance_trends.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Analyze Clustering Effectiveness\n",
    "\n",
    "### Understanding the Impact\n",
    "\n",
    "Let's examine how liquid clustering has organized our data and analyze some aggregate statistics to demonstrate the manufacturing insights possible with this optimized structure.\n",
    "\n",
    "### Key Analytics\n",
    "\n",
    "- **Equipment utilization** and performance metrics\n",
    "- **Quality control analysis** and defect patterns\n",
    "- **Production line efficiency** and bottleneck identification\n",
    "- **Product type performance** and optimization opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Equipment Performance Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+----------+------------------+---------------+--------------+-----------+\n",
       "|machine_id|total_runs|avg_units_produced|avg_defect_rate|avg_cycle_time|total_units|\n",
       "+----------+----------+------------------+---------------+--------------+-----------+\n",
       "|   MCH0075|        90|            457.58|           5.17|           8.4|      41182|\n",
       "|   MCH0021|        89|            437.87|           4.97|           9.6|      38970|\n",
       "|   MCH0165|        87|            447.21|           5.52|          8.89|      38907|\n",
       "|   MCH0092|        88|            440.33|           4.91|          9.29|      38749|\n",
       "|   MCH0070|        88|            426.16|           4.89|          9.45|      37502|\n",
       "|   MCH0161|        86|             427.2|           5.23|          8.58|      36739|\n",
       "|   MCH0023|        80|            456.73|           5.13|         10.48|      36538|\n",
       "|   MCH0143|        90|            400.39|           5.03|          9.79|      36035|\n",
       "|   MCH0175|        85|            418.02|           4.89|          7.87|      35532|\n",
       "|   MCH0071|        84|            422.68|           5.73|         10.47|      35505|\n",
       "|   MCH0078|        84|            421.49|           4.68|          8.71|      35405|\n",
       "|   MCH0167|        80|            438.34|           5.17|          9.41|      35067|\n",
       "|   MCH0153|        90|            386.58|           5.10|         10.48|      34792|\n",
       "|   MCH0152|        88|            391.89|           5.43|         10.84|      34486|\n",
       "|   MCH0026|        89|            387.17|           4.68|          9.22|      34458|\n",
       "|   MCH0014|        77|            445.75|           5.17|          9.21|      34323|\n",
       "|   MCH0158|        78|             437.1|           4.27|          7.83|      34094|\n",
       "|   MCH0037|        85|            399.69|           5.40|          9.94|      33974|\n",
       "|   MCH0125|        90|            377.14|           5.77|         11.69|      33943|\n",
       "|   MCH0146|        81|            413.89|           4.64|          9.75|      33525|\n",
       "+----------+----------+------------------+---------------+--------------+-----------+\n",
       "only showing top 20 rows\n",
       "\n",
       "\n",
       "=== Quality Analysis by Product Type ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+--------------------+---------------+-----------+-------------+---------------+--------------+\n",
       "|        product_type|production_runs|total_units|total_defects|avg_defect_rate|avg_cycle_time|\n",
       "+--------------------+---------------+-----------+-------------+---------------+--------------+\n",
       "|      Consumer Goods|           2998|    2404126|        89016|           3.70|          1.98|\n",
       "|         Electronics|           3059|    1532323|        36643|           2.39|          2.74|\n",
       "|    Automotive Parts|           3044|     606508|        36631|           6.02|          8.78|\n",
       "|Industrial Equipment|           3075|     152655|        13638|           8.92|         27.44|\n",
       "+--------------------+---------------+-----------+-------------+---------------+--------------+\n",
       "\n",
       "\n",
       "=== Production Line Efficiency ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+---------------+----------+-------------+----------------+------------+---------------+\n",
       "|production_line|total_runs|machines_used|total_production|avg_run_size|avg_defect_rate|\n",
       "+---------------+----------+-------------+----------------+------------+---------------+\n",
       "|         LINE_B|      2482|          200|          963641|      388.25|           5.37|\n",
       "|         LINE_D|      2442|          200|          938669|      384.39|           5.29|\n",
       "|         LINE_E|      2423|          200|          933097|       385.1|           5.23|\n",
       "|         LINE_C|      2429|          200|          933026|      384.12|           5.22|\n",
       "|         LINE_A|      2400|          200|          927179|      386.32|           5.23|\n",
       "+---------------+----------+-------------+----------------+------------+---------------+\n",
       "\n",
       "\n",
       "=== Monthly Production Trends ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-------+---------------+-----------+---------------+---------------+\n",
       "|  month|production_runs|total_units|avg_defect_rate|active_machines|\n",
       "+-------+---------------+-----------+---------------+---------------+\n",
       "|2024-01|           1072|     421855|           5.21|            197|\n",
       "|2024-02|            910|     352351|           5.19|            196|\n",
       "|2024-03|            972|     383983|           5.12|            196|\n",
       "|2024-04|           1058|     413469|           5.24|            197|\n",
       "|2024-05|           1017|     382081|           5.42|            195|\n",
       "|2024-06|            873|     343832|           5.22|            195|\n",
       "|2024-07|           1072|     397166|           5.45|            199|\n",
       "|2024-08|           1020|     385670|           5.14|            196|\n",
       "|2024-09|           1082|     418096|           5.29|            194|\n",
       "|2024-10|           1029|     390922|           5.40|            195|\n",
       "|2024-11|            977|     386337|           5.18|            196|\n",
       "|2024-12|           1094|     419850|           5.34|            200|\n",
       "+-------+---------------+-----------+---------------+---------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze clustering effectiveness and manufacturing insights\n",
    "\n",
    "\n",
    "# Equipment performance analysis\n",
    "\n",
    "print(\"=== Equipment Performance Analysis ===\")\n",
    "\n",
    "equipment_performance = spark.sql(\"\"\"\n",
    "\n",
    "SELECT machine_id, COUNT(*) as total_runs,\n",
    "\n",
    "       ROUND(AVG(units_produced), 2) as avg_units_produced,\n",
    "\n",
    "       ROUND(AVG(defect_count * 100.0 / units_produced), 2) as avg_defect_rate,\n",
    "\n",
    "       ROUND(AVG(cycle_time), 2) as avg_cycle_time,\n",
    "\n",
    "       ROUND(SUM(units_produced), 0) as total_units\n",
    "\n",
    "FROM manufacturing.analytics.production_records\n",
    "\n",
    "GROUP BY machine_id\n",
    "\n",
    "ORDER BY total_units DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "equipment_performance.show()\n",
    "\n",
    "\n",
    "# Quality analysis by product type\n",
    "\n",
    "print(\"\\n=== Quality Analysis by Product Type ===\")\n",
    "\n",
    "quality_by_product = spark.sql(\"\"\"\n",
    "\n",
    "SELECT product_type, COUNT(*) as production_runs,\n",
    "\n",
    "       ROUND(SUM(units_produced), 0) as total_units,\n",
    "\n",
    "       ROUND(SUM(defect_count), 0) as total_defects,\n",
    "\n",
    "       ROUND(AVG(defect_count * 100.0 / units_produced), 2) as avg_defect_rate,\n",
    "\n",
    "       ROUND(AVG(cycle_time), 2) as avg_cycle_time\n",
    "\n",
    "FROM manufacturing.analytics.production_records\n",
    "\n",
    "GROUP BY product_type\n",
    "\n",
    "ORDER BY total_units DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "quality_by_product.show()\n",
    "\n",
    "\n",
    "# Production line efficiency\n",
    "\n",
    "print(\"\\n=== Production Line Efficiency ===\")\n",
    "\n",
    "line_efficiency = spark.sql(\"\"\"\n",
    "\n",
    "SELECT production_line, COUNT(*) as total_runs,\n",
    "\n",
    "       COUNT(DISTINCT machine_id) as machines_used,\n",
    "\n",
    "       ROUND(SUM(units_produced), 0) as total_production,\n",
    "\n",
    "       ROUND(AVG(units_produced), 2) as avg_run_size,\n",
    "\n",
    "       ROUND(SUM(defect_count * 100.0 / units_produced) / COUNT(*), 2) as avg_defect_rate\n",
    "\n",
    "FROM manufacturing.analytics.production_records\n",
    "\n",
    "GROUP BY production_line\n",
    "\n",
    "ORDER BY total_production DESC\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "line_efficiency.show()\n",
    "\n",
    "\n",
    "# Monthly production trends\n",
    "\n",
    "print(\"\\n=== Monthly Production Trends ===\")\n",
    "\n",
    "monthly_trends = spark.sql(\"\"\"\n",
    "\n",
    "SELECT DATE_FORMAT(production_date, 'yyyy-MM') as month,\n",
    "\n",
    "       COUNT(*) as production_runs,\n",
    "\n",
    "       ROUND(SUM(units_produced), 0) as total_units,\n",
    "\n",
    "       ROUND(AVG(defect_count * 100.0 / units_produced), 2) as avg_defect_rate,\n",
    "\n",
    "       COUNT(DISTINCT machine_id) as active_machines\n",
    "\n",
    "FROM manufacturing.analytics.production_records\n",
    "\n",
    "GROUP BY DATE_FORMAT(production_date, 'yyyy-MM')\n",
    "\n",
    "ORDER BY month\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "monthly_trends.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Predictive Maintenance Model\n",
    "\n",
    "### Business Value of Predictive Maintenance in Manufacturing\n",
    "\n",
    "Predictive maintenance is critical for manufacturers to:\n",
    "\n",
    "- **Reduce downtime**: Prevent unplanned equipment failures and production stoppages\n",
    "- **Optimize maintenance costs**: Schedule maintenance based on actual equipment condition rather than fixed intervals\n",
    "- **Improve asset utilization**: Maximize equipment uptime and production efficiency\n",
    "- **Enhance quality control**: Identify equipment issues before they affect product quality\n",
    "- **Extend equipment lifespan**: Reduce wear and tear through timely interventions\n",
    "\n",
    "### Model Overview\n",
    "\n",
    "We'll build a machine learning model to predict equipment failure risk based on production performance metrics. The model will classify machines as:\n",
    "\n",
    "- **Low Risk**: Normal operation, continue monitoring\n",
    "- **Medium Risk**: Watch closely, schedule maintenance soon\n",
    "- **High Risk**: Immediate attention required\n",
    "\n",
    "### ML Pipeline Strategy\n",
    "\n",
    "1. **Feature Engineering**: Extract equipment health indicators from production data\n",
    "2. **Risk Classification**: Build a classifier to predict maintenance risk levels\n",
    "3. **Model Evaluation**: Assess prediction accuracy and business impact\n",
    "4. **Maintenance Insights**: Demonstrate proactive maintenance scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Feature Engineering for Predictive Maintenance ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset prepared with 12176 records for maintenance prediction\n",
       "Risk distribution:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------------+-----+\n",
       "|maintenance_risk|count|\n",
       "+----------------+-----+\n",
       "|            High|   34|\n",
       "|             Low|  140|\n",
       "|          Medium|12002|\n",
       "+----------------+-----+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Engineering for Predictive Maintenance\n",
    "\n",
    "from pyspark.sql.functions import col, lag, avg, stddev, count, window\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "print(\"=== Feature Engineering for Predictive Maintenance ===\")\n",
    "\n",
    "# Calculate equipment health indicators\n",
    "df_health = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    machine_id,\n",
    "    production_date,\n",
    "    product_type,\n",
    "    production_line,\n",
    "    units_produced,\n",
    "    defect_count,\n",
    "    cycle_time,\n",
    "    CASE WHEN units_produced > 0 THEN defect_count * 100.0 / units_produced ELSE 0 END as defect_rate,\n",
    "    CASE WHEN cycle_time > 0 THEN units_produced * 60.0 / cycle_time ELSE 0 END as hourly_rate\n",
    "FROM manufacturing.analytics.production_records\n",
    "ORDER BY machine_id, production_date\n",
    "\"\"\")\n",
    "\n",
    "# Add rolling statistics (7-day windows)\n",
    "window_spec_7d = Window.partitionBy(\"machine_id\").orderBy(\"production_date\").rowsBetween(-7, 0)\n",
    "\n",
    "df_health = df_health.withColumn(\"rolling_avg_defect_rate\", avg(\"defect_rate\").over(window_spec_7d)) \\\n",
    "                    .withColumn(\"rolling_std_defect_rate\", stddev(\"defect_rate\").over(window_spec_7d)) \\\n",
    "                    .withColumn(\"rolling_avg_hourly_rate\", avg(\"hourly_rate\").over(window_spec_7d)) \\\n",
    "                    .withColumn(\"rolling_std_hourly_rate\", stddev(\"hourly_rate\").over(window_spec_7d)) \\\n",
    "                    .withColumn(\"production_count_7d\", count(\"*\").over(window_spec_7d))\n",
    "\n",
    "# Create maintenance risk labels based on health indicators\n",
    "from pyspark.sql.functions import when\n",
    "df_health = df_health.withColumn(\"maintenance_risk\", \n",
    "    when((col(\"rolling_avg_defect_rate\") > 8.0) & (col(\"rolling_std_defect_rate\") > 3.0) & \n",
    "         (col(\"rolling_avg_hourly_rate\") < 1000), \"High\")\n",
    "    .when((col(\"rolling_avg_defect_rate\") > 5.0) | (col(\"rolling_std_hourly_rate\") > 2000), \"Medium\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "print(f\"Dataset prepared with {df_health.count()} records for maintenance prediction\")\n",
    "print(\"Risk distribution:\")\n",
    "df_health.groupBy(\"maintenance_risk\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Data Preparation for ML ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training set: 8355 records\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Testing set: 3421 records\n",
       "ML pipeline configured for maintenance risk classification\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data for ML training\n",
    "\n",
    "print(\"\\n=== Data Preparation for ML ===\")\n",
    "\n",
    "# Filter out records with insufficient history\n",
    "df_ml = df_health.filter(\"production_count_7d >= 3\")\n",
    "\n",
    "# Split data (70/30 split)\n",
    "train_data, test_data = df_ml.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(f\"Training set: {train_data.count()} records\")\n",
    "print(f\"Testing set: {test_data.count()} records\")\n",
    "\n",
    "# Encode categorical features\n",
    "product_indexer = StringIndexer(inputCol=\"product_type\", outputCol=\"product_type_index\")\n",
    "line_indexer = StringIndexer(inputCol=\"production_line\", outputCol=\"production_line_index\")\n",
    "risk_indexer = StringIndexer(inputCol=\"maintenance_risk\", outputCol=\"label\")\n",
    "\n",
    "product_encoder = OneHotEncoder(inputCol=\"product_type_index\", outputCol=\"product_type_vec\")\n",
    "line_encoder = OneHotEncoder(inputCol=\"production_line_index\", outputCol=\"production_line_vec\")\n",
    "\n",
    "# Assemble feature vector\n",
    "feature_cols = [\n",
    "    \"defect_rate\", \"hourly_rate\", \"rolling_avg_defect_rate\", \"rolling_std_defect_rate\",\n",
    "    \"rolling_avg_hourly_rate\", \"rolling_std_hourly_rate\", \"production_count_7d\",\n",
    "    \"product_type_vec\", \"production_line_vec\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Define Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    numTrees=100,\n",
    "    maxDepth=8,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create ML pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    product_indexer, line_indexer, risk_indexer,\n",
    "    product_encoder, line_encoder,\n",
    "    assembler, rf\n",
    "])\n",
    "\n",
    "print(\"ML pipeline configured for maintenance risk classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Model Training ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Maintenance prediction model training completed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Predictions generated for 3421 test records\n",
       "Sample predictions:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+----------------+----------+\n",
       "|machine_id|    production_date|maintenance_risk|prediction|\n",
       "+----------+-------------------+----------------+----------+\n",
       "|   MCH0001|2024-01-23 18:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-02-21 07:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-03-04 12:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-03-07 07:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-03-14 13:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-03-14 18:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-03-19 15:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-04-01 11:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-04-03 11:00:00|          Medium|       0.0|\n",
       "|   MCH0001|2024-04-15 06:00:00|          Medium|       0.0|\n",
       "+----------+-------------------+----------------+----------+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "print(\"\\n=== Model Training ===\")\n",
    "\n",
    "# Fit the pipeline on training data\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "print(\"Maintenance prediction model training completed\")\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "print(f\"Predictions generated for {predictions.count()} test records\")\n",
    "print(\"Sample predictions:\")\n",
    "predictions.select(\"machine_id\", \"production_date\", \"maintenance_risk\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Model Evaluation ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 0.9985\n",
       "F1 Score: 0.9980\n",
       "\n",
       "Confusion Matrix:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------------+----------+-----+\n",
       "|maintenance_risk|prediction|count|\n",
       "+----------------+----------+-----+\n",
       "|            High|       0.0|    4|\n",
       "|            High|       1.0|    1|\n",
       "|             Low|       0.0|    1|\n",
       "|          Medium|       0.0| 3415|\n",
       "+----------------+----------+-----+\n",
       "\n",
       "\n",
       "=== Business Value Assessment ===\n",
       "Model accuracy of 99.9% enables:\n",
       "- Proactive maintenance scheduling\n",
       "- Reduced unplanned downtime\n",
       "- Optimized maintenance costs\n",
       "- Improved production reliability\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate model performance\n",
    "\n",
    "print(\"\\n=== Model Evaluation ===\")\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "f1 = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Show confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "predictions.groupBy(\"maintenance_risk\", \"prediction\").count().orderBy(\"maintenance_risk\", \"prediction\").show()\n",
    "\n",
    "# Business value assessment\n",
    "print(\"\\n=== Business Value Assessment ===\")\n",
    "print(f\"Model accuracy of {accuracy:.1%} enables:\")\n",
    "print(f\"- Proactive maintenance scheduling\")\n",
    "print(f\"- Reduced unplanned downtime\")\n",
    "print(f\"- Optimized maintenance costs\")\n",
    "print(f\"- Improved production reliability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Maintenance Insights ===\n",
       "Top 10 high-risk machines requiring immediate attention:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+-------------------+-----------------------+-----------------------+\n",
       "|machine_id|    production_date|rolling_avg_defect_rate|rolling_avg_hourly_rate|\n",
       "+----------+-------------------+-----------------------+-----------------------+\n",
       "|   MCH0155|2024-02-02 06:00:00|   11.04108309990662...|     134.01581722567553|\n",
       "|   MCH0198|2024-02-06 11:00:00|   10.98675710594315...|      651.0827753122406|\n",
       "|   MCH0115|2024-01-17 09:00:00|   10.88383838383838...|      117.7089552037474|\n",
       "|   MCH0180|2024-10-25 08:00:00|   10.66130444410588...|      388.3798951998131|\n",
       "|   MCH0180|2024-12-12 11:00:00|   9.761636541894456250|      7730.490649465822|\n",
       "|   MCH0180|2024-11-12 15:00:00|   9.687191127764070000|     4466.6515877255615|\n",
       "|   MCH0180|2024-10-30 06:00:00|   9.629320757393700000|      4467.460590623792|\n",
       "|   MCH0180|2024-10-24 15:00:00|   9.548354727013963750|     1534.9828469694578|\n",
       "|   MCH0062|2024-01-08 11:00:00|   9.450199536406430000|     3808.7500977214677|\n",
       "|   MCH0008|2024-10-11 06:00:00|   9.394826352665711250|     2025.5288033179913|\n",
       "+----------+-------------------+-----------------------+-----------------------+\n",
       "\n",
       "\n",
       "Maintenance scheduling recommendations:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------------------+\n",
       "|prediction|machines_needing_attention|\n",
       "+----------+--------------------------+\n",
       "|       0.0|                      3420|\n",
       "|       1.0|                         1|\n",
       "+----------+--------------------------+\n",
       "\n",
       "\n",
       "Top performing equipment (by efficiency):\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+------------------+--------------------+-----------------+\n",
       "|machine_id|   avg_hourly_rate|     avg_defect_rate|total_productions|\n",
       "+----------+------------------+--------------------+-----------------+\n",
       "|   MCH0183| 14210.23541718347|5.017873975909437...|                7|\n",
       "|   MCH0023|14002.642213047213|4.766842599160854...|               22|\n",
       "|   MCH0075|13892.659291604145|5.159525444673925...|               26|\n",
       "|   MCH0063| 13019.53607934131|5.078956924062062...|               14|\n",
       "|   MCH0044|12858.187275613313|5.112319375340358...|               13|\n",
       "|   MCH0021|12540.889231838602|5.037477915688167...|               21|\n",
       "|   MCH0092| 12422.28150104669|4.777298079000824...|               18|\n",
       "|   MCH0073|12197.130181869465|4.879424023395495...|               15|\n",
       "|   MCH0186|12151.423418196893|4.669963422534405...|               19|\n",
       "|   MCH0196|12085.061373636592|3.819311461648962...|               13|\n",
       "+----------+------------------+--------------------+-----------------+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze maintenance insights\n",
    "\n",
    "print(\"\\n=== Maintenance Insights ===\")\n",
    "\n",
    "# Identify high-risk machines\n",
    "high_risk_machines = predictions.filter(\"prediction = 0\") \\\n",
    "    .select(\"machine_id\", \"production_date\", \"rolling_avg_defect_rate\", \"rolling_avg_hourly_rate\") \\\n",
    "    .orderBy(\"rolling_avg_defect_rate\", ascending=False) \\\n",
    "    .limit(10)\n",
    "\n",
    "print(\"Top 10 high-risk machines requiring immediate attention:\")\n",
    "high_risk_machines.show()\n",
    "\n",
    "# Maintenance scheduling recommendations\n",
    "maintenance_schedule = predictions.filter(\"prediction < 2\") \\\n",
    "    .groupBy(\"prediction\") \\\n",
    "    .agg(count(\"machine_id\").alias(\"machines_needing_attention\")) \\\n",
    "    .orderBy(\"prediction\")\n",
    "\n",
    "print(\"\\nMaintenance scheduling recommendations:\")\n",
    "maintenance_schedule.show()\n",
    "\n",
    "# Equipment utilization analysis\n",
    "equipment_utilization = predictions.groupBy(\"machine_id\") \\\n",
    "    .agg(\n",
    "        avg(\"rolling_avg_hourly_rate\").alias(\"avg_hourly_rate\"),\n",
    "        avg(\"rolling_avg_defect_rate\").alias(\"avg_defect_rate\"),\n",
    "        count(\"*\").alias(\"total_productions\")\n",
    "    ) \\\n",
    "    .orderBy(\"avg_hourly_rate\", ascending=False)\n",
    "\n",
    "print(\"\\nTop performing equipment (by efficiency):\")\n",
    "equipment_utilization.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: Delta Liquid Clustering with ML in AIDP\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Automatic Optimization**: Created a Delta table with `CLUSTER BY (machine_id, production_date)` for optimal query performance\n",
    "\n",
    "2. **Performance Benefits**: Liquid clustering enables fast data access for ML feature engineering\n",
    "\n",
    "3. **Zero Maintenance**: Delta handles data layout optimization automatically\n",
    "\n",
    "4. **ML Integration**: Built predictive maintenance model using PySpark MLlib for equipment failure prediction\n",
    "\n",
    "5. **Business Value**: Model predictions enable proactive maintenance and improved manufacturing efficiency\n",
    "\n",
    "### AIDP Advantages\n",
    "\n",
    "- **Unified Analytics**: Seamlessly combines data engineering and ML workflows\n",
    "- **Performance**: Optimized Delta tables accelerate ML feature extraction\n",
    "- **Scalability**: Handles large-scale manufacturing datasets and complex ML training\n",
    "- **Governance**: Enterprise-grade data management and model deployment\n",
    "\n",
    "### ML Model Insights\n",
    "\n",
    "- **Risk Classification**: Model predicts maintenance risk levels (Low, Medium, High) with high accuracy\n",
    "- **Feature Importance**: Rolling statistics of defect rates and production efficiency drive predictions\n",
    "- **Business Impact**: Enables predictive maintenance, reducing downtime and maintenance costs\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Deploy model for real-time equipment monitoring\n",
    "- Integrate with SCADA systems for automated alerts\n",
    "- Expand to multi-step failure prediction\n",
    "- Add sensor data and external factors for improved accuracy\n",
    "\n",
    "This notebook demonstrates how Oracle AI Data Platform combines advanced data engineering with machine learning to enable predictive maintenance and optimize manufacturing operations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
