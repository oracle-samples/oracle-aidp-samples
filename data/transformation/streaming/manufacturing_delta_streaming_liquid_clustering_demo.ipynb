{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manufacturing: Streaming Delta Liquid Clustering Demo\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "\n",
    "This notebook demonstrates **Streaming Delta Liquid Clustering** in Oracle AI Data Platform (AIDP) Workbench using a manufacturing production analytics use case. We leverage PySpark's rate emitter to generate continuous streaming data and showcase real-time production monitoring with Delta Liquid Clustering.\n",
    "\n",
    "\n",
    "\n",
    "### What is Streaming with Liquid Clustering?\n",
    "\n",
    "\n",
    "\n",
    "Combining Structured Streaming with Delta Liquid Clustering provides:\n",
    "\n",
    "\n",
    "\n",
    "- **Continuous production monitoring**: Real-time data processing with automatic clustering optimization\n",
    "\n",
    "- **Optimized streaming queries**: Liquid clustering improves performance of real-time analytics\n",
    "\n",
    "- **Live quality control**: Windowed operations for continuous defect monitoring\n",
    "\n",
    "- **Automatic maintenance**: Delta handles optimization during streaming writes\n",
    "\n",
    "\n",
    "\n",
    "### Use Case: Real-time Production Quality Control and Equipment Monitoring\n",
    "\n",
    "\n",
    "We'll process streaming manufacturing data for:\n",
    "\n",
    "\n",
    "- **Real-time equipment monitoring**: Continuous tracking of machine performance\n",
    "\n",
    "- **Live quality control**: Streaming defect detection and yield analysis\n",
    "\n",
    "- **Production line optimization**: Real-time bottleneck identification\n",
    "\n",
    "- **Predictive maintenance triggers**: Continuous equipment health assessment\n",
    "\n",
    "\n",
    "### AIDP Environment Setup\n",
    "\n",
    "\n",
    "This notebook uses the existing Spark session in your AIDP environment.\n",
    "# Create manufacturing catalog and analytics schema\n",
    "\n",
    "\n",
    "# In AIDP, catalogs provide data isolation and governance\n",
    "\n",
    "\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS manufacturing\")\n",
    "\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS manufacturing.analytics\")\n",
    "\n",
    "\n",
    "print(\"Manufacturing catalog and analytics schema created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create manufacturing catalog and analytics schema\n",
    "\n",
    "# In AIDP, catalogs provide data isolation and governance\n",
    "\n",
    "spark.sql(\"CREATE CATALOG IF NOT EXISTS manufacturing\")\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS manufacturing.analytics\")\n",
    "\n",
    "print(\"Manufacturing catalog and analytics schema created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE VOLUME IF NOT EXISTS default.default.testdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Delta Table with Liquid Clustering\n",
    "\n",
    "### Table Design\n",
    "\n",
    "Our `production_records_stream` table will store streaming manufacturing data with the same schema as the original demo:\n",
    "\n",
    "- **machine_id**: Unique equipment identifier\n",
    "- **production_date**: Timestamp of production run\n",
    "- **product_type**: Type of product manufactured\n",
    "- **units_produced**: Number of units produced\n",
    "- **defect_count**: Number of defective units\n",
    "- **production_line**: Assembly line identifier\n",
    "- **cycle_time**: Time to produce one unit (minutes)\n",
    "\n",
    "### Clustering Strategy\n",
    "\n",
    "We'll cluster by `machine_id` and `production_date` to optimize streaming writes and real-time equipment monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Streaming Delta table with liquid clustering created successfully!\n",
       "Clustering will automatically optimize data layout during streaming writes.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Delta table with liquid clustering for streaming\n",
    "\n",
    "# CLUSTER BY defines the columns for automatic optimization\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS manufacturing.analytics.production_records_stream (\n",
    "\n",
    "    machine_id STRING,\n",
    "\n",
    "    production_date TIMESTAMP,\n",
    "\n",
    "    product_type STRING,\n",
    "\n",
    "    units_produced INT,\n",
    "\n",
    "    defect_count INT,\n",
    "\n",
    "    production_line STRING,\n",
    "\n",
    "    cycle_time DECIMAL(5,2)\n",
    "\n",
    ")\n",
    "\n",
    "USING DELTA\n",
    "\n",
    "CLUSTER BY (machine_id, production_date)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"Streaming Delta table with liquid clustering created successfully!\")\n",
    "print(\"Clustering will automatically optimize data layout during streaming writes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Streaming Data Producer with PySpark Rate Emitter\n",
    "\n",
    "### Streaming Production Data Generation Strategy\n",
    "\n",
    "We'll use PySpark's built-in **rate source** to generate continuous streaming production data:\n",
    "\n",
    "- **Rate Source**: Generates rows at a specified rate with `timestamp` and `value` columns\n",
    "- **Data Transformation**: Convert rate data into realistic manufacturing production records\n",
    "- **Continuous Processing**: Simulate real-time production line monitoring\n",
    "\n",
    "### Data Transformation Logic\n",
    "\n",
    "- **machine_id**: Derived from `value % 200` to create 200 unique machines\n",
    "- **production_date**: Use the `timestamp` from rate source\n",
    "- **product_type/line**: Randomly assigned based on manufacturing characteristics\n",
    "- **units_produced**: Calculated with realistic production volumes and variations\n",
    "- **defect_count**: Based on product type defect rates with quality variations\n",
    "- **cycle_time**: Equipment performance with efficiency variations\n",
    "- **Real-time Simulation**: Data flows continuously for live production monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rate streaming source created for production monitoring\n",
       "Schema:\n",
       "root\n",
       " |-- timestamp: timestamp (nullable = true)\n",
       " |-- value: long (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary functions for streaming\n",
    "from pyspark.sql.functions import col, expr, rand, when, hour, dayofweek, month, abs\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Define constants for manufacturing data generation\n",
    "PRODUCT_TYPES = ['Electronics', 'Automotive Parts', 'Consumer Goods', 'Industrial Equipment']\n",
    "PRODUCTION_LINES = ['LINE_A', 'LINE_B', 'LINE_C', 'LINE_D', 'LINE_E']\n",
    "\n",
    "# Create streaming DataFrame using rate source\n",
    "# This generates rows at 10 rows per second (production runs)\n",
    "streaming_rate = spark.readStream \\\n",
    "    .format(\"rate\") \\\n",
    "    .option(\"rowsPerSecond\", 10) \\\n",
    "    .load()\n",
    "\n",
    "print(\"Rate streaming source created for production monitoring\")\n",
    "print(\"Schema:\")\n",
    "streaming_rate.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Streaming manufacturing production data transformation defined\n",
       "Sample transformed schema:\n",
       "root\n",
       " |-- machine_id: string (nullable = true)\n",
       " |-- production_date: timestamp (nullable = true)\n",
       " |-- product_type: string (nullable = false)\n",
       " |-- units_produced: integer (nullable = true)\n",
       " |-- defect_count: integer (nullable = true)\n",
       " |-- production_line: string (nullable = false)\n",
       " |-- cycle_time: decimal(5,2) (nullable = true)\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform rate data into manufacturing production records\n",
    "production_stream = streaming_rate \\\n",
    "    .withColumn(\"machine_num\", (col(\"value\") % 200) + 1) \\\n",
    "    .withColumn(\"machine_id\", expr(\"concat('MCH', lpad(cast(machine_num as string), 4, '0'))\")) \\\n",
    "    .withColumn(\"production_date\", col(\"timestamp\")) \\\n",
    "    .withColumn(\"is_problem_machine\", when(col(\"machine_num\").isin([42, 87, 123, 156, 189]), True).otherwise(False)) \\\n",
    "    .withColumn(\"product_type\", \n",
    "                when((col(\"value\") % 4) == 0, \"Electronics\")\n",
    "                .when((col(\"value\") % 4) == 1, \"Automotive Parts\")\n",
    "                .when((col(\"value\") % 4) == 2, \"Consumer Goods\")\n",
    "                .otherwise(\"Industrial Equipment\")) \\\n",
    "    .withColumn(\"production_line\",\n",
    "                when((col(\"value\") % 5) == 0, \"LINE_A\")\n",
    "                .when((col(\"value\") % 5) == 1, \"LINE_B\")\n",
    "                .when((col(\"value\") % 5) == 2, \"LINE_C\")\n",
    "                .when((col(\"value\") % 5) == 3, \"LINE_D\")\n",
    "                .otherwise(\"LINE_E\")) \\\n",
    "    .withColumn(\"base_units\",\n",
    "                when(col(\"product_type\") == \"Electronics\", 500)\n",
    "                .when(col(\"product_type\") == \"Automotive Parts\", 200)\n",
    "                .when(col(\"product_type\") == \"Consumer Goods\", 800)\n",
    "                .otherwise(50)) \\\n",
    "    .withColumn(\"base_defect_rate\",\n",
    "                when(col(\"product_type\") == \"Electronics\", 0.02)\n",
    "                .when(col(\"product_type\") == \"Automotive Parts\", 0.05)\n",
    "                .when(col(\"product_type\") == \"Consumer Goods\", 0.03)\n",
    "                .otherwise(0.08)) \\\n",
    "    .withColumn(\"base_cycle_time\",\n",
    "                when(col(\"product_type\") == \"Electronics\", 2.5)\n",
    "                .when(col(\"product_type\") == \"Automotive Parts\", 8.0)\n",
    "                .when(col(\"product_type\") == \"Consumer Goods\", 1.8)\n",
    "                .otherwise(25.0)) \\\n",
    "    .withColumn(\"production_multiplier\", \n",
    "                when(col(\"is_problem_machine\"), 0.3 + rand() * 0.8)  # Problem machines: 30% to 110% of normal\n",
    "                .otherwise(0.7 + rand() * 0.6)) \\\n",
    "    .withColumn(\"units_produced\", \n",
    "                expr(\"cast(base_units * production_multiplier as int)\")) \\\n",
    "    .withColumn(\"defect_multiplier\",\n",
    "                when(col(\"is_problem_machine\"), 2.0 + rand() * 3.0)  # Problem machines: 2x to 5x defect rate\n",
    "                .otherwise(0.5 + rand() * 1.0)) \\\n",
    "    .withColumn(\"defect_count\", \n",
    "                expr(\"cast(units_produced * base_defect_rate * defect_multiplier as int)\")) \\\n",
    "    .withColumn(\"cycle_time_multiplier\",\n",
    "                when(col(\"is_problem_machine\"), 1.5 + rand() * 1.0)  # Problem machines: 50% slower\n",
    "                .otherwise(0.8 + rand() * 0.4)) \\\n",
    "    .withColumn(\"cycle_time\", \n",
    "                expr(\"round(base_cycle_time * cycle_time_multiplier, 2)\").cast(\"decimal(5, 2)\")) \\\n",
    "    .select(\"machine_id\", \"production_date\", \"product_type\", \"units_produced\", \n",
    "            \"defect_count\", \"production_line\", \"cycle_time\")\n",
    "\n",
    "print(\"Streaming manufacturing production data transformation defined\")\n",
    "print(\"Sample transformed schema:\")\n",
    "production_stream.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Streaming Write to Delta Table\n",
    "\n",
    "### Streaming Ingestion Strategy\n",
    "\n",
    "We'll write the transformed streaming production data to the Delta table with liquid clustering:\n",
    "\n",
    "- **Append Mode**: Continuously add new production records as they arrive\n",
    "- **Checkpointing**: Enable fault tolerance and exactly-once processing\n",
    "- **Liquid Clustering**: Automatic optimization during streaming writes\n",
    "- **Trigger**: Process micro-batches every 10 seconds for real-time monitoring\n",
    "\n",
    "### Why Streaming Writes?\n",
    "\n",
    "- **Real-time Production Monitoring**: Data becomes available for quality control immediately\n",
    "- **Optimized Equipment Queries**: Liquid clustering accelerates machine performance analysis\n",
    "- **Scalability**: Handles continuous production line data streams\n",
    "- **Consistency**: ACID transactions ensure manufacturing data integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start streaming write to Delta table\n",
    "# Note: In a real scenario, this would run continuously\n",
    "# For demo purposes, we'll limit it to a short duration\n",
    "QUERY_NAME=\"manufacturing_stream\"\n",
    "checkpointLocation = \"/Volumes/default/default/testdata/manuStreamingCheckpoint\"\n",
    "\n",
    "streaming_query = production_stream.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .queryName(QUERY_NAME) \\\n",
    "    .option(\"checkpointLocation\", checkpointLocation) \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .toTable(\"manufacturing.analytics.production_records_stream\")\n",
    "\n",
    "print(\"Streaming write query configured\")\n",
    "print(\"This will continuously write production records to the Delta table with liquid clustering\")\n",
    "\n",
    "# For demo purposes, we'll start and stop the stream after a short time\n",
    "# In production, this would run indefinitely\n",
    "print(\"Starting streaming query...\")\n",
    "query_handle = streaming_query.start()\n",
    "\n",
    "# Let it run for 30 seconds to generate some data\n",
    "import time\n",
    "time.sleep(30)\n",
    "\n",
    "# Stop the streaming query\n",
    "query_handle.stop()\n",
    "print(\"Streaming query stopped after 30 seconds\")\n",
    "print(\"Data has been written to the Delta table with liquid clustering optimization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Real-time Production Analytics\n",
    "\n",
    "### Streaming Analytics Strategy\n",
    "\n",
    "With data continuously flowing into the Delta table, we can perform real-time production analytics:\n",
    "\n",
    "- **Live Production Dashboard**: Real-time overview of factory operations\n",
    "- **Quality Control Monitoring**: Continuous defect rate tracking\n",
    "- **Equipment Performance**: Real-time machine efficiency analysis\n",
    "- **Production Line Optimization**: Live bottleneck identification\n",
    "\n",
    "### Benefits of Streaming Analytics\n",
    "\n",
    "- **Immediate Quality Insights**: No waiting for end-of-shift reports\n",
    "- **Optimized Equipment Queries**: Liquid clustering accelerates production analysis\n",
    "- **Continuous Process Control**: Always up-to-date manufacturing intelligence\n",
    "- **Operational Excellence**: Enable real-time production decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Real-time Production Status ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+---------------------+---------------+--------------------+-----------------+--------------+\n",
       "|total_production_runs|active_machines|total_units_produced|avg_units_per_run|avg_cycle_time|\n",
       "+---------------------+---------------+--------------------+-----------------+--------------+\n",
       "|                  470|            200|              180731|           384.53|          9.52|\n",
       "+---------------------+---------------+--------------------+-----------------+--------------+\n",
       "\n",
       "\n",
       "=== Real-time Quality Control Dashboard ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+--------------------+---------------+-----------+-------------+---------------+-------------+\n",
       "|        product_type|production_runs|total_units|total_defects|avg_defect_rate|overall_yield|\n",
       "+--------------------+---------------+-----------+-------------+---------------+-------------+\n",
       "|      Consumer Goods|            142|     110439|         3358|           3.18|         3.04|\n",
       "|         Electronics|            143|      73254|         1459|           1.99|         1.99|\n",
       "|    Automotive Parts|            143|      28709|         1387|           4.86|         4.83|\n",
       "|Industrial Equipment|            142|       6890|          513|           7.58|         7.45|\n",
       "+--------------------+---------------+-----------+-------------+---------------+-------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analyze the streaming production data that was ingested\n",
    "\n",
    "print(\"=== Real-time Production Status ===\")\n",
    "\n",
    "current_production = spark.sql(\"\"\"\n",
    "SELECT COUNT(*) as total_production_runs,\n",
    "       COUNT(DISTINCT machine_id) as active_machines,\n",
    "       SUM(units_produced) as total_units_produced,\n",
    "       ROUND(AVG(units_produced), 2) as avg_units_per_run,\n",
    "       ROUND(AVG(cycle_time), 2) as avg_cycle_time\n",
    "FROM manufacturing.analytics.production_records_stream\n",
    "\"\"\")\n",
    "\n",
    "current_production.show()\n",
    "\n",
    "print(\"\\n=== Real-time Quality Control Dashboard ===\")\n",
    "quality_dashboard = spark.sql(\"\"\"\n",
    "SELECT product_type,\n",
    "       COUNT(*) as production_runs,\n",
    "       ROUND(SUM(units_produced), 0) as total_units,\n",
    "       ROUND(SUM(defect_count), 0) as total_defects,\n",
    "       ROUND(AVG(defect_count * 100.0 / units_produced), 2) as avg_defect_rate,\n",
    "       ROUND(SUM(defect_count) * 100.0 / SUM(units_produced), 2) as overall_yield\n",
    "FROM manufacturing.analytics.production_records_stream\n",
    "GROUP BY product_type\n",
    "ORDER BY total_units DESC\n",
    "\"\"\")\n",
    "\n",
    "quality_dashboard.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Equipment Performance Analysis ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+----------+------------------+--------------+---------------+-----------------+\n",
       "|machine_id|total_runs|avg_units_produced|avg_cycle_time|avg_defect_rate|hourly_throughput|\n",
       "+----------+----------+------------------+--------------+---------------+-----------------+\n",
       "|   MCH0131|         4|             891.0|          1.58|           2.70|         33889.06|\n",
       "|   MCH0147|         4|            816.25|          1.52|           3.23|         32326.73|\n",
       "|   MCH0071|         4|            944.75|          1.76|           2.71|         32207.39|\n",
       "|   MCH0035|         4|             886.5|          1.66|           2.77|         32090.50|\n",
       "|   MCH0023|         4|             846.0|          1.68|           2.59|         30214.29|\n",
       "|   MCH0163|         4|            816.25|          1.66|           3.16|         29458.65|\n",
       "|   MCH0075|         4|             848.0|          1.75|           3.62|         29157.59|\n",
       "|   MCH0199|         3|            867.67|          1.80|           3.08|         28922.22|\n",
       "|   MCH0111|         4|            863.25|          1.81|           2.56|         28616.02|\n",
       "|   MCH0135|         4|            814.25|          1.74|           3.04|         28117.99|\n",
       "+----------+----------+------------------+--------------+---------------+-----------------+\n",
       "\n",
       "\n",
       "=== Production Line Efficiency ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+---------------+----------+-------------+----------------+------------+---------------+--------------+\n",
       "|production_line|total_runs|machines_used|total_production|avg_run_size|avg_defect_rate|avg_cycle_time|\n",
       "+---------------+----------+-------------+----------------+------------+---------------+--------------+\n",
       "|         LINE_E|       174|           40|           68873|      395.82|           4.17|          9.26|\n",
       "|         LINE_A|       174|           40|           66794|      383.87|           4.74|          9.80|\n",
       "|         LINE_C|       174|           40|           65991|      379.26|           4.32|          9.55|\n",
       "|         LINE_D|       174|           40|           65955|      379.05|           4.01|          9.25|\n",
       "|         LINE_B|       174|           40|           65337|       375.5|           4.52|          9.59|\n",
       "+---------------+----------+-------------+----------------+------------+---------------+--------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"=== Equipment Performance Analysis ===\")\n",
    "equipment_analysis = spark.sql(\"\"\"\n",
    "SELECT machine_id,\n",
    "       COUNT(*) as total_runs,\n",
    "       ROUND(AVG(units_produced), 2) as avg_units_produced,\n",
    "       ROUND(AVG(cycle_time), 2) as avg_cycle_time,\n",
    "       ROUND(AVG(defect_count * 100.0 / units_produced), 2) as avg_defect_rate,\n",
    "       ROUND(SUM(units_produced) * 60.0 / SUM(cycle_time), 2) as hourly_throughput\n",
    "FROM manufacturing.analytics.production_records_stream\n",
    "GROUP BY machine_id\n",
    "ORDER BY hourly_throughput DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "equipment_analysis.show()\n",
    "\n",
    "print(\"\\n=== Production Line Efficiency ===\")\n",
    "line_efficiency = spark.sql(\"\"\"\n",
    "SELECT production_line,\n",
    "       COUNT(*) as total_runs,\n",
    "       COUNT(DISTINCT machine_id) as machines_used,\n",
    "       ROUND(SUM(units_produced), 0) as total_production,\n",
    "       ROUND(AVG(units_produced), 2) as avg_run_size,\n",
    "       ROUND(SUM(defect_count * 100.0 / units_produced) / COUNT(*), 2) as avg_defect_rate,\n",
    "       ROUND(AVG(cycle_time), 2) as avg_cycle_time\n",
    "FROM manufacturing.analytics.production_records_stream\n",
    "GROUP BY production_line\n",
    "ORDER BY total_production DESC\n",
    "\"\"\")\n",
    "\n",
    "line_efficiency.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Real-time Manufacturing Anomaly Detection\n",
    "\n",
    "### Streaming Anomaly Detection Strategy\n",
    "\n",
    "We'll implement statistical anomaly detection for real-time manufacturing monitoring:\n",
    "\n",
    "- **Quality Anomalies**: Identify production runs with unusually high defect rates\n",
    "- **Performance Anomalies**: Detect equipment with abnormal cycle times or throughput\n",
    "- **Production Anomalies**: Flag runs with extreme unit production variations\n",
    "- **Line Efficiency Alerts**: Monitor for production line bottlenecks\n",
    "\n",
    "### Real-time Manufacturing Benefits\n",
    "\n",
    "- **Immediate Quality Control**: Catch defects before they reach customers\n",
    "- **Equipment Health Monitoring**: Identify maintenance needs proactively\n",
    "- **Production Optimization**: Address bottlenecks in real-time\n",
    "- **Cost Reduction**: Minimize scrap and rework through early detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Statistical Baselines for Manufacturing Anomaly Detection ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+--------------------+----------+------------+---------------+-----------------+----------------+------------------+\n",
       "|        product_type|mean_units|stddev_units|mean_cycle_time|stddev_cycle_time|mean_defect_rate|stddev_defect_rate|\n",
       "+--------------------+----------+------------+---------------+-----------------+----------------+------------------+\n",
       "|    Automotive Parts|    197.78|       34.95|           8.15|             1.52|            5.00|              2.24|\n",
       "|      Consumer Goods|    786.86|       154.3|           1.88|             0.43|            3.19|              1.65|\n",
       "|Industrial Equipment|     48.62|        9.04|          25.39|             4.44|            7.38|              3.92|\n",
       "|         Electronics|    497.65|       86.73|           2.55|             0.39|            1.98|              0.93|\n",
       "+--------------------+----------+------------+---------------+-----------------+----------------+------------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Anomaly thresholds calculated for real-time manufacturing monitoring (2 standard deviations for higher sensitivity)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from decimal import Decimal\n",
    "# Calculate statistical baselines for manufacturing anomaly detection\n",
    "print(\"=== Statistical Baselines for Manufacturing Anomaly Detection ===\")\n",
    "\n",
    "manufacturing_baselines = spark.sql(\"\"\"\n",
    "SELECT product_type,\n",
    "       ROUND(AVG(units_produced), 2) as mean_units,\n",
    "       ROUND(STDDEV(units_produced), 2) as stddev_units,\n",
    "       ROUND(AVG(cycle_time), 2) as mean_cycle_time,\n",
    "       ROUND(STDDEV(cycle_time), 2) as stddev_cycle_time,\n",
    "       ROUND(AVG(defect_count * 100.0 / units_produced), 2) as mean_defect_rate,\n",
    "       ROUND(STDDEV(defect_count * 100.0 / units_produced), 2) as stddev_defect_rate\n",
    "FROM manufacturing.analytics.production_records_stream\n",
    "GROUP BY product_type\n",
    "\"\"\")\n",
    "\n",
    "manufacturing_baselines.show()\n",
    "\n",
    "# Convert to pandas for threshold calculations\n",
    "baselines_pd = manufacturing_baselines.toPandas()\n",
    "\n",
    "# Define anomaly thresholds (2 standard deviations for more sensitive detection)\n",
    "manufacturing_thresholds = {}\n",
    "for _, row in baselines_pd.iterrows():\n",
    "    product_type = row['product_type']\n",
    "    manufacturing_thresholds[product_type] = {\n",
    "        'units_high': row['mean_units'] + 2 * row['stddev_units'],\n",
    "        'units_low': row['mean_units'] - 2 * row['stddev_units'],\n",
    "        'cycle_time_high': row['mean_cycle_time'] + 2 * Decimal.from_float(row['stddev_cycle_time']),\n",
    "        'defect_rate_high': row['mean_defect_rate'] + 2 * Decimal.from_float(row['stddev_defect_rate'])\n",
    "    }\n",
    "\n",
    "print(\"\\nAnomaly thresholds calculated for real-time manufacturing monitoring (2 standard deviations for higher sensitivity)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=== Real-time Manufacturing Anomaly Detection Results ===\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Quality Anomalies (High Defect Rates):\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------------+--------------------+---------------+--------------+------------+-----------+----------------+\n",
       "|machine_id|     production_date|        product_type|production_line|units_produced|defect_count|defect_rate|      alert_type|\n",
       "+----------+--------------------+--------------------+---------------+--------------+------------+-----------+----------------+\n",
       "|   MCH0156|2025-12-15 16:25:...|Industrial Equipment|         LINE_A|            37|          14|      37.84|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:24:...|Industrial Equipment|         LINE_A|            49|          18|      36.73|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:23:...|Industrial Equipment|         LINE_A|            47|          17|      36.17|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:24:...|Industrial Equipment|         LINE_A|            33|          11|      33.33|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:22:...|Industrial Equipment|         LINE_A|            37|          12|      32.43|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:21:...|Industrial Equipment|         LINE_A|            32|          10|      31.25|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:22:...|Industrial Equipment|         LINE_A|            26|           8|      30.77|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:22:...|Industrial Equipment|         LINE_A|            30|           9|      30.00|HIGH_DEFECT_RATE|\n",
       "|   MCH0156|2025-12-15 16:24:...|Industrial Equipment|         LINE_A|            15|           4|      26.67|HIGH_DEFECT_RATE|\n",
       "|   MCH0042|2025-12-15 16:23:...|    Automotive Parts|         LINE_B|           139|          33|      23.74|HIGH_DEFECT_RATE|\n",
       "+----------+--------------------+--------------------+---------------+--------------+------------+-----------+----------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Performance Anomalies (Slow Equipment):\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------------+--------------------+---------------+----------+--------------+-----------+---------------+\n",
       "|machine_id|     production_date|        product_type|production_line|cycle_time|units_produced|hourly_rate|     alert_type|\n",
       "+----------+--------------------+--------------------+---------------+----------+--------------+-----------+---------------+\n",
       "|   MCH0156|2025-12-15 16:23:...|Industrial Equipment|         LINE_A|     62.19|            20|      19.30|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:21:...|Industrial Equipment|         LINE_A|     61.06|            32|      31.44|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:22:...|Industrial Equipment|         LINE_A|     53.01|            30|      33.96|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:25:...|Industrial Equipment|         LINE_A|     49.26|            45|      54.81|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:25:...|Industrial Equipment|         LINE_A|     47.36|            37|      46.88|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:23:...|Industrial Equipment|         LINE_A|     46.39|            47|      60.79|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:25:...|Industrial Equipment|         LINE_A|     45.85|            21|      27.48|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:24:...|Industrial Equipment|         LINE_A|     44.70|            49|      65.77|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:24:...|Industrial Equipment|         LINE_A|     44.55|            15|      20.20|SLOW_CYCLE_TIME|\n",
       "|   MCH0156|2025-12-15 16:22:...|Industrial Equipment|         LINE_A|     42.66|            26|      36.57|SLOW_CYCLE_TIME|\n",
       "+----------+--------------------+--------------------+---------------+----------+--------------+-----------+---------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Production Volume Anomalies:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+----------+--------------------+--------------+---------------+--------------+-------------+\n",
       "|machine_id|     production_date|  product_type|production_line|units_produced|volume_status|\n",
       "+----------+--------------------+--------------+---------------+--------------+-------------+\n",
       "|   MCH0123|2025-12-15 16:21:...|Consumer Goods|         LINE_C|           441|   LOW_VOLUME|\n",
       "|   MCH0087|2025-12-15 16:24:...|Consumer Goods|         LINE_B|           409|   LOW_VOLUME|\n",
       "|   MCH0087|2025-12-15 16:25:...|Consumer Goods|         LINE_B|           398|   LOW_VOLUME|\n",
       "|   MCH0123|2025-12-15 16:23:...|Consumer Goods|         LINE_C|           350|   LOW_VOLUME|\n",
       "|   MCH0123|2025-12-15 16:22:...|Consumer Goods|         LINE_C|           348|   LOW_VOLUME|\n",
       "|   MCH0123|2025-12-15 16:22:...|Consumer Goods|         LINE_C|           347|   LOW_VOLUME|\n",
       "|   MCH0087|2025-12-15 16:22:...|Consumer Goods|         LINE_B|           346|   LOW_VOLUME|\n",
       "|   MCH0123|2025-12-15 16:25:...|Consumer Goods|         LINE_C|           310|   LOW_VOLUME|\n",
       "|   MCH0123|2025-12-15 16:23:...|Consumer Goods|         LINE_C|           279|   LOW_VOLUME|\n",
       "|   MCH0087|2025-12-15 16:24:...|Consumer Goods|         LINE_B|           265|   LOW_VOLUME|\n",
       "+----------+--------------------+--------------+---------------+--------------+-------------+\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform anomaly detection on the streaming manufacturing data\n",
    "print(\"=== Real-time Manufacturing Anomaly Detection Results ===\")\n",
    "\n",
    "# Register thresholds as a temporary view for SQL queries\n",
    "thresholds_data = []\n",
    "for product_type, thresholds in manufacturing_thresholds.items():\n",
    "    thresholds_data.append({\n",
    "        'product_type': product_type,\n",
    "        'units_high': thresholds['units_high'],\n",
    "        'units_low': thresholds['units_low'],\n",
    "        'cycle_time_high': thresholds['cycle_time_high'],\n",
    "        'defect_rate_high': thresholds['defect_rate_high']\n",
    "    })\n",
    "\n",
    "thresholds_df = spark.createDataFrame(thresholds_data)\n",
    "thresholds_df.createOrReplaceTempView(\"manufacturing_thresholds\")\n",
    "\n",
    "# Find quality anomalies (high defect rates)\n",
    "quality_anomalies = spark.sql(\"\"\"\n",
    "SELECT r.machine_id, r.production_date, r.product_type, r.production_line,\n",
    "       r.units_produced, r.defect_count,\n",
    "       ROUND(r.defect_count * 100.0 / r.units_produced, 2) as defect_rate,\n",
    "       'HIGH_DEFECT_RATE' as alert_type\n",
    "FROM manufacturing.analytics.production_records_stream r\n",
    "JOIN manufacturing_thresholds t ON r.product_type = t.product_type\n",
    "WHERE (r.defect_count * 100.0 / r.units_produced) > t.defect_rate_high\n",
    "ORDER BY defect_rate DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"Quality Anomalies (High Defect Rates):\")\n",
    "quality_anomalies.show()\n",
    "\n",
    "# Find performance anomalies (slow cycle times)\n",
    "performance_anomalies = spark.sql(\"\"\"\n",
    "SELECT r.machine_id, r.production_date, r.product_type, r.production_line,\n",
    "       r.cycle_time, r.units_produced,\n",
    "       ROUND(r.units_produced * 60.0 / r.cycle_time, 2) as hourly_rate,\n",
    "       'SLOW_CYCLE_TIME' as alert_type\n",
    "FROM manufacturing.analytics.production_records_stream r\n",
    "JOIN manufacturing_thresholds t ON r.product_type = t.product_type\n",
    "WHERE r.cycle_time > t.cycle_time_high\n",
    "ORDER BY r.cycle_time DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nPerformance Anomalies (Slow Equipment):\")\n",
    "performance_anomalies.show()\n",
    "\n",
    "# Find production volume anomalies\n",
    "volume_anomalies = spark.sql(\"\"\"\n",
    "SELECT r.machine_id, r.production_date, r.product_type, r.production_line,\n",
    "       r.units_produced,\n",
    "       CASE \n",
    "         WHEN r.units_produced > t.units_high THEN 'HIGH_VOLUME'\n",
    "         WHEN r.units_produced < t.units_low THEN 'LOW_VOLUME'\n",
    "         ELSE 'NORMAL'\n",
    "       END as volume_status\n",
    "FROM manufacturing.analytics.production_records_stream r\n",
    "JOIN manufacturing_thresholds t ON r.product_type = t.product_type\n",
    "WHERE r.units_produced > t.units_high OR r.units_produced < t.units_low\n",
    "ORDER BY ABS(r.units_produced) DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nProduction Volume Anomalies:\")\n",
    "volume_anomalies.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways: Streaming Delta Liquid Clustering in Manufacturing\n",
    "\n",
    "### What We Demonstrated\n",
    "\n",
    "1. **Streaming Production Ingestion**: Used PySpark's rate emitter to generate continuous manufacturing data\n",
    "\n",
    "2. **Real-time Processing**: Transformed and ingested production records in micro-batches with fault tolerance\n",
    "\n",
    "3. **Liquid Clustering Optimization**: Automatic data layout optimization during streaming writes\n",
    "\n",
    "4. **Real-time Manufacturing Analytics**: Live production dashboards and quality control monitoring\n",
    "\n",
    "5. **Anomaly Detection**: Statistical monitoring for equipment health and quality control\n",
    "\n",
    "### AIDP Manufacturing Advantages\n",
    "\n",
    "- **Unified Platform**: Seamlessly combines streaming ingestion and analytical queries\n",
    "- **Optimized Equipment Queries**: Liquid clustering accelerates machine performance analysis\n",
    "- **Fault Tolerance**: Checkpointing ensures exactly-once processing of production data\n",
    "- **Scalability**: Handles high-volume manufacturing data streams with automatic optimization\n",
    "\n",
    "### Real-time Manufacturing Insights\n",
    "\n",
    "- **Quality Control**: Continuous defect monitoring prevents product quality issues\n",
    "- **Equipment Monitoring**: Real-time performance tracking enables predictive maintenance\n",
    "- **Production Optimization**: Live bottleneck identification improves throughput\n",
    "- **Operational Intelligence**: Anomaly detection enables proactive manufacturing decisions\n",
    "\n",
    "### Business Benefits: Industry 4.0 ROI\n",
    "\n",
    "- **Quality Improvement**: 40% reduction in defect rates through real-time monitoring\n",
    "- **Maintenance Optimization**: 30% decrease in unplanned downtime with predictive alerts\n",
    "- **Production Efficiency**: 25% increase in overall equipment effectiveness (OEE)\n",
    "- **Cost Reduction**: Significant savings through reduced scrap and rework\n",
    "\n",
    "### Next Steps for Production\n",
    "\n",
    "- Deploy continuous streaming pipelines for 24/7 factory monitoring\n",
    "- Integrate with SCADA systems for automated equipment control\n",
    "- Add predictive maintenance using streaming ML models\n",
    "- Implement real-time alerting and automated quality control\n",
    "- Scale to monitor thousands of machines across global facilities\n",
    "\n",
    "This notebook demonstrates how Oracle AIDP enables Industry 4.0 manufacturing intelligence through streaming Delta tables with liquid clustering, providing manufacturers with the tools for smart factory operations and operational excellence.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
